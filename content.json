{"pages":[{"title":"","text":"404","link":"/404.html"},{"title":"关于我","text":"码农一枚，坚信代码改变世界！ 记录 15:06:28/06/06/2019 爱情就像在海滩上捡贝壳，不要捡最大的， 也不要捡最漂亮的，要捡就捡自己最喜欢的， 最重要的是捡到了自己喜欢的 就永远不要再去海边了。 –公众号文章 11:07/05/22/2019 无论走到哪里，都应该记住。过去都是假的，回忆是一条没有尽头的路，一切以往的春天都不复存在，就连那最坚韧而又狂乱的爱情归根结底也不过是一种转瞬即逝的现实。 –马尔克斯《百年孤独》 11:05/05/22/2019 我觉得美不是一切，它很浪费人生。美要加上滋味、加上开心、加上别的东西，才是人生的美满。 –张曼玉 15:37/05/06/2019 Under no circumstances will I give up loving you.山无棱天地合才敢与君绝。 –《mooc学院》 17:15/04/26/2019 一个人无法自成孤岛，要么至少，一个人无法自成最理想的孤岛。 –《岛上书店》 17:12/04/22/2019 你写下的每一个bug，都是人类反抗被人工智能统治的一颗子弹 17:12/04/22/2019 所谓活着并不是单纯的呼吸，心脏跳动，也不是脑电波，而是在这个世界上留下痕迹。要能看见自己一路走来的脚印，并确信那些都是自己留下的印记，这才叫活着。 –《东野圭吾》 2019计划21:59/12/31/2018 2019-flag 购买的专业书籍至少看完一遍（并发、重构、设计模式…） 微信读书每天一个小时(年终总计300小时) 坚持每周去两次健身房(多练肚子、力量、学会蝶泳) 至少完成一项 前后端分离项目 完成一项 微服务项目(类似公司使用相关技术) 不辞职 多交朋友、多换位思考、多与朋友交流沟通 居安思危，多思考关注相关专业前景，生活环境 Java基础技能强化 多买书 学习更多的新菜(至少三项) 少买电子产品，少网购，少逛数码产品 学英语记单词、学数学、多看视频教程 少玩游戏","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"留言板","text":"畅所欲言有留必应","link":"/message/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"一次数据库的死锁问题排查过程","text":"摘要某天晚上，同事正在发布，突然线上大量报警，很多是关于数据库死锁的，报警提示信息如下： 现象某天晚上，同事正在发布，突然线上大量报警，很多是关于数据库死锁的，报警提示信息如下： 123456789{\"errorCode\":\"SYSTEM_ERROR\",\"errorMsg\":\"nested exception is org.apache.ibatis.exceptions.PersistenceException: Error updating database. Cause: ERR-CODE: [TDDL-4614][ERR_EXECUTE_ON_MYSQL] Deadlock found when trying to get lock; The error occurred while setting parameters\\n### SQL: update fund_transfer_stream set gmt_modified=now(),state = ? where fund_transfer_order_no = ? and seller_id = ? and state = 'NEW' 通过报警，我们基本可以定位到发生死锁的数据库以及数据库表。先来介绍下本文案例中涉及到的数据库相关信息。 背景情况我们使用的数据库是Mysql 5.7，引擎是InnoDB，事务隔离级别是READ-COMMITED。 数据库版本查询方法： 1SELECT version(); 引擎查询方法： 1show create table fund_transfer_stream; 建表语句中会显示存储引擎信息，形如：ENGINE=InnoDB 事务隔离级别查询方法： 1select @@tx_isolation; 事务隔离级别设置方法（只对当前Session生效）： 1set session transaction isolation level read committed; PS：注意，如果数据库是分库的，以上几条SQL语句需要在单库上执行，不要在逻辑库执行。 发生死锁的表结构及索引情况（隐去了部分无关字段和索引）： 1234567891011121314CREATE TABLE `fund_transfer_stream` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键', `gmt_create` datetime NOT NULL COMMENT '创建时间', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `pay_scene_name` varchar(256) NOT NULL COMMENT '支付场景名称', `pay_scene_version` varchar(256) DEFAULT NULL COMMENT '支付场景版本', `identifier` varchar(256) NOT NULL COMMENT '唯一性标识', `seller_id` varchar(64) NOT NULL COMMENT '卖家Id', `state` varchar(64) DEFAULT NULL COMMENT '状态', `fund_transfer_order_no` varchar(256) DEFAULT NULL COMMENT '资金平台返回的状态', PRIMARY KEY (`id`),UNIQUE KEY `uk_scene_identifier` (KEY `idx_seller` (`seller_id`), KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='资金流水'; 该数据库共有三个索引，1个聚簇索引（主键索引），2个非聚簇索（非主键索引）引。 聚簇索引： 1PRIMARY KEY (`id`) 非聚簇索引： 123KEY `idx_seller` (`seller_id`),KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) 以上两个索引，其实idx_seller_transNo已经覆盖到了idx_seller，由于历史原因，因为该表以seller_id分表，所以是先有的idx_seller，后有的idx_seller_transNo 死锁日志当数据库发生死锁时，可以通过以下命令获取死锁日志： 1show engine innodb status 发生死锁，第一时间查看死锁日志，得到死锁日志内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243Transactions deadlock detected, dumping detailed information.2019-03-19T21:44:23.516263+08:00 5877341 [Note] InnoDB: *** (1) TRANSACTION:TRANSACTION 173268495, ACTIVE 0 sec fetching rowsmysql tables in use 1, locked 1LOCK WAIT 304 lock struct(s), heap size 41168, 6 row lock(s), undo log entries 1MySQL thread id 5877358, OS thread handle 47356539049728, query id 557970181 11.183.244.150 fin_instant_app updatingupdate `fund_transfer_stream` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031958363857'))2019-03-19T21:44:23.516321+08:00 5877341 [Note] InnoDB: *** (1) HOLDS THE LOCK(S):RECORD LOCKS space id 173 page no 13726 n bits 248 index idx_seller_transNo of table `xxx`.`fund_transfer_stream` trx id 173268495 lock_mode X locks rec but not gapRecord lock, heap no 168 PHYSICAL RECORD: n_fields 3; compact format; info bits 02019-03-19T21:44:23.516565+08:00 5877341 [Note] InnoDB: *** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 173 page no 12416 n bits 128 index PRIMARY of table `xxx`.`fund_transfer_stream` trx id 173268495 lock_mode X locks rec but not gap waitingRecord lock, heap no 56 PHYSICAL RECORD: n_fields 17; compact format; info bits 02019-03-19T21:44:23.517793+08:00 5877341 [Note] InnoDB: *** (2) TRANSACTION:TRANSACTION 173268500, ACTIVE 0 sec fetching rows, thread declared inside InnoDB 81mysql tables in use 1, locked 1302 lock struct(s), heap size 41168, 2 row lock(s), undo log entries 1MySQL thread id 5877341, OS thread handle 47362313119488, query id 557970189 11.131.81.107 fin_instant_app updatingupdate `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031957477256'))2019-03-19T21:44:23.517855+08:00 5877341 [Note] InnoDB: *** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 173 page no 12416 n bits 128 index PRIMARY of table `fin_instant_0003`.`fund_transfer_stream_0056` trx id 173268500 lock_mode X locks rec but not gapRecord lock, heap no 56 PHYSICAL RECORD: n_fields 17; compact format; info bits 02019-03-19T21:44:23.519053+08:00 5877341 [Note] InnoDB: *** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 173 page no 13726 n bits 248 index idx_seller_transNo of table `fin_instant_0003`.`fund_transfer_stream_0056` trx id 173268500 lock_mode X locks rec but not gap waitingRecord lock, heap no 168 PHYSICAL RECORD: n_fields 3; compact format; info bits 02019-03-19T21:44:23.519297+08:00 5877341 [Note] InnoDB: *** WE ROLL BACK TRANSACTION (2) 简单解读一下死锁日志，可以得到以下信息： 1、导致死锁的两条SQL语句分别是： 123update `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031957477256')) 和 123update `fund_transfer_stream_0056` set `gmt_modified` = NOW(), `state` = 'PROCESSING' where ((`state` = 'NEW') AND (`seller_id` = '38921111') AND (`fund_transfer_order_no` = '99010015000805619031958363857')) 2、事务1，持有索引idx_seller_transNo的锁，在等待获取PRIMARY的锁。 3、事务2，持有PRIMARY的锁，在等待获取idx_seller_transNo的锁。 4、因事务1和事务2之间发生循环等待，故发生死锁。 5、事务1和事务2当前持有的锁均为：lock_mode X locks rec but not gap 两个事务对记录加的都是X 锁，No Gap锁，即对当行记录加锁，并为加间隙锁。 X锁：排他锁、又称写锁。若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。 与之对应的是S锁：共享锁，又称读锁，若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。 Next-Key Lock：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 详见：https://www.cnblogs.com/zhoujinyi/p/3435982.html 、 https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html 问题排查根据我们目前已知的数据库相关信息，以及死锁的日志，我们基本可以做一些简单的判定。 首先，此次死锁一定是和Gap锁以及Next-Key Lock没有关系的。因为我们的数据库隔离级别是RC（READ-COMMITED）的，这种隔离级别是不会添加Gap锁的。前面的死锁日志也提到这一点。 然后，就要翻代码了，看看我们的代码中事务到底是怎么做的。核心代码及SQL如下： 12345@Transactional(rollbackFor = Exception.class)public int doProcessing(String sellerId, Long id, String fundTransferOrderNo) { fundTreansferStreamDAO.updateFundStreamId(sellerId, id, fundTransferOrderNo); return fundTreansferStreamDAO.updateStatus(sellerId, fundTransferOrderNo, FundTransferStreamState.PROCESSING.name());} 该代码的目的是先后修改同一条记录的两个不同字段，updateFundStreamId SQL： 123update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = #{fundTransferOrderNo} where id = #{id} and seller_id = #{sellerId} updateStatus SQL： 1234update fund_transfer_stream set gmt_modified=now(),state = #{state} where fund_transfer_order_no = #{fundTransferOrderNo} and seller_id = #{sellerId} and state = 'NEW' 可以看到，我们的同一个事务中执行了两条Update语句，这里分别查看下两条SQL的执行计划： updateFundStreamId执行的时候使用到的是PRIMARY索引。 updateStatus执行的时候使用到的是idx_seller_transNo索引。 通过执行计划，我们发现updateStatus其实是有两个索引可以用的，执行的时候真正使用的是idx_seller_transNo索引。这是因为MySQL查询优化器是基于代价（cost-based）的查询方式。因此，在查询过程中，最重要的一部分是根据查询的SQL语句，依据多种索引，计算查询需要的代价，从而选择最优的索引方式生成查询计划。 我们查询执行计划是在死锁发生之后做的，事后查询的执行计划和发绳死锁那一刻的索引使用情况并不一定相同的。但是，我们结合死锁日志，也可以定位到以上两条SQL语句执行的时候使用到的索引。即updateFundStreamId执行的时候使用到的是PRIMARY索引，updateStatus执行的时候使用到的是idx_seller_transNo索引。 有了以上这些已知信息，我们就可以开始排查死锁原因及其背后的原理了。通过分析死锁日志，再结合我们的代码以及数据库建表语句，我们发现主要问题出在我们的idx_seller_transNo索引上面： 1KEY `idx_seller_transNo` (`seller_id`,`fund_transfer_order_no`(20)) 索引创建语句中，我们使用了前缀索引，为了节约索引空间，提高索引效率，我们只选择了fund_transfer_order_no字段的前20位作为索引值。 因为fund_transfer_order_no只是普通索引，而非唯一性索引。又因为在一种特殊情况下，会有同一个用户的两个fund_transfer_order_no的前20位相同，这就导致两条不同的记录的索引值一样（因为seller_id 和fund_transfer_order_no(20)都相同 ）。 就如本文中的例子，发生死锁的两条记录的fund_transfer_order_no字段的值：99010015000805619031958363857和99010015000805619031957477256这两个就是前20位相同的。 那么为什么fund_transfer_order_no的前20位相同会导致死锁呢？ 加锁原理我们就拿本次的案例来看一下MySql数据库加锁的原理是怎样的，本文的死锁背后又发生了什么。 我们在数据库上模拟死锁场景，执行顺序如下： 事务1 事务2 执行结果 begin update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = ‘99010015000805619031958363857’ where id = 1 and seller_id = 3111095611; 执行成功 begin update fund_transfer_stream set gmt_modified=now(),fund_transfer_order_no = ‘99010015000805619031957477256’ where id = 2 and seller_id = 3111095611; 执行成功 update fund_transfer_stream set gmt_modified = NOW(), state = ‘PROCESSING’ where ((state = ‘NEW’) AND (seller_id = ‘3111095611’) AND (fund_transfer_order_no = ‘99010015000805619031958363857’)); 阻塞 update fund_transfer_stream set gmt_modified = NOW(), state = ‘PROCESSING’ where ((state = ‘NEW’) AND (seller_id = ‘3111095611’) AND (fund_transfer_order_no = ‘99010015000805619031957477256’)); 死锁 我们知道，在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 主键索引的叶子节点存的是整行数据。在InnoDB中，主键索引也被称为聚簇索引（clustered index） 非主键索引的叶子节点的内容是主键的值，在InnoDB中，非主键索引也被称为非聚簇索引（secondary index） 所以，本文的示例中涉及到的索引结构（索引是B+树，简化成表格了）如图： 死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。那么接下来就看下上面的例子中两个事务的加锁顺序是怎样的： 下图是分解图，每一条SQL执行的时候加锁情况： 结合以上两张图，我们发现了导致死锁的原因： 事务1执行update1占用PRIMARY = 1的锁 ——&gt; 事务2执行update1 占有PRIMARY = 2的锁； 事务1执行update2占有idx_seller_transNo = (3111095611，99010015000805619031)的锁，尝试占有PRIMARY = 2锁失败（阻塞）； 事务2执行update2尝试占有idx_seller_transNo = (3111095611，99010015000805619031)的锁失败（死锁）； 事务在以非主键索引为where条件进行Update的时候，会先对该非主键索引加锁，然后再查询该非主键索引对应的主键索引都有哪些，再对这些主键索引进行加锁。） 解决方法至此，我们分析清楚了导致死锁的根本原理以及其背后的原理。那么这个问题解决起来就不难了。 可以从两方面入手，分别是修改索引和修改代码（包含SQL语句）。 修改索引：只要我们把前缀索引 idx_seller_transNo中fund_transfer_order_no的前缀长度修改下就可以了。比如改成50。即可避免死锁。 但是，改了idx_seller_transNo的前缀长度后，可以解决死锁的前提条件是update语句真正执行的时候，会用到fund_transfer_order_no索引。如果MySQL查询优化器在代价分析之后，决定使用索引 KEY idx_seller(seller_id)，那么还是会存在死锁问题。原理和本文类似。 所以，根本解决办法就是改代码： 12* 所有update都通过主键ID进行。* 在同一个事务中，避免出现多条update语句修改同一条记录。 总结与思考在死锁发生之后的一周内，我几乎每天都会抽空研究一会，问题早早的就定位到了，修改方案也有了，但是其中原理一直没搞清楚。 前前后后做过很多中种推断及假设，又都被自己一次次推翻。最终还是要靠实践来验证自己的想法。于是我自己在本地安装了数据库，实战的做了些测试，并实时查看数据库锁情况。show engine innodb status ;可以查看锁情况。最终才搞清楚原理。 简单说几点思考： 1、遇到问题，不要猜！！！亲手复现下问题，然后再来分析。 2、不要忽略上下文！！！我刚开始就是只关注死锁日志，一直忽略了代码中的事务其实还执行了另外一条SQL语句（updateFundStreamId）。 3、理论知识再充足，关键时刻不一定想的起来！！！ 4、坑都是自己埋的！！！ 参考资料：MySQL 加锁处理分析 innodb 事务隔离级别 《MySql实战45讲》 MySQL中的行级锁,表级锁,页级锁 查看原文","link":"/2019/06/25/一次数据库的死锁问题排查过程.html"},{"title":"博客图片上传picgo工具github图传使用","text":"摘要对于每一个写博客的人来说，图片是至关重要。这一路经历了多次图片的烦恼，之前选择了微博个人文章那里粘贴图片的方式上传，感觉也挺方便的。但是由于新浪的图片显示问题，如果header中不设置 标签就不能异步访问图片，导致图裂，那之恶心。然而设置之后又与网站访客统计的插件冲突，使之不能统计，真是神仙打架。无赖之下使用了PicGo工具，使用后感觉真XX方便！ PicGo工具下载安装配置下载 .PicGo下载 github网站提供三个版本的下载，MacOs、linux、windows覆盖市面上90%系统，还是很给力了。 我是mac用户，直接使用brew cask来安装PicGo: brew cask install picgo，简直方便到爆。 配置 PicGo配置(使用github图传，免费方便，同时配合github.io博客真是方便) 选上必填的就ok,一开始不知道token的设置，附赠token获取方法 图片上传相关的设置 链接格式：选择适合自己的，一般用户md文件中，选第一个，然后就可以疯狂使用了。 使用github图传，获取token在github-&gt;setting-&gt;developer settings 选择generate new token 勾选好之后生成就好了 使用 PicGo使用，简直方便 1).默认网页上直接右键复制图片 2).点击等待中的图片，开始上传 3).上传完之后有个提示，同时粘贴板也会自动粘贴上 4).直接粘贴到想要的地方 或者也可以直接截图，然后点击图片里的图片上传，很方便 PicGo上传动图gif 如果直接复制网页上的动图，去上传的话是截取的某帧，是静图。应该下载到本地，然后在拖进去上传就可以了。","link":"/2019/06/20/博客图片上传picgo工具github图传使用.html"},{"title":"阿里一年的成长经历","text":"摘要任何工作一定对个人都是有提升的，但是不会总结的人，在每个项目/需求中成长的东西都是散的，久而久之就忘了。通过充分的总结之后，犯过的错误我们不会二次再犯，理清楚的业务的来龙去脉铭记在心，对自己是一种提升，分享给别人对别人也是很大的帮助。失败者失败的原因各有不同，成功者的做事方式总是相似的，从宏观角度去看，我认为总结就是成功者之所以能成功，很重要一个原因。 应当如何面对线上的异常/故障看起来毫无意义的一个问题，碰到线上异常/故障如何面对，排查解决了不就好了，但是这真的只是第一层 最近在想“消防”这个词语很有意思，它其实是两层意思： “消”是消除问题 “防”是防止问题 即“消防”这个词语表达的意思应该是先消除问题再防止相同的问题再次发生。其实线上的异常/故障也是同样的道理，我们应当先及时止血，把问题处理掉，然后深挖问题，探究根因，举几个例子： 假设是某段代码的空指针异常导致的，那么是否考虑加强Code Review，或者使用findbugs插件去自动扫描代码中可能的异常？ 假设是线上某个配置修改导致的，那么是否今后变更的修改必须有人双重检查一遍才可以修改？ 假设是本地内存中某些值因为系统重启丢失导致的，那么是否引入定时任务，定时把值写入本地内存中？ 假设是某段代码逻辑没测试到导致的，那么是否可以反思总结为什么这段逻辑没有测试到，未来的测试应该如何改进？ 根据我过往的经验，太多公司、太多团队处理线上的问题仅仅满足于把问题处理完就完事，忽略了对问题的复盘，这对团队/对公司的发展都是不利的。 什么是真正的技术能力之前加了几个技术微信群，看到很多技术朋友在兴高采烈地讨论各种源码，spring源码我彻底撸了一遍、最近深入学习了dubbo底层实现方式，当然曾经的我也是这样的，记得学习volatile的时候一直挖到了volatile在硬件层面上的实现方式，但是这真的说明技术能力强吗？从今天的思考去看这个问题，我认为这更多反应的是一个人的学习能力、钻研能力以及对技术的热情，除此之外再体现不出太多其他东西了。 这个话题，可能是这一年思考的最多个的一个点，钻研是好事，但是实际上大多时候的深入钻研并不在实际工作中有用，且研究得越深，忘得越快，因为研究得越深，那么这个技术点关联的技术点就越多，边边角角的忘了，核心的东西不容易串起来。那么什么是真正的技术能力，我画一张图概括一下： 技术能力=解决问题的能力(解决当下问题+解决长远问题) 简而言之，技术能力 = 解决问题的能力，那么同样都在解决问题，大家之间的技术高低又有什么区分呢？我认为有以下几个层次： 第一层级，解决当下问题 第二层级，以优雅且可复用的方式解决当下问题 第三层级，解决的问题不仅仅能满足当下，还能满足未来一段时间 其实从这个角度上来看，不同的技术能力，在工作过程中区分度是很明显的： 写的代码是否存在异常风险，多线程运行下是否存在线程安全问题，某段代码是否会导致内存泄露 写的代码是否优雅可复用，设计的框架是否足够符合开闭原则，代码结构层次是否清晰明了 针对特定的场景，技术选型、库表结构设计是否足够合理，今天你设计的框架是只能用一年，还是未来三年五年都可以持续使用 来了一个大的需求，就比如做一个App的会员体系功能好了，是否可以在充分分析需求后，精确将需求划分为几个特定的子模块并梳理清楚模块之间的关系 越厉害的人，在代码设计与开发过程中，越能看到想到一些别人看不到想不到的问题，这叫做高屋建瓴；当代码运行出现问题的时候，有人1小时排查出问题，有人1分钟发现问题，这叫做举重若轻。 因此我认为解决问题的能力才是技术能力的真正体现，这一年对技术的探究我也从研究源码更多的转变去学习设计模式、去学习分布式环境下各种NoSql的选型对比、去学习使用Lambda让代码更简洁，往真正在实际工作中解决问题的方向去努力。 另外，抛开这个点，这两天我在思考，还有一个体现技术能力的点，就是学习能力。现实中的全栈是很少的，互联网这个行业的程序员的方向通常有几类： 服务端 前端 移动端 AI 嵌入式 大数据 在同一类中，基础知识、基本概念、思维方向是一致的，更多可能差异在开发工具、语言上，我精通Java，但是如果明天有一个需求，使用nodejs、scala、go更好，那么是否可以快速学习、快速上手？甚至明天有一个需求需要写前端代码，是否可以快速开发、无bug上线？ 所以，解决问题的能力 + 学习能力，是我认为真正的技术能力，不过说到底，学习能力某种程度上也只是为了解决问题而已。 不要造轮子曾几何时，当我们看着github上这么多优秀的源代码的时候，默默立誓，这辈子我一定要写出一个牛逼的框架，开源在网上。 曾几何时，公司招聘的时候，技术负责人激情满满地介绍着公司内部自研了多少系统并在线上投入使用。 很多对技术有追求的朋友，进入一家公司可能时时刻刻在寻找机会去做一些自己造轮子的事情，但是就如同前面所说的，衡量真正好技术的标准就是能否实实在在地解决问题，自己造轮子风险高、周期长，且需要长时间的验证、排坑才能达到比较好的效果。 随便举几个例子，在互联网发展的今天： 数据库连接池有dbcp、c3p0、druid 本地缓存有ehcache、要用中心缓存有redis、tail 服务化有dubbo、跨语言可以用thrift 分布式任务调度可以考虑schedulex 搜索可以选es、solr 更高级一点图片存储可以用七牛、im可以用融云/环信、音视频这块声网做得比较成熟，所有这些都提供了各个开发版本的sdk，接入简单 只要你有的技术方面的需求，绝大多数业界已经有了成熟的解决方案了，根本不需要去专门自己搞一套。因此我认为轻易一定不要造轮子，如果一定要造轮子，那么请想清楚下面几个问题： 你要做的事情是否当前已经有了类似解决方案？ 如果有，那么你自己做的这一套东西和类似解决方案的差异点在哪里？假设不用你这套，基于已有的解决方案稍加改造是否就能达到目的？ 如果没有，那么为什么之前没有？是你们公司这种场景是独一无二的？还是这种场景对应的解决方案根本就是不可行的所以之前没人去搞？ 如果想清楚了这些问题，那么就去干吧。 去提升看问题的高度过去有太多人在我的公众号或者博客下反馈了一个问题：在这个公司，整天做着增删改查的工作，对自己一点都没有提高。 对于这种看法，说难听点就是四个字—-目光短浅。我们看：如果以普通的视角去看，那么一颗树那也就只是一棵树而已，但是如果跳脱出目前的视角，站在更高的角度去看，它其实是森林的一部分。你的主管并不是因为他是你的主管所以他就应该你比更高瞻远瞩，而是因为他看问题的高度比你更高、想得更远、做得更深，所以才成为了你的主管。 把这个问题说得实际点： 假设今天你负责的是一个系统，那么你仅仅是把这个系统的基本原理搞懂了？还是可以把上下游有几个系统、每个系统之间如何调用、依赖方式都理顺？ 假设今天你负责的是一块业务，那么你仅仅把自己负责的功能点弄清楚了？还是你可以从最上游开始，到你负责的系统，再到最下游，都思考得非常透彻？ 今天与其在抱怨没有机会、抱怨公司对自己能力没有提升，为什么不去思考机会为什么降临在别人头上不降临在你头上？为什么别人可以从小公司写着一样的增删改查走向BAT而你年复一年还在小公司写着增删改查？当你真正能转变自己的思维模式，跳脱出现在的圈子往更高一个层次去看问题、去提升自己，我相信总会有发光发热的一天的。 同样在阿里巴巴，马老师思考自然、思考环保、思考人类的发展，你的主管思考团队未来的方向和打法，我们在思考如何把某个客户需求完整落地，这就是高度，你未必能想到马老师想的，但是你对标层级高一点的人，一步一步尝试往他们的高度去靠。 总而言之：眼界决定高度，多看、多想、多保持好奇心、多问几个为什么，久而久之自然就迈上了一个新的台阶。 学会总结需求、项目的复盘是非常重要的一部分内容，然而我之前见过的太多团队、太多Leader，只顾着一个迭代接着一个迭代，一个版本接着一个版本，只满足于把需求做好，而忽略了总结的重要性。 我认为大到项目、小到需求，如果在完成之后缺乏总结那么某种程度上来说是失败的，可以总结的点非常多： 通过这个项目/需求，是否吃透了某一块业务，搞懂了来龙去脉 通过这个项目/需求，是否充分理解了公司某个技术框架/基础组件的用法 在整个项目的设计上，有哪些做的不好的地方 在整个项目的开发（针对程序员而言），是否踩了坑，犯了低级的错误 在整个项目的进度把控上、人员安排上、上下游协调上，是否存在不足之处 经历了某次大促的值班，是否对可以熟练使用公司的监控工具，遇到突发事件，是否快速有效地进行了解决 任何工作一定对个人都是有提升的，但是不会总结的人，在每个项目/需求中成长的东西都是散的，久而久之就忘了。通过充分的总结之后，犯过的错误我们不会二次再犯，理清楚的业务的来龙去脉铭记在心，对自己是一种提升，分享给别人对别人也是很大的帮助。 失败者失败的原因各有不同，成功者的做事方式总是相似的，从宏观角度去看，我认为总结就是成功者之所以能成功，很重要一个原因。 参考资料","link":"/2019/06/13/阿里一年的成长经历.html"},{"title":"mysql数据库索引解析","text":"摘要看了很多关于索引的博客，讲的大同小异。但是始终没有让我明白关于索引的一些概念，如B-Tree索引，Hash索引，唯一索引….或许有很多人和我一样，没搞清楚概念就开始研究B-Tree，B+Tree等结构，导致在面试的时候答非所问！ 索引是什么?索引是帮助MySQL高效获取数据的数据结构。 索引能干什么?索引非常关键，尤其是当表中的数据量越来越大时，索引对于性能的影响愈发重要。 索引能够轻易将查询性能提高好几个数量级，总的来说就是可以明显的提高查询效率。 索引的分类? 从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。这里所描述的是索引存储时保存的形式， 从应用层次来分：普通索引，唯一索引，复合索引 根据中数据的物理顺序与键值的逻辑（索引）顺序关系：聚集索引，非聚集索引。 平时讲的索引类型一般是指在应用层次的划分。就像手机分类：安卓手机，IOS手机 与 华为手机，苹果手机，OPPO手机一样。 普通索引**：**即一个索引只包含单个列，一个表可以有多个单列索引 唯一索引：索引列的值必须唯一，但允许有空值 复合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 聚簇索引(聚集索引)：并不是一种单独的索引类型，而是一种数据存储方式。具体细节取决于不同的实现，InnoDB的聚簇索引其实就是在同一个结构中保存了B-Tree索引(技术上来说是B+Tree)和数据行。 非聚簇索引：不是聚簇索引，就是非聚簇索引 索引的底层实现mysql默认存储引擎innodb只显式支持B-Tree( 从技术上来说是B+Tree)索引，对于频繁访问的表，innodb会透明建立自适应hash索引，即在B树索引基础上建立hash索引，可以显著提高查找效率，对于客户端是透明的，不可控制的，隐式的。 不谈存储引擎，只讨论实现(抽象) Hash索引基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。 B-Tree索引（MySQL使用B+Tree）B-Tree能加快数据的访问速度，因为存储引擎不再需要进行全表扫描来获取数据，数据分布在各个节点之中。 B+Tree索引 是B-Tree的改进版本，同时也是数据库索引索引所采用的存储结构。数据都在叶子节点上，并且增加了顺序访问指针，每个叶子节点都指向相邻的叶子节点的地址。相比B-Tree来说，进行范围查找时只需要查找两个节点，进行遍历即可。而B-Tree需要获取所有节点，相比之下B+Tree效率更高。 结合存储引擎来讨论（一般默认使用B+Tree） 案例：假设有一张学生表，id为主键 id name birthday 1 Tom 1996-01-01 2 Jann 1996-01-04 3 Ray 1996-01-08 4 Michael 1996-01-10 5 Jack 1996-01-13 6 Steven 1996-01-23 7 Lily 1996-01-25 在MyISAM引擎中的实现（二级索引也是这样实现的） 在InnoDB中的实现 为什么索引结构默认使用B+Tree，而不是Hash，二叉树，红黑树？B+tree：因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低； Hash：虽然可以快速定位，但是没有顺序，IO复杂度高。 二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。 红黑树：树的高度随着数据量增加而增加，IO代价高。 红黑树: 每个节点或者是黑色，或者是红色。 根节点是黑色。 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！] 如果一个节点是红色的，则它的子节点必须是黑色的。 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。 为什么官方建议使用自增长主键作为索引？结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。 插入连续的数据： 插入非连续的数据 简单总结下 MySQL使用B+Tree作为索引数据结构。 B+Tree在新增数据时，会根据索引指定列的值对旧的B+Tree做调整。 从物理存储结构上说，B-Tree和B+Tree都以页(4K)来划分节点的大小，但是由于B+Tree中中间节点不存储数据，因此B+Tree能够在同样大小的节点中，存储更多的key，提高查找效率。 影响MySQL查找性能的主要还是磁盘IO次数，大部分是磁头移动到指定磁道的时间花费。 MyISAM存储引擎下索引和数据存储是分离的，InnoDB索引和数据存储在一起。 InnoDB存储引擎下索引的实现，(辅助索引)全部是依赖于主索引建立的(辅助索引中叶子结点存储的并不是数据的地址，还是主索引的值，因此，所有依赖于辅助索引的都是先根据辅助索引查到主索引，再根据主索引查数据的地址)。 由于InnoDB索引的特性，因此如果主索引不是自增的(id作主键)，那么每次插入新的数据，都很可能对B+Tree的主索引进行重整，影响性能。因此，尽量以自增id作为InnoDB的主索引。 InnoDB一棵B+树能存多少行数据？为什么要用B+树？而不是其他树？InnoDB一棵B+树可以存放多少行数据？这个问题的简单回答是：约2千万。为什么是这么多呢？因为这是可以算出来的，要搞清楚这个问题，我们先从InnoDB索引数据结构、数据组织方式说起。 我们都知道计算机在存储数据的时候，有最小存储单元，这就好比我们今天进行现金的流通最小单位是一毛。在计算机中磁盘存储数据最小单元是扇区，一个扇区的大小是512字节，而文件系统（例如XFS/EXT4）他的最小单元是块，一个块的大小是4k，而对于我们的InnoDB存储引擎也有自己的最小储存单元——页（Page），一个页的大小是16K。 innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是16384（16k）的整数倍。 磁盘扇区、文件系统、InnoDB存储引擎都有各自的最小存储单元。 在MySQL中我们的InnoDB页的大小默认是16k，当然也可以通过参数设置： 12345678mysql&gt; show variables like &apos;innodb_page_size&apos;;+------------------+-------+| Variable_name| Value|+------------------+-------+| innodb_page_size | 16384|+------------------+-------+1 row in set(0.00sec) 数据表中的数据都是存储在页中的，所以一个页中能存储多少行数据呢？假设一行数据的大小是1k，那么一个页可以存放16行这样的数据。 如果数据库只按这样的方式存储，那么如何查找数据就成为一个问题，因为我们不知道要查找的数据存在哪个页中，也不可能把所有的页遍历一遍，那样太慢了。所以人们想了一个办法，用B+树的方式组织这些数据。如图所示： 我们先将数据记录按主键进行排序，分别存放在不同的页中（为了便于理解我们这里一个页中只存放3条记录，实际情况可以存放很多），除了存放数据的页以外，还有存放键值+指针的页，如图中page number=3的页，该页存放键值和指向数据页的指针，这样的页由N个键值+指针组成。当然它也是排好序的。这样的数据组织形式，我们称为索引组织表。现在来看下，要查找一条数据，怎么查？ 如select * from user where id=5; 这里id是主键,我们通过这棵B+树来查找，首先找到根页，你怎么知道user表的根页在哪呢？其实每张表的根页位置在表空间文件中是固定的，即page number=3的页（这点我们下文还会进一步证明），找到根页后通过二分查找法，定位到id=5的数据应该在指针P5指向的页中，那么进一步去page number=5的页中查找，同样通过二分查询法即可找到id=5的记录： | 5 | zhao2 | 27 | 现在我们清楚了InnoDB中主键索引B+树是如何组织数据、查询数据的，我们总结一下： 1、InnoDB存储引擎的最小存储单元是页，页可以用于存放数据也可以用于存放键值+指针，在B+树中叶子节点存放数据，非叶子节点存放键值+指针。 2、索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而在去数据页中查找到需要的数据； 那么回到我们开始的问题，通常一棵B+树可以存放多少行数据？这里我们先假设B+树高为2，即存在一个根节点和若干个叶子节点，那么这棵B+树的存放总记录数为：根节点指针数*单个叶子节点记录行数。 上文我们已经说明单个叶子节点（页）中的记录数=16K/1K=16。（这里假设一行记录的数据大小为1k，实际上现在很多互联网业务数据记录大小通常就是1K左右）。 那么现在我们需要计算出非叶子节点能存放多少指针？ 其实这也很好算，我们假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，这样一共14字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即16384/14=1170。那么可以算出一棵高度为2的B+树，能存放1170*16=18720条这样的数据记录。 根据同样的原理我们可以算出一个高度为3的B+树可以存放：1170*1170*16=21902400条这样的记录。 所以在InnoDB中B+树高度一般为1-3层，它就能满足千万级的数据存储。在查找数据时一次页的查找代表一次IO，所以通过主键索引查询通常只需要1-3次IO操作即可查找到数据。 怎么得到InnoDB主键索引B+树的高度？上面我们通过推断得出B+树的高度通常是1-3，下面我们从另外一个侧面证明这个结论。在InnoDB的表空间文件中，约定page number为3的代表主键索引的根页，而在根页偏移量为64的地方存放了该B+树的page level。如果page level为1，树高为2，page level为2，则树高为3。即B+树的高度=page level+1；下面我们将从实际环境中尝试找到这个page level。 在实际操作之前，你可以通过InnoDB元数据表确认主键索引根页的page number为3，你也可以从《InnoDB存储引擎》这本书中得到确认。 1234567SELECTb.name, a.name, index_id, type, a.space, a.PAGE_NOFROMinformation_schema.INNODB_SYS_INDEXES a,information_schema.INNODB_SYS_TABLES bWHEREa.table_id = b.table_id AND a.space &lt;&gt; 0; 执行结果： 可以看出数据库dbt3下的customer表、lineitem表主键索引根页的page number均为3，而其他的二级索引page number为4。关于二级索引与主键索引的区别请参考MySQL相关书籍，本文不在此介绍。 下面我们对数据库表空间文件做想相关的解析： 因为主键索引B+树的根页在整个表空间文件中的第3个页开始，所以可以算出它在文件中的偏移量：16384*3=49152（16384为页大小）。 另外根据《InnoDB存储引擎》中描述在根页的64偏移量位置前2个字节，保存了page level的值，因此我们想要的page level的值在整个文件中的偏移量为：16384*3+64=49152+64=49216，前2个字节中。 接下来我们用hexdump工具，查看表空间文件指定偏移量上的数据： linetem表的page level为2，B+树高度为page level+1=3；**region表的page level为0，B+树高度为page level+1=1；**customer表的page level为2，B+树高度为page level+1=3； 这三张表的数据量如下： 小结lineitem表的数据行数为600多万，B+树高度为3，customer表数据行数只有15万，B+树高度也为3。可以看出尽管数据量差异较大，这两个表树的高度都是3，换句话说这两个表通过索引查询效率并没有太大差异，因为都只需要做3次IO。那么如果有一张表行数是一千万，那么他的B+树高度依旧是3，查询效率仍然不会相差太大。 region表只有5行数据，当然他的B+树高度为1。 最后回顾一道面试题有一道MySQL的面试题，为什么MySQL的索引要使用B+树而不是其它树形结构？比如B树？ 现在这个问题的复杂版本可以参考本文； 他的简单版本回答是： 因为B树不管叶子节点还是非叶子节点，都会保存数据，这样导致在非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致IO操作变多，查询性能变低； 总结本文从一个问题出发，逐步介绍了InnoDB索引组织表的原理、查询方式，并结合已有知识，回答该问题，结合实践来证明。当然为了表述简单易懂，文中忽略了一些细枝末节，比如一个页中不可能所有空间都用于存放数据，它还会存放一些少量的其他字段比如page level，index number等等，另外还有页的填充因子也导致一个页不可能全部用于保存数据。关于二级索引数据存取方式可以参考MySQL相关书籍，他的要点是结合主键索引进行回表查询。参考参考","link":"/2019/06/04/mysql数据库索引解析.html"},{"title":"java注解Annotation说明实例","text":"摘要Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。 什么是注解？对于很多初次接触的开发者来说应该都有这个疑问？Annontation是Java5开始引入的新特征，中文名称叫注解。它提供了一种安全的类似注释的机制，用来将任何的信息或元数据（metadata）与程序元素（类、方法、成员变量等）进行关联。为程序的元素（类、方法、成员变量）加上更直观更明了的说明，这些说明信息是与程序的业务逻辑无关，并且供指定的工具或框架使用。Annontation像一种修饰符一样，应用于包、类型、构造方法、方法、成员变量、参数及本地变量的声明语句中。 Java注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。包含在 java.lang.annotation 包中。 注解的用处 生成文档。这是最常见的，也是java 最早提供的注解。常用的有@param @return 等 跟踪代码依赖性，实现替代配置文件功能。比如Dagger 2 依赖注入，未来java 开发，将大量注解配置，具有很大用处; 在编译时进行格式检查。如@override 放在方法前，如果你这个方法并不是覆盖了超类方法，则编译时就能检查出。 注解原理注解本质是一个继承了Annotation 的特殊接口，其具体实现类是Java 运行时生成的动态代理类。而我们通过反射获取注解时，返回的是Java 运行时生成的动态代理对象$Proxy1。通过代理对象调用自定义注解（接口）的方法，会最终调用AnnotationInvocationHandler 的invoke 方法。该方法会从memberValues 这个Map 中索引出对应的值。而memberValues 的来源是Java 常量池。 元注解java.lang.annotation 提供了四种元注解，专门注解其他的注解（在自定义注解的时候，需要使用到元注解）： @Documented – 注解是否将包含在JavaDoc中 @Retention – 什么时候使用该注解 @Target – 注解用于什么地方 @Inherited – 是否允许子类继承该注解 @Retention 定义该注解的生命周期 ● RetentionPolicy.SOURCE : 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。 ● RetentionPolicy.CLASS : 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式 ● RetentionPolicy.RUNTIME : 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。 @Target 表示该注解用于什么地方。默认值为任何元素，表示该注解用于什么地方。可用的ElementType 参数包括 ● ElementType.CONSTRUCTOR: 用于描述构造器 ● ElementType.FIELD: 成员变量、对象、属性（包括enum实例） ● ElementType.LOCAL_VARIABLE: 用于描述局部变量 ● ElementType.METHOD: 用于描述方法 ● ElementType.PACKAGE: 用于描述包 ● ElementType.PARAMETER: 用于描述参数 ● ElementType.TYPE: 用于描述类、接口(包括注解类型) 或enum声明 @Documented 一个简单的Annotations 标记注解，表示是否将注解信息添加在java 文档中。 @Inherited 定义该注释和子类的关系@Inherited 元注解是一个标记注解，@Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited 修饰的annotation 类型被用于一个class，则这个annotation 将被用于该class 的子类。 常见标准的Annotation Overridejava.lang.Override 是一个标记类型注解，它被用作标注方法。它说明了被标注的方法重载了父类的方法，起到了断言的作用。如果我们使用了这种注解在一个没有覆盖父类方法的方法时，java 编译器将以一个编译错误来警示 DeprecatedDeprecated 也是一种标记类型注解。当一个类型或者类型成员使用@Deprecated 修饰的话，编译器将不鼓励使用这个被标注的程序元素。所以使用这种修饰具有一定的“延续性”：如果我们在代码中通过继承或者覆盖的方式使用了这个过时的类型或者成员，虽然继承或者覆盖后的类型或者成员并不是被声明为@Deprecated，但编译器仍然要报警。 SuppressWarningsSuppressWarning 不是一个标记类型注解。它有一个类型为String[] 的成员，这个成员的值为被禁止的警告名。对于javac 编译器来讲，被-Xlint 选项有效的警告名也同样对@SuppressWarings 有效，同时编译器忽略掉无法识别的警告名。 @SuppressWarnings(“unchecked”) 自定义注解自定义注解类编写的一些规则: Annotation 型定义为@interface, 所有的Annotation 会自动继承java.lang.Annotation这一接口,并且不能再去继承别的类或是接口. 参数成员只能用public 或默认(default) 这两个访问权修饰 参数成员只能用基本类型byte、short、char、int、long、float、double、boolean八种基本数据类型和String、Enum、Class、annotations等数据类型，以及这一些类型的数组. 要获取类方法和字段的注解信息，必须通过Java的反射技术来获取 Annotation 对象，因为你除此之外没有别的获取注解对象的方法 注解也可以没有定义成员,，不过这样注解就没啥用了PS:自定义注解需要使用到元注解 实例FruitName.java 123456789101112131415import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果名称注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitName { String value() default \"\";} FruitColor.java 123456789101112131415161718192021222324import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果颜色注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitColor { /** * 颜色枚举 */ public enum Color{ BLUE,RED,GREEN}; /** * 颜色属性 */ Color fruitColor() default Color.GREEN;} FruitProvider.java 12345678910111213141516171819202122232425262728import java.lang.annotation.Documented;import java.lang.annotation.Retention;import java.lang.annotation.Target;import static java.lang.annotation.ElementType.FIELD;import static java.lang.annotation.RetentionPolicy.RUNTIME;/** * 水果供应者注解 */@Target(FIELD)@Retention(RUNTIME)@Documentedpublic @interface FruitProvider { /** * 供应商编号 */ public int id() default -1; /** * 供应商名称 */ public String name() default \"\"; /** * 供应商地址 */ public String address() default \"\";} FruitInfoUtil.java 1234567891011121314151617181920212223242526272829303132import java.lang.reflect.Field;/** * 注解处理器 */public class FruitInfoUtil { public static void getFruitInfo(Class&lt;?&gt; clazz){ String strFruitName=\" 水果名称：\"; String strFruitColor=\" 水果颜色：\"; String strFruitProvicer=\"供应商信息：\"; Field[] fields = clazz.getDeclaredFields(); for(Field field :fields){ if(field.isAnnotationPresent(FruitName.class)){ FruitName fruitName = (FruitName) field.getAnnotation(FruitName.class); strFruitName=strFruitName+fruitName.value(); System.out.println(strFruitName); } else if(field.isAnnotationPresent(FruitColor.class)){ FruitColor fruitColor= (FruitColor) field.getAnnotation(FruitColor.class); strFruitColor=strFruitColor+fruitColor.fruitColor().toString(); System.out.println(strFruitColor); } else if(field.isAnnotationPresent(FruitProvider.class)){ FruitProvider fruitProvider= (FruitProvider) field.getAnnotation(FruitProvider.class); strFruitProvicer=\" 供应商编号：\"+fruitProvider.id()+\" 供应商名称：\"+fruitProvider.name()+\" 供应商地址：\"+fruitProvider.address(); System.out.println(strFruitProvicer); } } }} Apple.java 1234567891011121314151617181920212223242526272829303132333435363738394041import test.FruitColor.Color;/** * 注解使用 */public class Apple { @FruitName(\"Apple\") private String appleName; @FruitColor(fruitColor=Color.RED) private String appleColor; @FruitProvider(id=1,name=\"陕西红富士集团\",address=\"陕西省西安市延安路89号红富士大厦\") private String appleProvider; public void setAppleColor(String appleColor) { this.appleColor = appleColor; } public String getAppleColor() { return appleColor; } public void setAppleName(String appleName) { this.appleName = appleName; } public String getAppleName() { return appleName; } public void setAppleProvider(String appleProvider) { this.appleProvider = appleProvider; } public String getAppleProvider() { return appleProvider; } public void displayName(){ System.out.println(\"水果的名字是：苹果\"); }} FruitRun.java 12345678/** * 输出结果 */public class FruitRun { public static void main(String[] args) { FruitInfoUtil.getFruitInfo(Apple.class); }} 运行结果： 123水果名称：Apple水果颜色：RED供应商编号：1 供应商名称：陕西红富士集团 供应商地址：陕西省西安市延安路89号红富士大厦 参考资料","link":"/2019/05/31/java注解Annotation说明实例.html"},{"title":"elasticsearch6.x倒排索引和分词","text":"摘要倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。 倒排索引（Inverted Index）也叫反向索引，有反向索引必有正向索引。通俗地来讲，正向索引是通过key找value，反向索引则是通过value找key。 倒排索引 正排索引：文档id到单词的关联关系 倒排索引：单词到文档id的关联关系 示例：对以下三个文档去除停用词后构造倒排索引 倒排索引-查询过程查询包含“搜索引擎”的文档 通过倒排索引获得“搜索引擎”对应的文档id列表，有1，3 通过正排索引查询1和3的完整内容 返回最终结果 倒排索引-组成 单词词典（Term Dictionary） 倒排列表（Posting List） 单词词典（Term Dictionary）单词词典的实现一般用B+树，B+树构造的可视化过程网址: B+ Tree Visualization 关于B树和B+树 维基百科-B树 维基百科-B+树 B树和B+树的插入、删除图文详解 倒排列表（Posting List） 倒排列表记录了单词对应的文档集合，有倒排索引项（Posting）组成 倒排索引项主要包含如下信息： 文档id用于获取原始信息 单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分 位置（Posting），记录单词在文档中的分词位置（多个），用于做词语搜索（Phrase Query） 偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示 B+树内部结点存索引，叶子结点存数据，这里的 单词词典就是B+树索引，倒排列表就是数据，整合在一起后如下所示 ES存储的是一个JSON格式的文档，其中包含多个字段，每个字段会有自己的倒排索引 分词分词是将文本转换成一系列单词（Term or Token）的过程，也可以叫文本分析，在ES里面称为Analysis 分词器分词器是ES中专门处理分词的组件，英文为Analyzer，它的组成如下： Character Filters：针对原始文本进行处理，比如去除html标签 Tokenizer：将原始文本按照一定规则切分为单词 Token Filters：针对Tokenizer处理的单词进行再加工，比如转小写、删除或增新等处理 分词器调用顺序 Analyze APIES提供了一个可以测试分词的API接口，方便验证分词效果，endpoint是_analyze 可以直接指定analyzer进行测试 可以直接指定索引中的字段进行测试 1234567891011POST test_index/doc{ \"username\": \"whirly\", \"age\":22}POST test_index/_analyze{ \"field\": \"username\", \"text\": [\"hello world\"]} 可以自定义分词器进行测试 123456POST _analyze{ &quot;tokenizer&quot;: &quot;standard&quot;, &quot;filter&quot;: [&quot;lowercase&quot;], &quot;text&quot;: [&quot;Hello World&quot;]} 预定义的分词器ES自带的分词器有如下： Standard Analyzer 默认分词器 按词切分，支持多语言 小写处理 Simple Analyzer 按照非字母切分 小写处理 Whitespace Analyzer 空白字符作为分隔符 Stop Analyzer 相比Simple Analyzer多了去除请用词处理 停用词指语气助词等修饰性词语，如the, an, 的， 这等 Keyword Analyzer 不分词，直接将输入作为一个单词输出 Pattern Analyzer 通过正则表达式自定义分隔符 默认是\\W+，即非字词的符号作为分隔符 Language Analyzer 提供了30+种常见语言的分词器 示例：停用词分词器 12345POST _analyze{ \"analyzer\": \"stop\", \"text\": [\"The 2 QUICK Brown Foxes jumped over the lazy dog's bone.\"]} 结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667{ \"tokens\": [ { \"token\": \"quick\", \"start_offset\": 6, \"end_offset\": 11, \"type\": \"word\", \"position\": 1 }, { \"token\": \"brown\", \"start_offset\": 12, \"end_offset\": 17, \"type\": \"word\", \"position\": 2 }, { \"token\": \"foxes\", \"start_offset\": 18, \"end_offset\": 23, \"type\": \"word\", \"position\": 3 }, { \"token\": \"jumped\", \"start_offset\": 24, \"end_offset\": 30, \"type\": \"word\", \"position\": 4 }, { \"token\": \"over\", \"start_offset\": 31, \"end_offset\": 35, \"type\": \"word\", \"position\": 5 }, { \"token\": \"lazy\", \"start_offset\": 40, \"end_offset\": 44, \"type\": \"word\", \"position\": 7 }, { \"token\": \"dog\", \"start_offset\": 45, \"end_offset\": 48, \"type\": \"word\", \"position\": 8 }, { \"token\": \"s\", \"start_offset\": 49, \"end_offset\": 50, \"type\": \"word\", \"position\": 9 }, { \"token\": \"bone\", \"start_offset\": 51, \"end_offset\": 55, \"type\": \"word\", \"position\": 10 } ]} 中文分词 难点 中文分词指的是将一个汉字序列切分为一个一个的单独的词。在英文中，单词之间以空格作为自然分界词，汉语中词没有一个形式上的分界符 上下文不同，分词结果迥异，比如交叉歧义问题 常见分词系统 IK：实现中英文单词的切分，可自定义词库，支持热更新分词词典 jieba：支持分词和词性标注，支持繁体分词，自定义词典，并行分词等 Hanlp：由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用 THUAC：中文分词和词性标注 安装ik中文分词插件12345# 在Elasticsearch安装目录下执行命令，然后重启esbin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip# 如果由于网络慢，安装失败，可以先下载好zip压缩包，将下面命令改为实际的路径，执行，然后重启esbin/elasticsearch-plugin install file:///path/to/elasticsearch-analysis-ik-6.3.0.zip ik测试 - ik_smart 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667POST _analyze{ \"analyzer\": \"ik_smart\", \"text\": [\"公安部：各地校车将享最高路权\"]}# 结果{ \"tokens\": [ { \"token\": \"公安部\", \"start_offset\": 0, \"end_offset\": 3, \"type\": \"CN_WORD\", \"position\": 0 }, { \"token\": \"各地\", \"start_offset\": 4, \"end_offset\": 6, \"type\": \"CN_WORD\", \"position\": 1 }, { \"token\": \"校车\", \"start_offset\": 6, \"end_offset\": 8, \"type\": \"CN_WORD\", \"position\": 2 }, { \"token\": \"将\", \"start_offset\": 8, \"end_offset\": 9, \"type\": \"CN_CHAR\", \"position\": 3 }, { \"token\": \"享\", \"start_offset\": 9, \"end_offset\": 10, \"type\": \"CN_CHAR\", \"position\": 4 }, { \"token\": \"最高\", \"start_offset\": 10, \"end_offset\": 12, \"type\": \"CN_WORD\", \"position\": 5 }, { \"token\": \"路\", \"start_offset\": 12, \"end_offset\": 13, \"type\": \"CN_CHAR\", \"position\": 6 }, { \"token\": \"权\", \"start_offset\": 13, \"end_offset\": 14, \"type\": \"CN_CHAR\", \"position\": 7 } ]} ik测试 - ik_max_word 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081POST _analyze{ \"analyzer\": \"ik_max_word\", \"text\": [\"公安部：各地校车将享最高路权\"]}# 结果{ \"tokens\": [ { \"token\": \"公安部\", \"start_offset\": 0, \"end_offset\": 3, \"type\": \"CN_WORD\", \"position\": 0 }, { \"token\": \"公安\", \"start_offset\": 0, \"end_offset\": 2, \"type\": \"CN_WORD\", \"position\": 1 }, { \"token\": \"部\", \"start_offset\": 2, \"end_offset\": 3, \"type\": \"CN_CHAR\", \"position\": 2 }, { \"token\": \"各地\", \"start_offset\": 4, \"end_offset\": 6, \"type\": \"CN_WORD\", \"position\": 3 }, { \"token\": \"校车\", \"start_offset\": 6, \"end_offset\": 8, \"type\": \"CN_WORD\", \"position\": 4 }, { \"token\": \"将\", \"start_offset\": 8, \"end_offset\": 9, \"type\": \"CN_CHAR\", \"position\": 5 }, { \"token\": \"享\", \"start_offset\": 9, \"end_offset\": 10, \"type\": \"CN_CHAR\", \"position\": 6 }, { \"token\": \"最高\", \"start_offset\": 10, \"end_offset\": 12, \"type\": \"CN_WORD\", \"position\": 7 }, { \"token\": \"路\", \"start_offset\": 12, \"end_offset\": 13, \"type\": \"CN_CHAR\", \"position\": 8 }, { \"token\": \"权\", \"start_offset\": 13, \"end_offset\": 14, \"type\": \"CN_CHAR\", \"position\": 9 } ]} ik两种分词模式ik_max_word 和 ik_smart 什么区别? ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合； ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。 自定义分词当自带的分词无法满足需求时，可以自定义分词，通过定义Character Filters、Tokenizer和Token Filters实现 Character Filters 在Tokenizer之前对原始文本进行处理，比如增加、删除或替换字符等 自带的如下: HTML Strip Character Filter：去除HTML标签和转换HTML实体 Mapping Character Filter：进行字符替换操作 Pattern Replace Character Filter：进行正则匹配替换 会影响后续tokenizer解析的position和offset信息 Character Filters测试1234567891011121314151617181920212223POST _analyze{ \"tokenizer\": \"keyword\", \"char_filter\": [\"html_strip\"], \"text\": [\"&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;\"]}# 结果{ \"tokens\": [ { \"token\": \"\"\"I'm so happy!\"\"\", \"start_offset\": 0, \"end_offset\": 32, \"type\": \"word\", \"position\": 0 } ]} Tokenizers 将原始文本按照一定规则切分为单词（term or token） 自带的如下： standard 按照单词进行分割 letter 按照非字符类进行分割 whitespace 按照空格进行分割 UAX URL Email 按照standard进行分割，但不会分割邮箱和URL Ngram 和 Edge NGram 连词分割 Path Hierarchy 按照文件路径进行分割 Tokenizers 测试1234567891011121314151617181920212223242526272829303132POST _analyze{ \"tokenizer\": \"path_hierarchy\", \"text\": [\"/path/to/file\"]}# 结果{ \"tokens\": [ { \"token\": \"/path\", \"start_offset\": 0, \"end_offset\": 5, \"type\": \"word\", \"position\": 0 }, { \"token\": \"/path/to\", \"start_offset\": 0, \"end_offset\": 8, \"type\": \"word\", \"position\": 0 }, { \"token\": \"/path/to/file\", \"start_offset\": 0, \"end_offset\": 13, \"type\": \"word\", \"position\": 0 } ]} Token Filters 对于tokenizer输出的单词（term）进行增加、删除、修改等操作 自带的如下： lowercase 将所有term转为小写 stop 删除停用词 Ngram 和 Edge NGram 连词分割 Synonym 添加近义词的term Token Filters测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950POST _analyze{ \"text\": [ \"a Hello World!\" ], \"tokenizer\": \"standard\", \"filter\": [ \"stop\", \"lowercase\", { \"type\": \"ngram\", \"min_gram\": 4, \"max_gram\": 4 } ]}# 结果{ \"tokens\": [ { \"token\": \"hell\", \"start_offset\": 2, \"end_offset\": 7, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"ello\", \"start_offset\": 2, \"end_offset\": 7, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"worl\", \"start_offset\": 8, \"end_offset\": 13, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 }, { \"token\": \"orld\", \"start_offset\": 8, \"end_offset\": 13, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 } ]} 自定义分词自定义分词需要在索引配置中设定 char_filter、tokenizer、filter、analyzer等 自定义分词示例: 分词器名称：my_custom\\ 过滤器将token转为大写 1234567891011121314151617181920PUT test_index_1{ \"settings\": { \"analysis\": { \"analyzer\": { \"my_custom_analyzer\": { \"type\": \"custom\", \"tokenizer\": \"standard\", \"char_filter\": [ \"html_strip\" ], \"filter\": [ \"uppercase\", \"asciifolding\" ] } } } }} 12345678910111213141516171819202122232425262728293031323334353637383940// javaXContentFactory.jsonBuilder() .startObject().startObject(\"analysis\") .startObject(\"normalizer\").startObject(Normalizers.CASE_INSENSITIVE) .field(\"type\", \"custom\") .field(\"filter\", \"lowercase\") .endObject().endObject() // 动态同义词 .startObject(\"filter\") .startObject(\"dynamic_synonym\").field(\"type\", \"dynamic_synonym\").field(\"tokenizer\", \"ik_smart\").endObject().endObject() .startObject(\"analyzer\") // 自定义分词器 .startObject(\"ik\") .field(\"filter\", \"\") .field(\"char_filter\", Arrays.asList(\"char_mapper\")) .field(\"type\", \"custom\") .field(\"tokenizer\", \"ik_max_word\") .endObject() // 搜索时处理同义词 .startObject(\"ikt\") .field(\"filter\", Arrays.asList(\"dynamic_synonym\")) .field(\"char_filter\", Arrays.asList(\"char_mapper\")) .field(\"type\", \"custom\") .field(\"tokenizer\", \"ik_smart\") .endObject() .endObject() // 自定义字符过滤 .startObject(\"char_filter\") .startObject(\"char_mapper\") .field(\"type\", \"mapping\") .field(\"mappings_path\", \"analysis/mapping.txt\") .endObject() .endObject() .endObject().endObject(); 自定义分词器测试1234567891011121314151617181920212223242526272829303132POST test_index_1/_analyze{ \"analyzer\": \"my_custom_analyzer\", \"text\": [\"&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;\"]}# 结果{ \"tokens\": [ { \"token\": \"I'M\", \"start_offset\": 3, \"end_offset\": 11, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 0 }, { \"token\": \"SO\", \"start_offset\": 12, \"end_offset\": 14, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 1 }, { \"token\": \"HAPPY\", \"start_offset\": 18, \"end_offset\": 27, \"type\": \"&lt;ALPHANUM&gt;\", \"position\": 2 } ]} 分词使用说明分词会在如下两个时机使用： 创建或更新文档时(Index Time)，会对相应的文档进行分词处理 查询时（Search Time），会对查询语句进行分词 查询时通过analyzer指定分词器 通过index mapping设置search_analyzer实现 一般不需要特别指定查询时分词器，直接使用索引分词器即可，否则会出现无法匹配的情况 分词使用建议 明确字段是否需要分词，不需要分词的字段就将type设置为keyword，可以节省空间和提高写性能 善用_analyze API，查看文档的分词结果 参考自","link":"/2019/05/06/elasticsearch6-x倒排索引和分词.html"},{"title":"Java版常用正则表达式说明","text":"摘要正则表达式在几乎所有语言中都可以使用，无论是前端的JavaScript、还是后端的Java、c#。他们都提供相应的接口/函数支持正则表达式。 元字符元字符说明：匹配除换行符以外的任意字符 w：匹配字母或数字或下划线或汉字 s：匹配任意的空白符 d：匹配数字匹配单词的开始或结束 ^：匹配字符串的开始 $：匹配字符串的结束 eg:匹配有abc开头的字符串：abc或者^abc 匹配8位数字的QQ号码：^dddddddd$ 匹配1开头11位数字的手机号码：^1dddddddddd$ 重复限定符为了处理这些重复问题，正则表达式中一些重复限定符，把重复部分用合适的限定符替代 语法说明： *重复零次或更多次 +重复一次或更多次 ?重复零次或一次 {n}重复n次 {n,}重复n次或更多次 {n,m}重复n到m次 匹配8位数字的QQ号码：^d{8}$ 匹配1开头11位数字的手机号码：^1d{10}$ 匹配银行卡号是14~18位的数字：^d{14,18}$ 匹配以a开头的，0个或多个b结尾的字符串^ab*$ 分组正则表达式中用小括号()来做分组，也就是括号中的内容作为一个整体。 因此当我们要匹配多个ab时，我们可以这样。 如匹配字符串中包含0到多个ab开头：^(ab)* 转义我们看到正则表达式用小括号来做分组，那么问题来了： 如果要匹配的字符串中本身就包含小括号，那是不是冲突？应该怎么办？ 针对这种情况，正则提供了转义的方式，也就是要把这些元字符、限定符或者关键字转义成普通的字符，做法很简答，就是在要转义的字符前面加个斜杠，也就是\\即可。 如要匹配以(ab)开头：^\\(ab\\)* 条件或回到我们刚才的手机号匹配，我们都知道：国内号码都来自三大网，它们都有属于自己的号段，比如联通有130/131/132/155/156/185/186/145/176等号段，假如让我们匹配一个联通的号码，那按照我们目前所学到的正则，应该无从下手的，因为这里包含了一些并列的条件，也就是“或”，那么在正则中是如何表示“或”的呢？ 正则用符号 | 来表示或，也叫做分支条件，当满足正则里的分支条件的任何一种条件时，都会当成是匹配成功。 那么我们就可以用“或”条件来处理这个问题：^(130|131|132|155|156|185|186|145|176)d{8}$ 区间正则提供一个元字符中括号 [] 来表示区间条件。 限定0到9 可以写成[0-9] 限定A-Z 写成[A-Z] 限定某些数字 [165] 那上面的正则我们还改成这样： ^((13[0-2])|(15[56])|(18[5-6])|145|176)d{8}$ 好了，正则表达式的基本用法就讲到这里了，其实它还有非常多的知识点以及元字符，我们在此只列举了部分元字符和语法来讲，旨在给那些不懂正则或者想学正则但有看不下去文档的人做一个快速入门级的教程，看完本教程，即使你不能写出高大上的正则，至少也能写一些简单的正则或者看得懂别人写的正则了。 正则进阶知识点1.零宽断言断言：俗话的断言就是“我断定什么什么”，而正则中的断言，就是说正则可以指明在指定的内容的前面或后面会出现满足指定规则的内容，意思正则也可以像人类那样断定什么什么，比如”ss1aa2bb3”,正则可以用断言找出aa2前面有bb3，也可以找出aa2后面有ss1. 零宽：就是没有宽度，在正则中，断言只是匹配位置，不占字符，也就是说，匹配结果里是不会返回断言本身。 eg:假设我们要用爬虫抓取csdn里的文章阅读量。通过查看源代码可以看到文章阅读量这个内容是这样的结构 “阅读数：641“ 其中也就‘641’这个是变量，也就是说不同文章不同的值，当我们拿到这个字符串时，需要获得这里边的‘641’有很多种办法，但如果正则应该怎么匹配呢？ 正向先行断言（正前瞻）语法：（?=pattern） 作用：匹配pattern表达式的前面内容，不返回本身。 这样子说，还是一脸懵逼，好吧，回归刚才那个栗子，要取到阅读量，在正则表达式中就意味着要能匹配到‘’前面的数字内容。 按照上所说的正向先行断言可以匹配表达式前面的内容，那意思就是:(?=) 就可以匹配到前面的内容了。 匹配什么内容呢？如果要所有内容那就是： 12345678910 String reg=\".+(?=&lt;/span&gt;)\";String test = \"&lt;span class=\"read-count\"&gt;阅读数：641&lt;/span&gt;\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); while(mc.find()){ System.out.println(\"匹配结果：\") System.out.println(mc.group()); } //匹配结果：//&lt;span class=\"read-count\"&gt;阅读数：641 可是老哥我们要的只是前面的数字呀，那也简单咯，匹配数字 d,那可以改成： 123456789String reg=\"\\d+(?=&lt;/span&gt;)\";String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);while(mc.find()){ System.out.println(mc.group());}//匹配结果：//641 大功告成！ 正向后行断言（正后顾）语法：（?&lt;=pattern） 作用：匹配pattern表达式的后面的内容，不返回本身。 有先行就有后行，先行是匹配前面的内容，那后行就是匹配后面的内容啦。 上面的栗子，我们也可以用后行断言来处理。 12345678910//(?&lt;=&lt;span class=\"read-count\"&gt;阅读数：)d+String reg=\"(?&lt;=&lt;span class=\\\"read-count\\\"&gt;阅读数：)\\d+\";String test = \"&lt;span class=\\\"read-count\\\"&gt;阅读数：641&lt;/span&gt;\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); while(mc.find()){ System.out.println(mc.group()); }//匹配结果：//641 就这么简单。 负向先行断言（负前瞻）语法：(?!pattern) 作用：匹配非pattern表达式的前面内容，不返回本身。 有正向也有负向，负向在这里其实就是非的意思。 举个栗子：比如有一句 “我爱祖国，我是祖国的花朵” 现在要找到不是’的花朵’前面的祖国 用正则就可以这样写：祖国(?!的花朵)。 负向后行断言（负后顾）语法：(?&lt;!pattern) 作用：匹配非pattern表达式的后面内容，不返回本身。 2.捕获和非捕获单纯说到捕获，他的意思是匹配表达式，但捕获通常和分组联系在一起，也就是“捕获组”。 捕获组：匹配子表达式的内容，把匹配结果保存到内存中中数字编号或显示命名的组里，以深度优先进行编号，之后可以通过序号或名称来使用这些匹配结果。 而根据命名方式的不同，又可以分为两种组。 数字编号捕获组 语法：(exp) 解释：从表达式左侧开始，每出现一个左括号和它对应的右括号之间的内容为一个分组，在分组中，第0组为整个表达式，第一组开始为分组。 比如固定电话的：020-85653333 他的正则表达式为：(0d{2})-(d{8}) 按照左括号的顺序，这个表达式有如下分组： 序号编号分组内容00(0d{2})-(d{8})020-8565333311(0d{2})02022(d{8})85653333 我们用Java来验证一下： 12345678910String test = \"020-85653333\"; String reg=\"(0\\d{2})-(\\d{8})\"; Pattern pattern = Pattern.compile(reg); Matcher mc= pattern.matcher(test); if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); for(int i=0;i&lt;=mc.groupCount();i++){ System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); } } 输出结果： 1234分组的个数有：2第0个分组为：020-85653333第1个分组为：020第2个分组为：85653333 可见，分组个数是2，但是因为第0个为整个表达式本身，因此也一起输出了。 命名编号捕获组 语法：(?exp) 解释：分组的命名由表达式中的name指定 比如区号也可以这样写:(?d{2})-(?d{8}) 按照左括号的顺序，这个表达式有如下分组：序号名称分组内容00(0d{2})-(d{8})020-856533331quhao(0d{2})0202haoma(d{8})85653333 用代码来验证一下： 123456789String test = \"020-85653333\";String reg=\"(?&lt;quhao&gt;0\\d{2})-(?&lt;haoma&gt;\\d{8})\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); System.out.println(mc.group(\"quhao\")); System.out.println(mc.group(\"haoma\"));} 输出结果： 123分组的个数有：2分组名称为:quhao,匹配内容为：020分组名称为:haoma,匹配内容为：85653333 非捕获组 语法：(?:exp) 解释：和捕获组刚好相反，它用来标识那些不需要捕获的分组，说的通俗一点，就是你可以根据需要去保存你的分组。 比如上面的正则表达式，程序不需要用到第一个分组，那就可以这样写：(?:d{2})-(d{8}) 序号编号分组内容00(0d{2})-(d{8})020-8565333311(d{8})85653333 验证一下： 12345678910String test = \"020-85653333\";String reg=\"(?:0\\d{2})-(\\d{8})\";Pattern pattern = Pattern.compile(reg);Matcher mc= pattern.matcher(test);if(mc.find()){ System.out.println(\"分组的个数有：\"+mc.groupCount()); for(inti=0;i&lt;=mc.groupCount();i++){ System.out.println(\"第\"+i+\"个分组为：\"+mc.group(i)); }} 输出结果： 123分组的个数有：1第0个分组为：020-85653333第1个分组为：85653333 3.反向引用上面讲到捕获，我们知道：捕获会返回一个捕获组，这个分组是保存在内存中，不仅可以在正则表达式外部通过程序进行引用，也可以在正则表达式内部进行引用，这种引用方式就是反向引用。 根据捕获组的命名规则，反向引用可分为： 数字编号组反向引用：k或 umber 命名编号组反向引用：k或者’name’ 好了 讲完了，懂吗？不懂！！！ 可能连前面讲的捕获有什么用都还不懂吧？ 其实只是看完捕获不懂不会用是很正常的！ 因为捕获组通常是和反向引用一起使用的。 上面说到捕获组是匹配子表达式的内容按序号或者命名保存起来以便使用。 注意两个字眼：“内容” 和 “使用”。 这里所说的“内容”，是匹配结果，而不是子表达式本身，强调这个有什么用？嗯，先记住。 那这里所说的“使用”是怎样使用呢？ 因为它的作用主要是用来查找一些重复的内容或者做替换指定字符。 还是举栗子吧。 比如要查找一串字母”aabbbbgbddesddfiid”里成对的字母 如果按照我们之前学到的正则，什么区间啊限定啊断言啊可能是办不到的， 现在我们先用程序思维理一下思路： 1）匹配到一个字母 2）匹配第下一个字母，检查是否和上一个字母是否一样 3）如果一样，则匹配成功，否则失败 这里的思路2中匹配下一个字母时，需要用到上一个字母，那怎么记住上一个字母呢？？？ 这下子捕获就有用处啦，我们可以利用捕获把上一个匹配成功的内容用来作为本次匹配的条件 好了，有思路就要实践 首先匹配一个字母：w 我们需要做成分组才能捕获，因此写成这样：(w) 那这个表达式就有一个捕获组：（w） 然后我们要用这个捕获组作为条件，那就可以：(w) 这样就大功告成了 可能有人不明白了，是什么意思呢？ 还记得捕获组有两种命名方式吗，一种是是根据捕获分组顺序命名，一种是自定义命名来作为捕获组的命名 在默认情况下都是以数字来命名，而且数字命名的顺序是从1开始的 因此要引用第一个捕获组，根据反向引用的数字命名规则 就需要 k或者 当然，通常都是是后者。 我们来测试一下： 1234567String test = \"aabbbbgbddesddfiid\";Pattern pattern = Pattern.compile(\"(\\w)\\1\");Matcher mc= pattern.matcher(test);while(mc.find()){ System.out.println(mc.group());} 输出结果： 1aabbbbddddii 嗯，这就是我们想要的了。 在举个替换的例子，假如想要把字符串中abc换成a。 123String test = \"abcbbabcbcgbddesddfiid\";String reg=\"(a)(b)c\";System.out.println(test.replaceAll(reg, \"$1\")); 输出结果： 1abbabcgbddesddfiid 4.贪婪和非贪婪 贪婪 我们都知道，贪婪就是不满足，尽可能多的要。 在正则中，贪婪也是差不多的意思: 贪婪匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能多的字符，这匹配方式叫做贪婪匹配。 特性：一次性读入整个字符串进行匹配，每当不匹配就舍弃最右边一个字符，继续匹配，依次匹配和舍弃（这种匹配-舍弃的方式也叫做回溯），直到匹配成功或者把整个字符串舍弃完为止，因此它是一种最大化的数据返回，能多不会少。 前面我们讲过重复限定符，其实这些限定符就是贪婪量词，比如表达式：d{3,6}。 用来匹配3到6位数字，在这种情况下，它是一种贪婪模式的匹配，也就是假如字符串里有6个个数字可以匹配，那它就是全部匹配到。 如下面的代码。 123456789String reg=\"\\d{3,6}\";String test=\"61762828 176 2991 871\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 123456文本：61762828 176 2991 44 871贪婪模式：d{3,6}匹配结果：617628匹配结果：176匹配结果：2991匹配结果：871 由结果可见：本来字符串中的“61762828”这一段，其实只需要出现3个（617）就已经匹配成功了的，但是他并不满足，而是匹配到了最大能匹配的字符，也就是6个。 一个量词就如此贪婪了， 那有人会问，如果多个贪婪量词凑在一起，那他们是如何支配自己的匹配权的呢？ 是这样的，多个贪婪在一起时，如果字符串能满足他们各自最大程度的匹配时，就互不干扰，但如果不能满足时，会根据深度优先原则，也就是从左到右的每一个贪婪量词，优先最大数量的满足，剩余再分配下一个量词匹配。 123456789String reg=\"(\\d{1,2})(\\d{3,4})\";String test=\"61762828 176 2991 87321\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 12345文本：61762828 176 2991 87321贪婪模式：(d{1,2})(d{3,4})匹配结果：617628匹配结果：2991匹配结果：87321 “617628” 是前面的d{1,2}匹配出了61，后面的匹配出了7628 “2991” 是前面的d{1,2}匹配出了29 ，后面的匹配出了91 “87321”是前面的d{1,2}匹配出了87，后面的匹配出了321 懒惰（非贪婪） 懒惰匹配：当正则表达式中包含能接受重复的限定符时，通常的行为是（在使整个表达式能得到匹配的前提下）匹配尽可能少的字符，这匹配方式叫做懒惰匹配。 特性：从左到右，从字符串的最左边开始匹配，每次试图不读入字符匹配，匹配成功，则完成匹配，否则读入一个字符再匹配，依此循环（读入字符、匹配）直到匹配成功或者把字符串的字符匹配完为止。 懒惰量词是在贪婪量词后面加个“？” 代码说明 *?重复任意次，但尽可能少重复 +?重复1次或更多次，但尽可能少重复 ??重复0次或1次，但尽可能少重复 {n,m}?重复n到m次，但尽可能少重复 {n,}?重复n次以上，但尽可能少重复。 123456789String reg=\"(\\d{1,2}?)(\\d{3,4})\";String test=\"61762828 176 2991 87321\";System.out.println(\"文本：\"+test);System.out.println(\"贪婪模式：\"+reg);Pattern p1 =Pattern.compile(reg);Matcher m1 = p1.matcher(test);while(m1.find()){ System.out.println(\"匹配结果：\"+m1.group(0));} 输出结果： 12345文本：61762828 176 2991 87321贪婪模式：(d{1,2}?)(d{3,4})匹配结果：61762匹配结果：2991匹配结果：87321 “61762” 是左边的懒惰匹配出6，右边的贪婪匹配出1762 “2991” 是左边的懒惰匹配出2，右边的贪婪匹配出991 “87321” 左边的懒惰匹配出8，右边的贪婪匹配出7321 5.反义前面说到元字符的都是要匹配什么什么，当然如果你想反着来，不想匹配某些字符，正则也提供了一些常用的反义元字符。 元字符解释: W匹配任意不是字母，数字，下划线，汉字的字符 S匹配任意不是空白符的字符 D匹配任意非数字的字符 B匹配不是单词开头或结束的位置 [x]匹配除了x以外的任意字符 [aeiou]匹配除了aeiou这几个字母以外的任意字符 正则进阶知识就讲到这里，正则是一门博大精深的语言，其实学会它的一些语法和知识点还算不太难，但想要做到真正学以致用能写出非常6的正则，还有很远的距离，只有真正对它感兴趣的，并且经常研究和使用它，才会渐渐的理解它的博大精深之处，我就带你们走到这，剩下的，靠自己啦。 参考资料","link":"/2019/04/28/Java版常用正则表达式说明.html"},{"title":"Elasticsearch常用工具api","text":"摘要Elasticsearch 是一个高度可扩展且开源的全文检索和分析引擎。它可以让您快速且近实时地存储，检索以及分析海量数据。它通常用作那些具有复杂搜索功能和需求的应用的底层引擎或者技术。 下面是 Elasticsearch 一些简单的使用案例 : 您运行一个可以让您顾客来搜索您所售产品的在线的网络商店。在这种情况下，您可以使用 Elasticsearch 来存储您的整个产品的目录和库存，并且为他们提供搜索和自动完成的建议。 您想要去收集日志或交易数据，并且您还想要去分析和挖掘这些数据以来找出趋势，统计，概述，或者异常现。在这种情况下，您可以使用 Logstash（Elasticsearch/Logstash/Kibana 技术栈中的一部分）来收集，聚合，以及解析数据，然后让 Logstash 发送这些数据到 Elasticsearch。如果这些数据存在于 Elasticsearch 中，那么您就可以执行搜索和聚合以挖掘出任何您感兴趣的信息。 您运行一个价格警告平台，它允许客户指定精确的价格，如“我感兴趣的是购买指定的电子产品，如果任何供应商该产品的价格在未来一个月内低于 $X 这个价钱的话我应该被通知到”。在这种情况下，您可以收集供应商的价格，推送它们到 Elasticsearch 中去，然后使用 reverse-search（Percolator）（反向搜索（过滤器））功能以匹配客户查询价格的变动，最后如果发现匹配成功就给客户发出通知。 您必须分析/商业智能的需求，并希望快速的研究，分析，可视化，并且需要 ad-hoc（即席查询）海量数据（像数百万或者数十亿条记录）上的质疑。在这种情况下，您可以使用 Elasticsearch 来存储数据，然后使用 Kibana（Elasticsearch/Logstash/Kibana 技术栈中的一部分）以建立一个能够可视化的对您很重要的数据方面的定制的 dashboards（面板）。此外，您还可以使用 Elasticsearch 的聚合功能对您的数据执行复杂的商业智能查询 对于本教程的其余部分，我将引导您完成 Elasticsearch 的启动和运行的过程，同时了解其原理，并执行像 indexing（索引），searching（查询）和 modifing（修改）数据的基础操作。在本教程的最后一部分，您应该可以清楚的了解到 Elasticsearch 是什么，它是如何工作的，并有希望获得启发。看您如何使用它来构建复杂的搜索应用程序或者从数据中挖掘出想要的信息。 常用实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238# 常用kibana脚本(可以自动填充，比较好用)PUT /test_business/data/1 #更改数据{ \"name\":\"zhe\"}}POST _analyze #实时分词{ \"text\": \"张月超\", \"analyzer\": \"ik_max_word\"}DELETE /analyze_index #删除索引GET analyze_index/_settings #查看索引_settingsGET analyze_index/_mapping #查看索引_mappingPOST /analyze_index/data/_mapping #设置mapping{ \"dynamic\": \"false\", \"properties\": { \"name\": { \"type\": \"text\", \"analyzer\": \"ik\" } }}POST /analyze_index #设置settings{ \"settings\": { \"index\": { \"analysis\": { \"normalizer\": { \"case_insensitive_normalizer\": { \"type\": \"custom\", \"filter\": \"lowercase\" } }, \"filter\": { \"my_synonym\": { \"type\": \"synonym\", \"synonyms_path\": \"analysis-ik/extra/synonyms.dic\" } }, \"analyzer\": { \"ik\": { \"filter\": [ \"my_synonym\" ], \"char_filter\": [ \"my_char_mapper\" ], \"type\": \"custom\", \"tokenizer\": \"ik_max_word\" } }, \"char_filter\": { \"my_char_mapper\": { \"type\": \"mapping\", \"mappings_path\": \"analysis-ik/extra/pre_filter_mapping.dic\" } } } } }, \"mapping\": { \"data\": { \"properties\": { \"name\": { \"type\": \"text\", \"analyzer\": \"ik\" } } } }}GET /es_test_analyzer/_settingsGET /es_test_analyzer/_mappingGET /analyze_index/data/1POST /es_test_analyzer/_analyze{ \"text\": \"超越\", \"analyzer\": \"ik_max_word\"}POST /es_test_analyzer/data/1{ \"name\": \"张月超666哈哈张月超\", \"nick_name\":\"张月超666哈哈张月超\"}POST /es_test_analyzer/data/2{ \"name\": \"王月\", \"nick_name\":\"王月\"}POST /es_test_analyzer/data/3{ \"name\": \"超越\", \"nick_name\":\"超越\"}GET /es_test_analyzer/data/1GET /es_test_analyzer/data/3/_termvectors?fields=nick_name # 查看索引中分词情况GET /es_test_analyzer/data/_search{ \"query\": { \"multi_match\": { \"query\": \"超越\", \"fields\": [ \"nick_name\" ], \"analyzer\": \"ik\", \"operator\": \"or\", \"type\": \"best_fields\" } }, \"highlight\": { \"fields\": { \"name\": { } } }}DELETE /es_test_analyzer/GET /analyze_index/data/_mappingGET /test/data/_search{ \"query\": { \"bool\": { \"should\": [ { \"multi_match\": { \"query\": \"餐饮\", \"fields\": [\"title^2\",\"tags\"] } },{ \"wildcard\": { \"name\": { \"value\": \"*中国*\" } } } ] } }}GET /user/data/9969/_explain # 查看详细id：9969 得分情况{ \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"tacos n frankies\", \"fields\": [ \"name^1.0\", \"info^1.0\" ], \"type\": \"best_fields\", \"operator\": \"or\", \"analyzer\": \"ik_max_word\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } \"adjust_pure_negative\": true, \"boost\": 1 } } , \"highlight\": { \"fields\": { \"name\": {}, \"info\": {} } }}GET /user/data/_search{ \"query\": { \"bool\": { \"must\": [ { \"multi_match\": { \"query\": \"tacos n frankies\", \"fields\": [ \"name^1.0\", \"info^1.0\" ], \"type\": \"best_fields\", \"operator\": \"or\", \"analyzer\": \"ik_max_word\", \"slop\": 0, \"prefix_length\": 0, \"max_expansions\": 50, \"zero_terms_query\": \"NONE\", \"auto_generate_synonyms_phrase_query\": true, \"fuzzy_transpositions\": true, \"boost\": 1 } } \"adjust_pure_negative\": true, \"boost\": 1 } } , \"highlight\": { \"fields\": { \"name\": {}, \"info\": {} } }} 查看健康信息 curl -XGET ‘localhost:9200/_cat/health?v&amp;pretty’ 我们可以获得 green，yellow，或者 red 的 status。Green 表示一切正常（集群功能齐全）， yellow 表示所有数据可用，但是有些副本尚未分配（集群功能齐全），red 意味着由于某些原因有些数据不可用。注意，集群是 red，它仍然具有部分功能（例如，它将继续从可用的分片中服务搜索请求），但是您可能需要尽快去修复它，因为您已经丢失数据了。 查看所有的索引 curl -XGET ‘localhost:9200/_cat/indices?v&amp;pretty’ Document APISindex api 索引 API 在特定索引中 add ( 添加 ) 或 update *( 更新 ) *a typed JSON document ( 类型化的 JSON 文档 )，使其可搜索。以下示例将 JSON 文档插入到 “twitter” 索引中，ID 为1 ： 123456789101112131415161718192021curl -XPUT 'localhost:9200/twitter/tweet/1?pretty' -H 'Content-Type: application/json' -d'{ \"user\" : \"kimchy\", \"post_date\" : \"2009-11-15T14:12:12\", \"message\" : \"trying out Elasticsearch\"}'结果：{ \"_shards\" : { \"total\" : 2, \"failed\" : 0, \"successful\" : 2 }, \"_index\" : \"twitter\", \"_type\" : \"tweet\", \"_id\" : \"1\", \"_version\" : 1, \"created\" : true, \"result\" : created} total - 指示应对多少 shard copies ( 分片副本 )（ \\primary ( 主 )分片和 replica ( 副本 ) 分片）执行索引操作。 successful - 表示索引操作成功的分片副本的数量。 failed - 在索引操作在副本碎片上失败的情况下包含与复制相关的错误的数组。 当索引操作 successful 返回时，可能不会全部启动副本碎片（默认情况下，只需要主索引，但可以更改此行为）。在这种情况下， total 将等于基于 number_of_replicas 设置的总分片，并且 successful 将等于已启动的分片数（主副本和副本）。如果没有失败， failed 将是 0 。 get apiget api 允许从一个基于其id的 index 中获取一个 JSON格式的 document，下面的示例是从一个在名称为tweet的 type \\下的id为1，名称为twitter的 \\index \\中获取一个JSON格式的 \\document。 1curl -XGET 'http://localhost:9200/twitter/tweet/1' update api12345678910111213141516171819202122232425262728293031323334353637383940# 更新api PUT test/type1/1{ \"counter\" : 1, \"tags\" : [\"red\"]}# 脚本更新POST test/type1/1/_update{ \"script\" : { \"inline\": \"ctx._source.counter += params.count\", \"lang\": \"painless\", \"params\" : { \"count\" : 4 } }}# 将新字段添加到文档：POST test/type1/1/_update{ \"script\" : \"ctx._source.new_field = \\\"value_of_new_field\\\"\"}# 删除字段POST test/type1/1/_update{ \"script\" : \"ctx._source.remove(\\\"new_field\\\")\"}# 甚至可以改变已执行的操作。这个例子就是删除文档，如果 tags包含 green，否则就什么也不做（noop）：POST test/type1/1/_update{ \"script\" : { \"inline\": \"if (ctx._source.tags.contains(params.tag)) { ctx.op = \\\"delete\\\" } else { ctx.op = \\\"none\\\" }\", \"lang\": \"painless\", \"params\" : { \"tag\" : \"green\" } }} 通过查询api更新123456789101112POST twitter/_update_by_query{ \"script\": { \"inline\": \"ctx._source.likes++\", \"lang\": \"painless\" }, \"query\": { \"term\": { \"user\": \"kimchy\" } }} bulk apiBulk API，能够在一个单一的API调用执行多项索引/删除操作。这可以大大提高索引速度。 该 REST API 端点/_bulk，它遵循JSON结构： 1234567action_and_meta_data\\noptional_source\\naction_and_meta_data\\noptional_source\\n....action_and_meta_data\\noptional_source\\n 注意：数据的最终行必须以换行符结束\\n。 可能的操作有 index，create，delete和 update， index 和 `create期望在下一行的作为源，并与索引 API 有相同的语义。（如果文件具有相同的索引和类型的文件已经存在，就会创建失败，必要时候而索引回添加或替换文件）。delete不会作为下一行的源，并与 delete API 中具有相同的语义。update 是希望`部分文档，upsert 和脚本及其选项能够在下一行指定。 delete apidelete API允许基于指定的ID来从索引库中删除一个JSON文件。下面演示了从一个叫twitter的索引库的tweettype下删除文档，id是1: 1$ curl -XDELETE 'http://localhost:9200/twitter/tweet/1' 索引的每个文档都被标记了版本。当删除文档时， 可以通过指定version来确保我们试图删除一个实际上已被删除的文档时，它在此期间并没有改变。在文档中执行的每个写入操作，包括删除，都会使其版本递增。 delete by query api最简单的用法是使用_delete_by_query对每个查询匹配的文档执行删除。这是API: 12345678POST twitter/_delete_by_query{ \"query\": { //① \"match\": { \"message\": \"some message\" } }} term vectors返回有关特定文档字段中的词条的信息和统计信息。文档可以存储在索引中或由用户人工提供。词条向量默认为实时，不是近实时。这可以通过将realtime参数设置为false来更改。 1GET /twitter/tweet/1/_termvectors 可选的，您可以使用url中的参数指定检索信息的字段： 1GET /twitter/tweet/1/_termvectors?fields=message searchquery api结果的分页可以通过使用 from 和 size 参数来完成。 from 参数定义了您要提取的第一个结果的偏移量。 size 参数允许您配置要返回的最大匹配数。 虽然 from 和 size 可以设置为请求参数，但它们也可以在搜索正文中设置。from 默认值为 0，size 默认为 10。 1234567GET /_search{ &quot;from&quot; : 0, &quot;size&quot; : 10, &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} 注意 from + size 不能超过 index.max_result_window 索引设置，默认为 10,000。 有关深入滚动的更有效方法，请参阅 Scroll 或 Search After API。 sort排序选项可以有以下值： | asc | 按升序排序 | | desc | 按倒序排序 | 在对 _score 进行排序时，该顺序默认为 desc，在对其他事物进行排序时默认为 asc。 Sort mode Option Elasticsearch支持按数组或多值字段排序。 mode 选项控制选择用于对其所属文档进行排序的数组值。 mode 选项可以具有以下值： | min | 选择最低值。 | | max | 选择最高值。 | | sum | 使用所有值的和作为排序值。 仅适用于基于数字的数组字段。 | | avg | 使用所有值的平均值作为排序值。 仅适用于基于数字的数组字段。 | | median | 使用所有值的中值作为排序值。 仅适用于基于数字的数组字段。 | Elasticsearch 还支持根据一个或多个嵌套对象内的字段进行排序。 通过嵌套字段支持进行的排序在已经存在的排序选项之上具有以下参数： nested_path 定义要排序的嵌套对象。 实际排序字段必须是此嵌套对象内的直接字段。 当通过嵌套字段排序时，此字段是必需的。 nested_filter 嵌套路径中的内部对象应与其匹配的过滤器，以便通过排序考虑其字段值。 常见的情况是在嵌套的过滤器或查询中重复查询/过滤。 默认情况下，没有 nested_filter 是激活的。 Nested sorting example 在下面的示例中，offer是一个类型为嵌套的字段。 需要指定nested_path; 否则，elasticsearch不知道需要捕获哪个嵌套级排序值。 123456789101112131415161718POST /_search{ \"query\" : { \"term\" : { \"product\" : \"chocolate\" } }, \"sort\" : [ { \"offer.price\" : { \"mode\" : \"avg\", \"order\" : \"asc\", \"nested_path\" : \"offer\", \"nested_filter\" : { \"term\" : { \"offer.color\" : \"blue\" } } } } ]} 当通过脚本排序和按地理距离排序时，也支持嵌套排序。 Missing Values 缺少的参数指定应如何处理缺少字段的文档：缺少的值可以设置为 last，first 或自定义值（将用于缺少文档作为排序值）。 123456789GET /_search{ &quot;sort&quot; : [ { &quot;price&quot; : {&quot;missing&quot; : &quot;_last&quot;} } ], &quot;query&quot; : { &quot;term&quot; : { &quot;product&quot; : &quot;chocolate&quot; } }} Note：如果嵌套的内部对象与 nested_filter 不匹配，则使用缺少的值。 Geo Distance Sorting 允许按 geodistance 排序。 下面是一个例子，假设 pin.location 是一个类型为 geo_point 的字段： 1234567891011121314151617GET /_search{ &quot;sort&quot; : [ { &quot;_geo_distance&quot; : { &quot;pin.location&quot; : [-70, 40], &quot;order&quot; : &quot;asc&quot;, &quot;unit&quot; : &quot;km&quot;, &quot;mode&quot; : &quot;min&quot;, &quot;distance_type&quot; : &quot;sloppy_arc&quot; } } ], &quot;query&quot; : { &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot; } }} distance_type 如何计算距离。 可以是 sloppy_arc（默认），弧（稍微更精确但显着更慢）或平面（更快，但不准确在长距离和接近极点）。 mode 如果字段有多个地理点，该怎么办。 默认情况下，按升序排序时考虑最短距离，按降序排序时最长距离。 支持的值为 min，max，median 和 avg。 unit 计算排序值时使用的单位。 默认值为 m（米）。 geo distance sorting 不支持可配置的缺失值：当文档没有用于距离计算的字段的值时，距离将始终被视为等于 Infinity。 在提供坐标时支持以下格式： highlighting允许突出显示一个或多个字段的搜索结果。 实现使用 lucene 普通荧光笔，快速向量荧光笔（fvh）或 postings 荧光笔。 以下是一个搜索请求正文的示例： 1234567891011GET /_search{ &quot;query&quot; : { &quot;match&quot;: { &quot;user&quot;: &quot;kimchy&quot; } }, &quot;highlight&quot; : { &quot;fields&quot; : { &quot;content&quot; : {} } }} 在上述情况下，内容字段将为每个搜索命中突出显示（每个搜索命中内将有另一个元素，称为突出显示，其中包括突出显示的字段和突出显示的片段）。 Note： 为了执行突出显示，需要字段的实际内容。 如果有问题的字段被存储（在映射中存储设置为 true），它将被使用，否则，实际的 _source 将被加载，并且相关字段将从中提取。 _all 字段不能从 _source 中提取，因此它只能用于突出显示，如果它映射到将 store 设置为 true。 字段名称支持通配符符号。 例如，使用 comment_ * 将导致所有与表达式匹配的文本和关键字字段（以及 5.0 之前的字符串）被突出显示。 请注意，所有其他字段将不会突出显示。 如果您使用自定义映射器并要在字段上突出显示，则必须显式提供字段名称。 Plain highlighte(有多种类型选择、根据实际情况使用) 荧光笔的默认选择是普通类型，并使用Lucene荧光笔。 它试图在理解词重要性和短语查询中的任何词定位标准方面反映查询匹配逻辑。 warning： 如果你想突出很多文档中的大量字段与复杂的查询，这个荧光笔不会快。 在努力准确地反映查询逻辑，它创建一个微小的内存索引，并通过 Lucene 的查询执行计划程序重新运行原始查询条件，以获取当前文档的低级别匹配信息。 这对于每个字段和需要突出显示的每个文档重复。 如果这在您的系统中出现性能问题，请考虑使用替代荧光笔。 search typeQuery Then Fetch 参数值： query_then_fetch。 请求分两个阶段处理。 在第一阶段，查询被转发到所有涉及的分片。 每个分片执行搜索并生成对该分片本地的结果的排序列表。 每个分片只向协调节点返回足够的信息，以允许其合并并将分片级结果重新排序为全局排序的最大长度大小的结果集。 在第二阶段期间，协调节点仅从相关分片请求文档内容（以及高亮显示的片段，如果有的话）。 Note： 如果您未在请求中指定 search_type，那么这是默认设置。 Dfs, Query Then Fetch 参数值：dfs_query_then_fetch 与 “Query Then Fetch” 相同，除了初始分散阶段，其计算分布项频率用于更准确的计分。 scroll 游标(多数据深度分页问题解决)从滚动请求返回的结果反映了进行初始搜索请求时索引的状态，如时间快照。 对文档（索引，更新或删除）的后续更改只会影响以后的搜索请求。 为了使用滚动，初始搜索请求应该在查询字符串中指定滚动参数，它告诉 Elasticsearch 应保持“搜索上下文”活动的时间（见保持搜索上下文），例如 ?scroll=1m。 123456789POST /twitter/tweet/_search?scroll=1m{ \"size\": 100, \"query\": { \"match\" : { \"title\" : \"elasticsearch\" } }} 上述请求的结果包括一个 scrollid，它应该被传递给滚动 API，以便检索下一批结果。 12345POST ①/_search/scroll ②{ \"scroll\" : \"1m\", ③ \"scroll_id\" : \"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==\" ④} | ① | 可以使用GET或POST。 | | ② | 网址不应包含索引或类型名称 - 而是在原始搜索请求中指定的。 | | ③ | scroll 参数告诉 Elasticsearch 将搜索上下文打开另一个1m。 | | ④ | scroll_id参数 | size 参数允许您配置每批结果返回的最大命中数。 每次调用 scroll API 都会返回下一批结果，直到没有更多结果要返回，即 hits 数组为空。 explan启用每次匹配对其评分计算方式的说明。 1234567GET /_search{ \"explain\": true, \"query\" : { \"term\" : { \"user\" : \"kimchy\" } }} suggesters (共有四种方式) Completion Suggester Context Suggester Phrase Suggester Term suggester completion suggester完全（completion）suggester 提供自动完成/按需搜索功能。 这是一种导航功能，可在用户输入时引导用户查看相关结果，从而提高搜索精度。 它不是用于拼写校正或平均值功能，如术语或短语 suggesters 。 理想地，自动完成功能应当与用户键入的速度一样快，以提供与用户已经键入的内容相关的即时反馈。因此，完成 suggester 针对速度进行优化。 suggester 使用允许快速查找的数据结构，但是构建成本高并且存储在存储器中。 要使用此功能，请为此字段指定一个特殊映射，为快速完成的字段值编制索引。 123456789101112131415PUT music{ \"mappings\": { \"song\" : { \"properties\" : { \"suggest\" : { \"type\" : \"completion\" }, \"title\" : { \"type\": \"keyword\" } } } }} 映射支持以下参数： analyzer 使用索引分析器，默认为简单。 如果你想知道为什么我们没有选择标准分析器：我们尝试在这里很容易理解的行为，如果你索引字段内容在Drive-in，你不会得到任何建议， （第一个非停用词） search_analyzer 要使用的搜索分析器，默认为分析器的值。 preserve_separators 保留分隔符，默认为true。 如果禁用，你可以找到一个以Foo Fighters开头的字段，如果你推荐foof。 preserve_position_increments 启用位置增量，默认为true。 如果禁用和使用停用分析器，您可以得到一个字段从披头士开始，如果你 suggest b。 注意：你也可以通过索引两个输入，Beatles和披头士，不需要改变一个简单的分析器，如果你能够丰富你的数据。 max_input_length 限制单个输入的长度，默认为50个UTF-16代码点。 此限制仅在索引时使用，以减少每个输入字符串的字符总数，以防止大量输入膨胀底层数据结构。 大多数用例不会受默认值的影响，因为前缀完成很少超过前缀长度超过少数几个字符。 索引 您像任何其他字段一样索引 suggestion 。 suggestion 由输入和可选的权重属性组成。 输入是要由 suggestion 查询匹配的期望文本，并且权重确定如何对 suggestion 进行评分。 索引 suggestion 如下： 1234567PUT music/song/1?refresh{ &quot;suggest&quot; : { &quot;input&quot;: [ &quot;Nevermind&quot;, &quot;Nirvana&quot; ], &quot;weight&quot; : 34 }} 以下参数被支持： input 输入存储，这可以是字符串数组或只是一个字符串。 此字段是必填字段。 weight 正整数或包含正整数的字符串，用于定义权重并允许对 suggestions 进行排名。 此字段是可选的。 查询 suggest 像往常一样工作，除了您必须指定 suggest 类型为完成。 suggestions 接近实时，这意味着可以通过刷新显示新 suggestions ，并且一旦删除就不会显示文档。 此请求： 123456789POST music/_suggest?pretty{ &quot;song-suggest&quot; : { &quot;prefix&quot; : &quot;nir&quot;, &quot;completion&quot; : { &quot;field&quot; : &quot;suggest&quot; } }} 返回这个响应： 12345678910111213141516171819202122{ &quot;_shards&quot; : { &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 }, &quot;song-suggest&quot; : [ { &quot;text&quot; : &quot;nir&quot;, &quot;offset&quot; : 0, &quot;length&quot; : 3, &quot;options&quot; : [ { &quot;text&quot; : &quot;Nirvana&quot;, &quot;_index&quot;: &quot;music&quot;, &quot;_type&quot;: &quot;song&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1.0, &quot;_source&quot;: { &quot;suggest&quot;: [&quot;Nevermind&quot;, &quot;Nirvana&quot;] } } ] } ]} 模糊查询 完成 suggester 还支持模糊查询 - 这意味着，您可以在搜索中输入错误，并仍然返回结果。 123456789101112POST music/_suggest?pretty{ &quot;song-suggest&quot; : { &quot;prefix&quot; : &quot;nor&quot;, &quot;completion&quot; : { &quot;field&quot; : &quot;suggest&quot;, &quot;fuzzy&quot; : { &quot;fuzziness&quot; : 2 } } }} 与查询前缀共享最长前缀的 suggestion 将得分更高。 模糊查询可以采用特定的模糊参数。 支持以下参数： | fuzziness | 模糊系数，默认为AUTO。 有关允许的设置，请参阅 “Fuzzinessedit”一节。 | | transpositions | 如果设置为true，则换位计数为一个更改而不是两个，默认为true | | min_length | 返回模糊 suggestions 前的输入的最小长度，默认值3 | | prefix_length | 输入的最小长度（未针对模糊替代项进行检查）默认为1 | | unicode_aware | 如果为true，则所有度量（如模糊编辑距离，置换和长度）都以Unicode代码点而不是字节为单位。 这比原始字节稍慢，因此默认情况下设置为false。 | 如果你想坚持使用默认值，但仍然使用模糊，你可以使用 fuzzy：{}或fuzzy：true。 Explan apiExplain API 计算查询和特定文档的分数说明。 这可以提供有用的反馈，无论文档是否匹配特定查询。 index 和 type 参数分别期望单个索引和单个类型。 用法完整查询示例： 123456GET /twitter/tweet/0/_explain{ &quot;query&quot; : { &quot;match&quot; : { &quot;message&quot; : &quot;elasticsearch&quot; } }} 这将产生以下结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748{ &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;0&quot;, &quot;matched&quot; : true, &quot;explanation&quot; : { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;sum of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;weight(message:elasticsearch in 0) [PerFieldSimilarity], result of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.55077, &quot;description&quot; : &quot;score(doc=0,freq=1.0 = termFreq=1.0\\n), product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.3862944, &quot;description&quot; : &quot;idf(docFreq=1, docCount=5)&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.1186441, &quot;description&quot; : &quot;tfNorm, computed from:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;termFreq=1.0&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.2, &quot;description&quot; : &quot;parameter k1&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 0.75, &quot;description&quot; : &quot;parameter b&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 5.4, &quot;description&quot; : &quot;avgFieldLength&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 4.0, &quot;description&quot; : &quot;fieldLength&quot;, &quot;details&quot; : [ ] } ] } ] } ] }, { &quot;value&quot; : 0.0, &quot;description&quot; : &quot;match on required clause, product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 0.0, &quot;description&quot; : &quot;# clause&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;_type:tweet, product of:&quot;, &quot;details&quot; : [ { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;boost&quot;, &quot;details&quot; : [ ] }, { &quot;value&quot; : 1.0, &quot;description&quot; : &quot;queryNorm&quot;, &quot;details&quot; : [ ] } ] } ] } ] }} 还有一种更简单的通过 q 参数指定查询的方法。 然后解析指定的 q 参数值，就像使用 query_string 查询一样。 在api中的 q 参数的用法示例： 1GET /twitter/tweet/0/_explain?q=message:search 这将产生与先前请求相同的结果。 参考资料","link":"/2019/04/26/Elasticsearch常用工具api.html"},{"title":"restful api 设计以及幂等性相关设计","text":"摘要针对项目中部分使用restful-api接口，总结文档如下，没有规矩不成方圆。写代码亦是，设计restful-api接口亦是。 RESTful 的核心思想就是，客户端发出的数据操作指令都是”动词 + 宾语”的结构。比如，GET /articles这个命令，GET是动词，/articles是宾语。 动词通常就是五种 HTTP 方法，对应 CRUD 操作。 GET：读取（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） 根据 HTTP 规范，动词一律大写 话不多说，先上代码，一份完整的restful-api示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445@RestController@RequestMapping(\"admin/biz-name/v1/user\") //@RequestMapping(\"api/biz-name/v1/city\")public class AdminUserController { @Autowired private UserService service; @GetMapping(\"{id}/county/list\") public List&lt;UserView&gt; getUsersByCategoryId(@PathVariable(\"id\") Integer id) { return service.getUsersByCategoryId(id); } @GetMapping(\"{id}\") public UserView userInfoById(@PathVariable(\"id\") Integer id) { return service.getUserInfoById(id); } @PostMapping public Object create(@RequestBody UserEntityForm form) { // 相关验证valid 设置默认值 service.valid(form); if (StringUtil.isEmpty(form.getCsEmail())) { form.setCsEmail(\"980099577@qq.com\"); } Integer id = service.ceate(form); return Collections.singletonMap(\"id\", id); } @PutMapping public Result update(@RequestBody UserEntityForm form) { // 相关验证 valid service.valid(form); service.update(form); return Result.SUCCEED; } @DeleteMapping(\"{id}\") public Result delete(@PathVariable(\"id\") Integer id) { // 相关验证 valid service.valid(form); service.delete(id); return Result.SUCCEED; }} 针对以上restful-api 代码需要注意一下几点：@RestController 注解此注解加在类的上面，返回的结果以json格式，标注此为RestController。不同于Controller注解。Controller非json格式返回。 @RequestMapping此注解标识api请求的路劲，可指定相应的请求方法，例如@RequestMapping(“admin/biz-name/v1/user”)：http://localhost:8080/admin/biz-name/v1/user 有如下定义参数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping { /** * Assign a name to this mapping. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used on both levels, a combined name is derived by concatenation * with \"#\" as separator. * @see org.springframework.web.servlet.mvc.method.annotation.MvcUriComponentsBuilder * @see org.springframework.web.servlet.handler.HandlerMethodMappingNamingStrategy */ String name() default \"\"; /** * The primary mapping expressed by this annotation. * &lt;p&gt;In a Servlet environment this is an alias for {@link #path}. * For example {@code @RequestMapping(\"/foo\")} is equivalent to * {@code @RequestMapping(path=\"/foo\")}. * &lt;p&gt;In a Portlet environment this is the mapped portlet modes * (i.e. \"EDIT\", \"VIEW\", \"HELP\" or any custom modes). * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. */ @AliasFor(\"path\") String[] value() default {}; /** * In a Servlet environment only: the path mapping URIs (e.g. \"/myPath.do\"). * Ant-style path patterns are also supported (e.g. \"/myPath/*.do\"). * At the method level, relative paths (e.g. \"edit.do\") are supported within * the primary mapping expressed at the type level. Path mapping URIs may * contain placeholders (e.g. \"/${connect}\") * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this primary mapping, narrowing it for a specific handler method. * @see org.springframework.web.bind.annotation.ValueConstants#DEFAULT_NONE * @since 4.2 */ @AliasFor(\"value\") String[] path() default {}; /** * The HTTP request methods to map to, narrowing the primary mapping: * GET, POST, HEAD, OPTIONS, PUT, PATCH, DELETE, TRACE. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this HTTP method restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;Supported for Servlet environments as well as Portlet 2.0 environments. */ RequestMethod[] method() default {}; /** * The parameters of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of \"myParam=myValue\" style * expressions, with a request only mapped if each such parameter is found * to have the given value. Expressions can be negated by using the \"!=\" operator, * as in \"myParam!=myValue\". \"myParam\" style expressions are also supported, * with such parameters having to be present in the request (allowed to have * any value). Finally, \"!myParam\" style expressions indicate that the * specified parameter is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this parameter restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;In a Servlet environment, parameter mappings are considered as restrictions * that are enforced at the type level. The primary path mapping (i.e. the * specified URI value) still has to uniquely identify the target handler, with * parameter mappings simply expressing preconditions for invoking the handler. * &lt;p&gt;In a Portlet environment, parameters are taken into account as mapping * differentiators, i.e. the primary portlet mode mapping plus the parameter * conditions uniquely identify the target handler. Different handlers may be * mapped onto the same portlet mode, as long as their parameter mappings differ. */ String[] params() default {}; /** * The headers of the mapped request, narrowing the primary mapping. * &lt;p&gt;Same format for any environment: a sequence of \"My-Header=myValue\" style * expressions, with a request only mapped if each such header is found * to have the given value. Expressions can be negated by using the \"!=\" operator, * as in \"My-Header!=myValue\". \"My-Header\" style expressions are also supported, * with such headers having to be present in the request (allowed to have * any value). Finally, \"!My-Header\" style expressions indicate that the * specified header is &lt;i&gt;not&lt;/i&gt; supposed to be present in the request. * &lt;p&gt;Also supports media type wildcards (*), for headers such as Accept * and Content-Type. For instance, * &lt;pre class=\"code\"&gt; * &amp;#064;RequestMapping(value = \"/something\", headers = \"content-type=text/*\") * &lt;/pre&gt; * will match requests with a Content-Type of \"text/html\", \"text/plain\", etc. * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings inherit * this header restriction (i.e. the type-level restriction * gets checked before the handler method is even resolved). * &lt;p&gt;Maps against HttpServletRequest headers in a Servlet environment, * and against PortletRequest properties in a Portlet 2.0 environment. * @see org.springframework.http.MediaType */ String[] headers() default {}; /** * The consumable media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the {@code Content-Type} matches one of these media types. * Examples: * &lt;pre class=\"code\"&gt; * consumes = \"text/plain\" * consumes = {\"text/plain\", \"application/*\"} * &lt;/pre&gt; * Expressions can be negated by using the \"!\" operator, as in \"!text/plain\", which matches * all requests with a {@code Content-Type} other than \"text/plain\". * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this consumes restriction. * @see org.springframework.http.MediaType * @see javax.servlet.http.HttpServletRequest#getContentType() */ String[] consumes() default {}; /** * The producible media types of the mapped request, narrowing the primary mapping. * &lt;p&gt;The format is a single media type or a sequence of media types, * with a request only mapped if the {@code Accept} matches one of these media types. * Examples: * &lt;pre class=\"code\"&gt; * produces = \"text/plain\" * produces = {\"text/plain\", \"application/*\"} * produces = \"application/json; charset=UTF-8\" * &lt;/pre&gt; * &lt;p&gt;It affects the actual content type written, for example to produce a JSON response * with UTF-8 encoding, {@code \"application/json; charset=UTF-8\"} should be used. * &lt;p&gt;Expressions can be negated by using the \"!\" operator, as in \"!text/plain\", which matches * all requests with a {@code Accept} other than \"text/plain\". * &lt;p&gt;&lt;b&gt;Supported at the type level as well as at the method level!&lt;/b&gt; * When used at the type level, all method-level mappings override * this produces restriction. * @see org.springframework.http.MediaType */ String[] produces() default {};} @GetMapping此注解，接收前端为get请求的相关方法,接口返回天生具有幂等性，每次请求参数一致返回的结果也一致 此注解请求一般为获取相关信息的方法 有如下参数， 12345678910111213141516171819202122232425262728293031323334353637383940414243@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@RequestMapping(method = RequestMethod.GET)public @interface GetMapping { /** * Alias for {@link RequestMapping#name}. */ @AliasFor(annotation = RequestMapping.class) String name() default \"\"; /** * Alias for {@link RequestMapping#value}. */ @AliasFor(annotation = RequestMapping.class) String[] value() default {}; /** * Alias for {@link RequestMapping#path}. */ @AliasFor(annotation = RequestMapping.class) String[] path() default {}; /** * Alias for {@link RequestMapping#params}. */ @AliasFor(annotation = RequestMapping.class) String[] params() default {}; /** * Alias for {@link RequestMapping#headers}. */ @AliasFor(annotation = RequestMapping.class) String[] headers() default {}; /** * Alias for {@link RequestMapping#produces}. */ @AliasFor(annotation = RequestMapping.class) String[] produces() default {};} @PostMapping此注解，接收前端为post请求的相关方法 一般为保存，创建信息的方法，save…,create… @putMapping此注解，接收前端为put请求的相关方法 一般为更新数据的接口方法，update… @deleteMapping此注解，接收前端为delete请求的相关方法 一般为删除数据的方法 @RequestBody此注解放入接口方法的参数前面，对应请求中的body里的内容，要求body内容为json格式 例如： 1public Object create(@RequestBody UserEntityForm form) {}; @PathVariable此注解放入接口方法的参数前面，要求里面的值出现在Mapping中，以{}包裹，如下 接受参数required，设置判断此字段是否必须 12@GetMapping(\"{id}\")public UserView userInfoById(@PathVariable(\"id\",required = true) Integer id) {} @RequestParam此注解放入接口方法的参数前面，前端放入请求参数中，非body里面 接受参数required，设置判断此字段是否必须 defaultValue 设置此字段的默认值 1public UserView userInfoById(@RequestParam(value = \"id\", required = false, defaultValue = \"1\") Integer id）{} 所有的接口方法都应该设计为幂等性，即接口请求多次或一次都应该达到同样的效果。此特性在高并发下面非常适用。 高并发的核心技术 - 幂等的实现方案一、背景我们实际系统中有很多操作，是不管做多少次，都应该产生一样的效果或返回一样的结果。 例如： 前端重复提交选中的数据，应该后台只产生对应这个数据的一个反应结果。 2. 我们发起一笔付款请求，应该只扣用户账户一次钱，当遇到网络重发或系统bug重发，也应该只扣一次钱； 3. 发送消息，也应该只发一次，同样的短信发给用户，用户会哭的； 4. 创建业务订单，一次业务请求只能创建一个，创建多个就会出大问题。 等等很多重要的情况，这些逻辑都需要幂等的特性来支持。 二、幂等性概念幂等（idempotent、idempotence）是一个数学与计算机学概念，常见于抽象代数中。 在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“getUsername()和setTrue()”函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 我的理解：幂等就是一个操作，不论执行多少次，产生的效果和返回的结果都是一样的 三、技术方案 查询操作 查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作 删除操作 删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) 3.唯一索引，防止新增脏数据 比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录 要点： 唯一索引或唯一组合索引来防止新增数据存在脏数据 （当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可） token机制，防止页面重复提交 业务要求： 页面的数据只能被点击提交一次 发生原因： 由于重复点击或者网络重发，或者nginx重发等情况会导致数据被重复提交 解决办法： 集群环境：采用token加redis（redis单线程的，处理需要排队） 单JVM环境：采用token加redis或token加jvm内存 处理流程： 1. 数据提交前要向服务的申请token，token放到redis或jvm内存，token有效时间 2. 提交后后台校验token，同时删除token，生成新的token返回 token特点： 要申请，一次有效性，可以限流 注意：redis要用删除操作来判断token，删除成功代表token校验通过，如果用select+delete来校验token，存在并发问题，不建议使用 悲观锁 获取数据的时候加锁获取 select * from table_xxx where id=’xxx’ for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的 悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 乐观锁 乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。 乐观锁的实现方式多种多样可以通过version或者其他状态条件： 1. 通过版本号实现 update table_xxx set name=#name#,version=version+1 where version=#version# 如下图(来自网上)： 通过条件限制 update tablexxx set avaiamount=avaiamount-#subAmount# where avaiamount-#subAmount# &gt;= 0 要求：quality-#subQuality# &gt;= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高 注意：乐观锁的更新操作，最好用主键或者唯一索引来更新,这样是行锁，否则更新时会锁表，上面两个sql改成下面的两个更好 update tablexxx set name=#name#,version=version+1 where id=#id# and version=#version# update tablexxx set avaiamount=avaiamount-#subAmount# where id=#id# and avai_amount-#subAmount# &gt;= 0 分布式锁 还是拿插入数据的例子，如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。 要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供) select + insert 并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了 注意：核心高并发流程不要用这种方法 状态机幂等 在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。 注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助 对外提供接口的api如何保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号 source+seq在数据库里面做唯一索引，防止多次付款，(并发时，只能处理一个请求) 重点对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。 总结幂等性应该是合格程序员的一个基因，在设计系统时，是首要考虑的问题，尤其是在像支付宝，银行，互联网金融公司等涉及的都是钱的系统，既要高效，数据也要准确，所以不能出现多扣款，多打款等问题，这样会很难处理，用户体验也不好 参考自","link":"/2019/04/18/restful-api-设计以及幂等性相关设计.html"},{"title":"一千行 MySQL 学习笔记(转载)","text":"摘要以下为本人初学 MySQL 时做的笔记，也从那时起没再更新过，但还是囊括了基本的知识点，有时还翻出来查查。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044/* Windows服务 */-- 启动MySQL net start mysql-- 创建Windows服务 sc create mysql binPath= mysqld_bin_path(注意：等号与值之间有空格)/* 连接与断开服务器 */mysql -h 地址 -P 端口 -u 用户名 -p 密码SHOW PROCESSLIST -- 显示哪些线程正在运行SHOW VARIABLES -- 显示系统变量信息/* 数据库操作 */ -------------------- 查看当前数据库 SELECT DATABASE();-- 显示当前时间、用户名、数据库版本 SELECT now(), user(), version();-- 创建库 CREATE DATABASE[ IF NOT EXISTS] 数据库名 数据库选项 数据库选项： CHARACTER SET charset_name COLLATE collation_name-- 查看已有库 SHOW DATABASES[ LIKE 'PATTERN']-- 查看当前库信息 SHOW CREATE DATABASE 数据库名-- 修改库的选项信息 ALTER DATABASE 库名 选项信息-- 删除库 DROP DATABASE[ IF EXISTS] 数据库名 同时删除该数据库相关的目录及其目录内容/* 表的操作 */ -------------------- 创建表 CREATE [TEMPORARY] TABLE[ IF NOT EXISTS] [库名.]表名 ( 表的结构定义 )[ 表选项] 每个字段必须有数据类型 最后一个字段后不能有逗号 TEMPORARY 临时表，会话结束时表自动消失 对于字段的定义： 字段名 数据类型 [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string']-- 表选项 -- 字符集 CHARSET = charset_name 如果表没有设定，则使用数据库字符集 -- 存储引擎 ENGINE = engine_name 表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同 常见的引擎：InnoDB MyISAM Memory/Heap BDB Merge Example CSV MaxDB Archive 不同的引擎在保存表的结构和数据时采用不同的方式 MyISAM表文件含义：.frm表定义，.MYD表数据，.MYI表索引 InnoDB表文件含义：.frm表定义，表空间数据和日志文件 SHOW ENGINES -- 显示存储引擎的状态信息 SHOW ENGINE 引擎名 {LOGS|STATUS} -- 显示存储引擎的日志或状态信息 -- 自增起始数 AUTO_INCREMENT = 行数 -- 数据文件目录 DATA DIRECTORY = '目录' -- 索引文件目录 INDEX DIRECTORY = '目录' -- 表注释 COMMENT = 'string' -- 分区选项 PARTITION BY ... (详细见手册)-- 查看所有表 SHOW TABLES[ LIKE 'pattern'] SHOW TABLES FROM 表名-- 查看表机构 SHOW CREATE TABLE 表名 （信息更详细） DESC 表名 / DESCRIBE 表名 / EXPLAIN 表名 / SHOW COLUMNS FROM 表名 [LIKE 'PATTERN'] SHOW TABLE STATUS [FROM db_name] [LIKE 'pattern']-- 修改表 -- 修改表本身的选项 ALTER TABLE 表名 表的选项 eg: ALTER TABLE 表名 ENGINE=MYISAM; -- 对表进行重命名 RENAME TABLE 原表名 TO 新表名 RENAME TABLE 原表名 TO 库名.表名 （可将表移动到另一个数据库） -- RENAME可以交换两个表名 -- 修改表的字段机构（13.1.2. ALTER TABLE语法） ALTER TABLE 表名 操作名 -- 操作名 ADD[ COLUMN] 字段定义 -- 增加字段 AFTER 字段名 -- 表示增加在该字段名后面 FIRST -- 表示增加在第一个 ADD PRIMARY KEY(字段名) -- 创建主键 ADD UNIQUE [索引名] (字段名)-- 创建唯一索引 ADD INDEX [索引名] (字段名) -- 创建普通索引 DROP[ COLUMN] 字段名 -- 删除字段 MODIFY[ COLUMN] 字段名 字段属性 -- 支持对字段属性进行修改，不能修改字段名(所有原有属性也需写上) CHANGE[ COLUMN] 原字段名 新字段名 字段属性 -- 支持对字段名修改 DROP PRIMARY KEY -- 删除主键(删除主键前需删除其AUTO_INCREMENT属性) DROP INDEX 索引名 -- 删除索引 DROP FOREIGN KEY 外键 -- 删除外键-- 删除表 DROP TABLE[ IF EXISTS] 表名 ...-- 清空表数据 TRUNCATE [TABLE] 表名-- 复制表结构 CREATE TABLE 表名 LIKE 要复制的表名-- 复制表结构和数据 CREATE TABLE 表名 [AS] SELECT * FROM 要复制的表名-- 检查表是否有错误 CHECK TABLE tbl_name [, tbl_name] ... [option] ...-- 优化表 OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...-- 修复表 REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM]-- 分析表 ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] .../* 数据操作 */ -------------------- 增 INSERT [INTO] 表名 [(字段列表)] VALUES (值列表)[, (值列表), ...] -- 如果要插入的值列表包含所有字段并且顺序一致，则可以省略字段列表。 -- 可同时插入多条数据记录！ REPLACE 与 INSERT 完全一样，可互换。 INSERT [INTO] 表名 SET 字段名=值[, 字段名=值, ...]-- 查 SELECT 字段列表 FROM 表名[ 其他子句] -- 可来自多个表的多个字段 -- 其他子句可以不使用 -- 字段列表可以用*代替，表示所有字段-- 删 DELETE FROM 表名[ 删除条件子句] 没有条件子句，则会删除全部-- 改 UPDATE 表名 SET 字段名=新值[, 字段名=新值] [更新条件]/* 字符集编码 */ -------------------- MySQL、数据库、表、字段均可设置编码-- 数据编码与客户端编码不需一致SHOW VARIABLES LIKE 'character_set_%' -- 查看所有字符集编码项 character_set_client 客户端向服务器发送数据时使用的编码 character_set_results 服务器端将结果返回给客户端所使用的编码 character_set_connection 连接层编码SET 变量名 = 变量值 SET character_set_client = gbk; SET character_set_results = gbk; SET character_set_connection = gbk;SET NAMES GBK; -- 相当于完成以上三个设置-- 校对集 校对集用以排序 SHOW CHARACTER SET [LIKE 'pattern']/SHOW CHARSET [LIKE 'pattern'] 查看所有字符集 SHOW COLLATION [LIKE 'pattern'] 查看所有校对集 CHARSET 字符集编码 设置字符集编码 COLLATE 校对集编码 设置校对集编码/* 数据类型（列类型） */ ------------------1. 数值类型-- a. 整型 ---------- 类型 字节 范围（有符号位） tinyint 1字节 -128 ~ 127 无符号位：0 ~ 255 smallint 2字节 -32768 ~ 32767 mediumint 3字节 -8388608 ~ 8388607 int 4字节 bigint 8字节 int(M) M表示总位数 - 默认存在符号位，unsigned 属性修改 - 显示宽度，如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改 例：int(5) 插入一个数'123'，补填后为'00123' - 在满足要求的情况下，越小越好。 - 1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型。-- b. 浮点型 ---------- 类型 字节 范围 float(单精度) 4字节 double(双精度) 8字节 浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性。 不同于整型，前后均会补填0. 定义浮点型时，需指定总位数和小数位数。 float(M, D) double(M, D) M表示总位数，D表示小数位数。 M和D的大小会决定浮点数的范围。不同于整型的固定范围。 M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）。 支持科学计数法表示。 浮点数表示近似值。-- c. 定点数 ---------- decimal -- 可变长度 decimal(M, D) M也表示总位数，D表示小数位数。 保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入。 将浮点数转换为字符串来保存，每9位数字保存为4个字节。2. 字符串类型-- a. char, varchar ---------- char 定长字符串，速度快，但浪费空间 varchar 变长字符串，速度慢，但节省空间 M表示能存储的最大长度，此长度是字符数，非字节数。 不同的编码，所占用的空间不同。 char,最多255个字符，与编码无关。 varchar,最多65535字符，与编码有关。 一条有效记录最大不能超过65535个字节。 utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符 varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。 varchar 的最大有效长度由最大行大小和使用的字符集确定。 最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。 例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？ 答：(65535-1-2-4-30*3)/3-- b. blob, text ---------- blob 二进制字符串（字节字符串） tinyblob, blob, mediumblob, longblob text 非二进制字符串（字符字符串） tinytext, text, mediumtext, longtext text 在定义时，不需要定义长度，也不会计算总长度。 text 类型在定义时，不可给default值-- c. binary, varbinary ---------- 类似于char和varchar，用于保存二进制字符串，也就是保存字节字符串而非字符字符串。 char, varchar, text 对应 binary, varbinary, blob.3. 日期时间类型 一般用整型保存时间戳，因为PHP可以很方便的将时间戳进行格式化。 datetime 8字节 日期及时间 1000-01-01 00:00:00 到 9999-12-31 23:59:59 date 3字节 日期 1000-01-01 到 9999-12-31 timestamp 4字节 时间戳 19700101000000 到 2038-01-19 03:14:07 time 3字节 时间 -838:59:59 到 838:59:59 year 1字节 年份 1901 - 2155datetime YYYY-MM-DD hh:mm:sstimestamp YY-MM-DD hh:mm:ss YYYYMMDDhhmmss YYMMDDhhmmss YYYYMMDDhhmmss YYMMDDhhmmssdate YYYY-MM-DD YY-MM-DD YYYYMMDD YYMMDD YYYYMMDD YYMMDDtime hh:mm:ss hhmmss hhmmssyear YYYY YY YYYY YY4. 枚举和集合-- 枚举(enum) ----------enum(val1, val2, val3...) 在已知的值中进行单选。最大数量为65535. 枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。 表现为字符串类型，存储却是整型。 NULL值的索引是NULL。 空字符串错误值的索引值是0。-- 集合（set） ----------set(val1, val2, val3...) create table tab ( gender set('男', '女', '无') ); insert into tab values ('男, 女'); 最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式。 当创建表时，SET成员值的尾部空格将自动被删除。/* 选择类型 */-- PHP角度1. 功能满足2. 存储空间尽量小，处理效率更高3. 考虑兼容问题-- IP存储 ----------1. 只需存储，可用字符串2. 如果需计算，查找等，可存储为4个字节的无符号int，即unsigned 1) PHP函数转换 ip2long可转换为整型，但会出现携带符号问题。需格式化为无符号的整型。 利用sprintf函数格式化字符串 sprintf(\"%u\", ip2long('192.168.3.134')); 然后用long2ip将整型转回IP字符串 2) MySQL函数转换(无符号整型，UNSIGNED) INET_ATON('127.0.0.1') 将IP转为整型 INET_NTOA(2130706433) 将整型转为IP/* 列属性（列约束） */ ------------------1. PRIMARY 主键 - 能唯一标识记录的字段，可以作为主键。 - 一个表只能有一个主键。 - 主键具有唯一性。 - 声明字段时，用 primary key 标识。 也可以在字段列表之后声明 例：create table tab ( id int, stu varchar(10), primary key (id)); - 主键字段的值不能为null。 - 主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。 例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));2. UNIQUE 唯一索引（唯一约束） 使得某字段的值也不能重复。3. NULL 约束 null不是数据类型，是列的一个属性。 表示当前列是否可以为null，表示什么都没有。 null, 允许为空。默认。 not null, 不允许为空。 insert into tab values (null, 'val'); -- 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null4. DEFAULT 默认值属性 当前字段的默认值。 insert into tab values (default, 'val'); -- 此时表示强制使用默认值。 create table tab ( add_time timestamp default current_timestamp ); -- 表示将当前时间的时间戳设为默认值。 current_date, current_time5. AUTO_INCREMENT 自动增长约束 自动增长必须为索引（主键或unique） 只能存在一个字段为自动增长。 默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;6. COMMENT 注释 例：create table tab ( id int ) comment '注释内容';7. FOREIGN KEY 外键约束 用于限制主表与从表数据完整性。 alter table t1 add constraint `t1_t2_fk` foreign key (t1_id) references t2(id); -- 将表t1的t1_id外键关联到表t2的id字段。 -- 每个外键都有一个名字，可以通过 constraint 指定 存在外键的表，称之为从表（子表），外键指向的表，称之为主表（父表）。 作用：保持数据一致性，完整性，主要目的是控制存储在外键表（从表）中的数据。 MySQL中，可以对InnoDB引擎使用外键约束： 语法： foreign key (外键字段） references 主表名 (关联字段) [主表记录删除时的动作] [主表记录更新时的动作] 此时需要检测一个从表的外键需要约束为主表的已存在的值。外键在没有关联的情况下，可以设置为null.前提是该外键列，没有not null。 可以不指定主表记录更改或更新时的动作，那么此时主表的操作被拒绝。 如果指定了 on update 或 on delete：在删除或更新时，有如下几个操作可以选择： 1. cascade，级联操作。主表数据被更新（主键值更新），从表也被更新（外键值更新）。主表记录被删除，从表相关记录也被删除。 2. set null，设置为null。主表数据被更新（主键值更新），从表的外键被设置为null。主表记录被删除，从表相关记录外键被设置成null。但注意，要求该外键列，没有not null属性约束。 3. restrict，拒绝父表删除和更新。 注意，外键只被InnoDB存储引擎所支持。其他引擎是不支持的。/* 建表规范 */ ------------------ -- Normal Format, NF - 每个表保存一个实体信息 - 每个具有一个ID字段作为主键 - ID主键 + 原子表 -- 1NF, 第一范式 字段不能再分，就满足第一范式。 -- 2NF, 第二范式 满足第一范式的前提下，不能出现部分依赖。 消除符合主键就可以避免部分依赖。增加单列关键字。 -- 3NF, 第三范式 满足第二范式的前提下，不能出现传递依赖。 某个字段依赖于主键，而有其他字段依赖于该字段。这就是传递依赖。 将一个实体信息的数据放在一个表内实现。/* SELECT */ ------------------SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr -- 可以用 * 表示所有字段。 select * from tb; -- 可以使用表达式（计算公式、函数调用、字段也是个表达式） select stu, 29+25, now() from tb; -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。 - 使用 as 关键字，也可省略 as. select stu+10 as add10 from tb;b. FROM 子句 用于标识查询来源。 -- 可以为表起别名。使用as关键字。 SELECT * FROM tb1 AS tt, tb2 AS bb; -- from子句后，可以同时出现多个表。 -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。 SELECT * FROM tb1, tb2; -- 向优化符提示如何选择索引 USE INDEX、IGNORE INDEX、FORCE INDEX SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3; SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句 -- 从from获得的数据源中进行筛选。 -- 整型1表示真，0表示假。 -- 表达式由运算符和运算数组成。 -- 运算数：变量（字段）、值、函数返回值 -- 运算符： =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||, in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor is/is not 加上ture/false/unknown，检验某个值的真假 &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句 GROUP BY 字段/别名 [排序方式] 分组后会进行排序。升序：ASC，降序：DESC 以下[合计函数]需配合 GROUP BY 使用： count 返回不同的非NULL值数目 count(*)、count(字段) sum 求和 max 求最大值 min 求最小值 avg 求平均值 group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句 与 where 功能、用法相同，执行时机不同。 where 在开始时执行检测数据，对原数据进行过滤。 having 对筛选出的结果再次进行过滤。 having 字段必须是查询出来的，where 字段必须是数据表存在的。 where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。 where 不可以使用合计函数。一般需用合计函数才会用 having SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句 order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]... 升序：ASC，降序：DESC 支持多个字段的排序。g. LIMIT 子句，限制结果数量子句 仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。 limit 起始位置, 获取条数 省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项 distinct 去除重复记录 默认为 all, 全部记录/* UNION */ ------------------ 将多个select查询的结果组合成一个结果集合。 SELECT ... UNION [ALL|DISTINCT] SELECT ... 默认 DISTINCT 方式，即所有返回的行都是唯一的 建议，对每个SELECT查询加上小括号包裹。 ORDER BY 排序时，需加上 LIMIT 进行结合。 需要各select查询的字段数量一样。 每个select查询的字段列表(数量、类型)应一致，因为结果中的字段名以第一条select语句为准。/* 子查询 */ ------------------ - 子查询需用括号包裹。-- from型 from后要求是一个表，必须给子查询结果取个别名。 - 简化每个查询内的条件。 - from型需将结果生成一个临时表格，可用以原表的锁定的释放。 - 子查询返回一个表，表型子查询。 select * from (select * from tb where id&gt;0) as subfrom where id&gt;1;-- where型 - 子查询返回一个值，标量子查询。 - 不需要给子查询取别名。 - where子查询内的表，不能直接用以更新。 select * from tb where money = (select max(money) from tb); -- 列子查询 如果子查询结果返回的是一列。 使用 in 或 not in 完成查询 exists 和 not exists 条件 如果子查询返回数据，则返回1或0。常用于判断条件。 select column1 from t1 where exists (select * from t2); -- 行子查询 查询条件是一个行。 select * from t1 where (id, gender) in (select id, gender from t2); 行构造符：(col1, col2, ...) 或 ROW(col1, col2, ...) 行构造符通常用于与对能返回两个或两个以上列的子查询进行比较。 -- 特殊运算符 != all() 相当于 not in = some() 相当于 in。any 是 some 的别名 != some() 不等同于 not in，不等于其中某一个。 all, some 可以配合其他运算符一起使用。/* 连接查询(join) */ ------------------ 将多个表的字段进行连接，可以指定连接条件。-- 内连接(inner join) - 默认就是内连接，可省略inner。 - 只有数据存在时才能发送连接。即连接结果不能出现空行。 on 表示连接条件。其条件表达式与where类似。也可以省略条件（表示条件永远为真） 也可用where表示连接条件。 还有 using, 但需字段名相同。 using(字段名) -- 交叉连接 cross join 即，没有条件的内连接。 select * from tb1 cross join tb2;-- 外连接(outer join) - 如果数据不存在，也会出现在连接结果中。 -- 左外连接 left join 如果数据不存在，左表记录会出现，而右表为null填充 -- 右外连接 right join 如果数据不存在，右表记录会出现，而左表为null填充-- 自然连接(natural join) 自动判断连接条件完成连接。 相当于省略了using，会自动查找相同字段名。 natural join natural left join natural right joinselect info.id, info.name, info.stu_num, extra_info.hobby, extra_info.sex from info, extra_info where info.stu_num = extra_info.stu_id;/* 导入导出 */ ------------------select * into outfile 文件地址 [控制格式] from 表名; -- 导出表数据load data [local] infile 文件地址 [replace|ignore] into table 表名 [控制格式]; -- 导入数据 生成的数据默认的分隔符是制表符 local未指定，则数据文件必须在服务器上 replace 和 ignore 关键词控制对现有的唯一键记录的重复的处理-- 控制格式fields 控制字段格式默认：fields terminated by '\\t' enclosed by '' escaped by '\\\\' terminated by 'string' -- 终止 enclosed by 'char' -- 包裹 escaped by 'char' -- 转义 -- 示例： SELECT a,b,a+b INTO OUTFILE '/tmp/result.text' FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\"' LINES TERMINATED BY '\\n' FROM test_table;lines 控制行格式默认：lines terminated by '\\n' terminated by 'string' -- 终止/* INSERT */ ------------------select语句获得的数据可以用insert插入。可以省略对列的指定，要求 values () 括号内，提供给了按照列顺序出现的所有字段的值。 或者使用set语法。 INSERT INTO tbl_name SET field=value,...；可以一次性使用多个值，采用(), (), ();的形式。 INSERT INTO tbl_name VALUES (), (), ();可以在列值指定时，使用表达式。 INSERT INTO tbl_name VALUES (field_value, 10+10, now());可以使用一个特殊值 DEFAULT，表示该列使用默认值。 INSERT INTO tbl_name VALUES (field_value, DEFAULT);可以通过一个查询的结果，作为需要插入的值。 INSERT INTO tbl_name SELECT ...;可以指定在插入的值出现主键（或唯一索引）冲突时，更新其他非主键列的信息。 INSERT INTO tbl_name VALUES/SET/SELECT ON DUPLICATE KEY UPDATE 字段=值, …;/* DELETE */ ------------------DELETE FROM tbl_name [WHERE where_definition] [ORDER BY ...] [LIMIT row_count]按照条件删除。where指定删除的最多记录数。limit可以通过排序条件删除。order by + limit支持多表删除，使用类似连接语法。delete from 需要删除数据多表1，表2 using 表连接操作 条件。/* TRUNCATE */ ------------------TRUNCATE [TABLE] tbl_name清空数据删除重建表区别：1，truncate 是删除表再创建，delete 是逐条删除2，truncate 重置auto_increment的值。而delete不会3，truncate 不知道删除了几条，而delete知道。4，当被用于带分区的表时，truncate 会保留分区/* 备份与还原 */ ------------------备份，将数据的结构与表内数据保存起来。利用 mysqldump 指令完成。-- 导出mysqldump [options] db_name [tables]mysqldump [options] ---database DB1 [DB2 DB3...]mysqldump [options] --all--database1. 导出一张表 mysqldump -u用户名 -p密码 库名 表名 &gt; 文件名(D:/a.sql)2. 导出多张表 mysqldump -u用户名 -p密码 库名 表1 表2 表3 &gt; 文件名(D:/a.sql)3. 导出所有表 mysqldump -u用户名 -p密码 库名 &gt; 文件名(D:/a.sql)4. 导出一个库 mysqldump -u用户名 -p密码 --lock-all-tables --database 库名 &gt; 文件名(D:/a.sql)可以-w携带WHERE条件-- 导入1. 在登录mysql的情况下： source 备份文件2. 在不登录的情况下 mysql -u用户名 -p密码 库名 &lt; 备份文件/* 视图 */ ------------------什么是视图： 视图是一个虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。但是，视图并不在数据库中以存储的数据值集形式存在。行和列数据来自由定义视图的查询所引用的表，并且在引用视图时动态生成。 视图具有表结构文件，但不存在数据文件。 对其中所引用的基础表来说，视图的作用类似于筛选。定义视图的筛选可以来自当前或其它数据库的一个或多个表，或者其它视图。通过视图进行查询没有任何限制，通过它们进行数据修改时的限制也很少。 视图是存储在数据库中的查询的sql语句，它主要出于两种原因：安全原因，视图可以隐藏一些数据，如：社会保险基金表，可以用视图只显示姓名，地址，而不显示社会保险号和工资数等，另一原因是可使复杂的查询易于理解和使用。-- 创建视图CREATE [OR REPLACE] [ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}] VIEW view_name [(column_list)] AS select_statement - 视图名必须唯一，同时不能与表重名。 - 视图可以使用select语句查询到的列名，也可以自己指定相应的列名。 - 可以指定视图执行的算法，通过ALGORITHM指定。 - column_list如果存在，则数目必须等于SELECT语句检索的列数-- 查看结构 SHOW CREATE VIEW view_name-- 删除视图 - 删除视图后，数据依然存在。 - 可同时删除多个视图。 DROP VIEW [IF EXISTS] view_name ...-- 修改视图结构 - 一般不修改视图，因为不是所有的更新视图都会映射到表上。 ALTER VIEW view_name [(column_list)] AS select_statement-- 视图作用 1. 简化业务逻辑 2. 对客户端隐藏真实的表结构-- 视图算法(ALGORITHM) MERGE 合并 将视图的查询语句，与外部查询需要先合并再执行！ TEMPTABLE 临时表 将视图执行完毕后，形成临时表，再做外层查询！ UNDEFINED 未定义(默认)，指的是MySQL自主去选择相应的算法。/* 事务(transaction) */ ------------------事务是指逻辑上的一组操作，组成这组操作的各个单元，要不全成功要不全失败。 - 支持连续SQL的集体成功或集体撤销。 - 事务是数据库在数据晚自习方面的一个功能。 - 需要利用 InnoDB 或 BDB 存储引擎，对自动提交的特性支持完成。 - InnoDB被称为事务安全型引擎。-- 事务开启 START TRANSACTION; 或者 BEGIN; 开启事务后，所有被执行的SQL语句均被认作当前事务内的SQL语句。-- 事务提交 COMMIT;-- 事务回滚 ROLLBACK; 如果部分操作发生问题，映射到事务开启前。-- 事务的特性 1. 原子性（Atomicity） 事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 2. 一致性（Consistency） 事务前后数据的完整性必须保持一致。 - 事务开始和结束时，外部数据一致 - 在整个事务过程中，操作是连续的 3. 隔离性（Isolation） 多个用户并发访问数据库时，一个用户的事务不能被其它用户的事物所干扰，多个并发事务之间的数据要相互隔离。 4. 持久性（Durability） 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。-- 事务的实现 1. 要求是事务支持的表类型 2. 执行一组相关的操作前开启事务 3. 整组操作完成后，都成功，则提交；如果存在失败，选择回滚，则会回到事务开始的备份点。-- 事务的原理 利用InnoDB的自动提交(autocommit)特性完成。 普通的MySQL执行语句后，当前的数据提交操作均可被其他客户端可见。 而事务是暂时关闭“自动提交”机制，需要commit提交持久化数据操作。-- 注意 1. 数据定义语言（DDL）语句不能被回滚，比如创建或取消数据库的语句，和创建、取消或更改表或存储的子程序的语句。 2. 事务不能被嵌套-- 保存点 SAVEPOINT 保存点名称 -- 设置一个事务保存点 ROLLBACK TO SAVEPOINT 保存点名称 -- 回滚到保存点 RELEASE SAVEPOINT 保存点名称 -- 删除保存点-- InnoDB自动提交特性设置 SET autocommit = 0|1; 0表示关闭自动提交，1表示开启自动提交。 - 如果关闭了，那普通操作的结果对其他客户端也不可见，需要commit提交后才能持久化数据操作。 - 也可以关闭自动提交来开启事务。但与START TRANSACTION不同的是， SET autocommit是永久改变服务器的设置，直到下次再次修改该设置。(针对当前连接) 而START TRANSACTION记录开启前的状态，而一旦事务提交或回滚后就需要再次开启事务。(针对当前事务)/* 锁表 */表锁定只用于防止其它客户端进行不正当地读取和写入MyISAM 支持表锁，InnoDB 支持行锁-- 锁定 LOCK TABLES tbl_name [AS alias]-- 解锁 UNLOCK TABLES/* 触发器 */ ------------------ 触发程序是与表有关的命名数据库对象，当该表出现特定事件时，将激活该对象 监听：记录的增加、修改、删除。-- 创建触发器CREATE TRIGGER trigger_name trigger_time trigger_event ON tbl_name FOR EACH ROW trigger_stmt 参数： trigger_time是触发程序的动作时间。它可以是 before 或 after，以指明触发程序是在激活它的语句之前或之后触发。 trigger_event指明了激活触发程序的语句的类型 INSERT：将新行插入表时激活触发程序 UPDATE：更改某一行时激活触发程序 DELETE：从表中删除某一行时激活触发程序 tbl_name：监听的表，必须是永久性的表，不能将触发程序与TEMPORARY表或视图关联起来。 trigger_stmt：当触发程序激活时执行的语句。执行多个语句，可使用BEGIN...END复合语句结构-- 删除DROP TRIGGER [schema_name.]trigger_name可以使用old和new代替旧的和新的数据 更新操作，更新前是old，更新后是new. 删除操作，只有old. 增加操作，只有new.-- 注意 1. 对于具有相同触发程序动作时间和事件的给定表，不能有两个触发程序。-- 字符连接函数concat(str1,str2,...])concat_ws(separator,str1,str2,...)-- 分支语句if 条件 then 执行语句elseif 条件 then 执行语句else 执行语句end if;-- 修改最外层语句结束符delimiter 自定义结束符号 SQL语句自定义结束符号delimiter ; -- 修改回原来的分号-- 语句块包裹begin 语句块end-- 特殊的执行1. 只要添加记录，就会触发程序。2. Insert into on duplicate key update 语法会触发： 如果没有重复记录，会触发 before insert, after insert; 如果有重复记录并更新，会触发 before insert, before update, after update; 如果有重复记录但是没有发生更新，则触发 before insert, before update3. Replace 语法 如果有记录，则执行 before insert, before delete, after delete, after insert/* SQL编程 */ --------------------// 局部变量 ------------ 变量声明 declare var_name[,...] type [default value] 这个语句被用来声明局部变量。要给变量提供一个默认值，请包含一个default子句。值可以被指定为一个表达式，不需要为一个常数。如果没有default子句，初始值为null。-- 赋值 使用 set 和 select into 语句为变量赋值。 - 注意：在函数内是可以使用全局变量（用户自定义的变量）--// 全局变量 ------------ 定义、赋值set 语句可以定义并为变量赋值。set @var = value;也可以使用select into语句为变量初始化并赋值。这样要求select语句只能返回一行，但是可以是多个字段，就意味着同时为多个变量进行赋值，变量的数量需要与查询的列数一致。还可以把赋值语句看作一个表达式，通过select执行完成。此时为了避免=被当作关系运算符看待，使用:=代替。（set语句可以使用= 和 :=）。select @var:=20;select @v1:=id, @v2=name from t1 limit 1;select * from tbl_name where @var:=30;select into 可以将表中查询获得的数据赋给变量。 -| select max(height) into @max_height from tb;-- 自定义变量名为了避免select语句中，用户自定义的变量与系统标识符（通常是字段名）冲突，用户自定义变量在变量名前使用@作为开始符号。@var=10; - 变量被定义后，在整个会话周期都有效（登录到退出）--// 控制结构 ------------ if语句if search_condition then statement_list [elseif search_condition then statement_list]...[else statement_list]end if;-- case语句CASE value WHEN [compare-value] THEN result[WHEN [compare-value] THEN result ...][ELSE result]END-- while循环[begin_label:] while search_condition do statement_listend while [end_label];- 如果需要在循环内提前终止 while循环，则需要使用标签；标签需要成对出现。 -- 退出循环 退出整个循环 leave 退出当前循环 iterate 通过退出的标签决定退出哪个循环--// 内置函数 ------------ 数值函数abs(x) -- 绝对值 abs(-10.9) = 10format(x, d) -- 格式化千分位数值 format(1234567.456, 2) = 1,234,567.46ceil(x) -- 向上取整 ceil(10.1) = 11floor(x) -- 向下取整 floor (10.1) = 10round(x) -- 四舍五入去整mod(m, n) -- m%n m mod n 求余 10%3=1pi() -- 获得圆周率pow(m, n) -- m^nsqrt(x) -- 算术平方根rand() -- 随机数truncate(x, d) -- 截取d位小数-- 时间日期函数now(), current_timestamp(); -- 当前日期时间current_date(); -- 当前日期current_time(); -- 当前时间date('yyyy-mm-dd hh:ii:ss'); -- 获取日期部分time('yyyy-mm-dd hh:ii:ss'); -- 获取时间部分date_format('yyyy-mm-dd hh:ii:ss', '%d %y %a %d %m %b %j'); -- 格式化时间unix_timestamp(); -- 获得unix时间戳from_unixtime(); -- 从时间戳获得时间-- 字符串函数length(string) -- string长度，字节char_length(string) -- string的字符个数substring(str, position [,length]) -- 从str的position开始,取length个字符replace(str ,search_str ,replace_str) -- 在str中用replace_str替换search_strinstr(string ,substring) -- 返回substring首次在string中出现的位置concat(string [,...]) -- 连接字串charset(str) -- 返回字串字符集lcase(string) -- 转换成小写left(string, length) -- 从string2中的左边起取length个字符load_file(file_name) -- 从文件读取内容locate(substring, string [,start_position]) -- 同instr,但可指定开始位置lpad(string, length, pad) -- 重复用pad加在string开头,直到字串长度为lengthltrim(string) -- 去除前端空格repeat(string, count) -- 重复count次rpad(string, length, pad) --在str后用pad补充,直到长度为lengthrtrim(string) -- 去除后端空格strcmp(string1 ,string2) -- 逐字符比较两字串大小-- 流程函数case when [condition] then result [when [condition] then result ...] [else result] end 多分支if(expr1,expr2,expr3) 双分支。-- 聚合函数count()sum();max();min();avg();group_concat()-- 其他常用函数md5();default();--// 存储函数，自定义函数 ------------ 新建 CREATE FUNCTION function_name (参数列表) RETURNS 返回值类型 函数体 - 函数名，应该合法的标识符，并且不应该与已有的关键字冲突。 - 一个函数应该属于某个数据库，可以使用db_name.funciton_name的形式执行当前函数所属数据库，否则为当前数据库。 - 参数部分，由\"参数名\"和\"参数类型\"组成。多个参数用逗号隔开。 - 函数体由多条可用的mysql语句，流程控制，变量声明等语句构成。 - 多条语句应该使用 begin...end 语句块包含。 - 一定要有 return 返回值语句。-- 删除 DROP FUNCTION [IF EXISTS] function_name;-- 查看 SHOW FUNCTION STATUS LIKE 'partten' SHOW CREATE FUNCTION function_name;-- 修改 ALTER FUNCTION function_name 函数选项--// 存储过程，自定义功能 ------------ 定义存储存储过程 是一段代码（过程），存储在数据库中的sql组成。一个存储过程通常用于完成一段业务逻辑，例如报名，交班费，订单入库等。而一个函数通常专注与某个功能，视为其他程序服务的，需要在其他语句中调用函数才可以，而存储过程不能被其他调用，是自己执行 通过call执行。-- 创建CREATE PROCEDURE sp_name (参数列表) 过程体参数列表：不同于函数的参数列表，需要指明参数类型IN，表示输入型OUT，表示输出型INOUT，表示混合型注意，没有返回值。/* 存储过程 */ ------------------存储过程是一段可执行性代码的集合。相比函数，更偏向于业务逻辑。调用：CALL 过程名-- 注意- 没有返回值。- 只能单独调用，不可夹杂在其他语句中-- 参数IN|OUT|INOUT 参数名 数据类型IN 输入：在调用过程中，将数据输入到过程体内部的参数OUT 输出：在调用过程中，将过程体处理完的结果返回到客户端INOUT 输入输出：既可输入，也可输出-- 语法CREATE PROCEDURE 过程名 (参数列表)BEGIN 过程体END/* 用户和权限管理 */ -------------------- root密码重置1. 停止MySQL服务2. [Linux] /usr/local/mysql/bin/safe_mysqld --skip-grant-tables &amp; [Windows] mysqld --skip-grant-tables3. use mysql;4. UPDATE `user` SET PASSWORD=PASSWORD(\"密码\") WHERE `user` = \"root\";5. FLUSH PRIVILEGES;用户信息表：mysql.user-- 刷新权限FLUSH PRIVILEGES;-- 增加用户CREATE USER 用户名 IDENTIFIED BY [PASSWORD] 密码(字符串) - 必须拥有mysql数据库的全局CREATE USER权限，或拥有INSERT权限。 - 只能创建用户，不能赋予权限。 - 用户名，注意引号：如 'user_name'@'192.168.1.1' - 密码也需引号，纯数字密码也要加引号 - 要在纯文本中指定密码，需忽略PASSWORD关键词。要把密码指定为由PASSWORD()函数返回的混编值，需包含关键字PASSWORD-- 重命名用户RENAME USER old_user TO new_user-- 设置密码SET PASSWORD = PASSWORD('密码') -- 为当前用户设置密码SET PASSWORD FOR 用户名 = PASSWORD('密码') -- 为指定用户设置密码-- 删除用户DROP USER 用户名-- 分配权限/添加用户GRANT 权限列表 ON 表名 TO 用户名 [IDENTIFIED BY [PASSWORD] 'password'] - all privileges 表示所有权限 - *.* 表示所有库的所有表 - 库名.表名 表示某库下面的某表 GRANT ALL PRIVILEGES ON `pms`.* TO 'pms'@'%' IDENTIFIED BY 'pms0817';-- 查看权限SHOW GRANTS FOR 用户名 -- 查看当前用户权限 SHOW GRANTS; 或 SHOW GRANTS FOR CURRENT_USER; 或 SHOW GRANTS FOR CURRENT_USER();-- 撤消权限REVOKE 权限列表 ON 表名 FROM 用户名REVOKE ALL PRIVILEGES, GRANT OPTION FROM 用户名 -- 撤销所有权限-- 权限层级-- 要使用GRANT或REVOKE，您必须拥有GRANT OPTION权限，并且您必须用于您正在授予或撤销的权限。全局层级：全局权限适用于一个给定服务器中的所有数据库，mysql.user GRANT ALL ON *.*和 REVOKE ALL ON *.*只授予和撤销全局权限。数据库层级：数据库权限适用于一个给定数据库中的所有目标，mysql.db, mysql.host GRANT ALL ON db_name.*和REVOKE ALL ON db_name.*只授予和撤销数据库权限。表层级：表权限适用于一个给定表中的所有列，mysql.talbes_priv GRANT ALL ON db_name.tbl_name和REVOKE ALL ON db_name.tbl_name只授予和撤销表权限。列层级：列权限适用于一个给定表中的单一列，mysql.columns_priv 当使用REVOKE时，您必须指定与被授权列相同的列。-- 权限列表ALL [PRIVILEGES] -- 设置除GRANT OPTION之外的所有简单权限ALTER -- 允许使用ALTER TABLEALTER ROUTINE -- 更改或取消已存储的子程序CREATE -- 允许使用CREATE TABLECREATE ROUTINE -- 创建已存储的子程序CREATE TEMPORARY TABLES -- 允许使用CREATE TEMPORARY TABLECREATE USER -- 允许使用CREATE USER, DROP USER, RENAME USER和REVOKE ALL PRIVILEGES。CREATE VIEW -- 允许使用CREATE VIEWDELETE -- 允许使用DELETEDROP -- 允许使用DROP TABLEEXECUTE -- 允许用户运行已存储的子程序FILE -- 允许使用SELECT...INTO OUTFILE和LOAD DATA INFILEINDEX -- 允许使用CREATE INDEX和DROP INDEXINSERT -- 允许使用INSERTLOCK TABLES -- 允许对您拥有SELECT权限的表使用LOCK TABLESPROCESS -- 允许使用SHOW FULL PROCESSLISTREFERENCES -- 未被实施RELOAD -- 允许使用FLUSHREPLICATION CLIENT -- 允许用户询问从属服务器或主服务器的地址REPLICATION SLAVE -- 用于复制型从属服务器（从主服务器中读取二进制日志事件）SELECT -- 允许使用SELECTSHOW DATABASES -- 显示所有数据库SHOW VIEW -- 允许使用SHOW CREATE VIEWSHUTDOWN -- 允许使用mysqladmin shutdownSUPER -- 允许使用CHANGE MASTER, KILL, PURGE MASTER LOGS和SET GLOBAL语句，mysqladmin debug命令；允许您连接（一次），即使已达到max_connections。UPDATE -- 允许使用UPDATEUSAGE -- “无权限”的同义词GRANT OPTION -- 允许授予权限/* 表维护 */-- 分析和存储表的关键字分布ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE 表名 ...-- 检查一个或多个表是否有错误CHECK TABLE tbl_name [, tbl_name] ... [option] ...option = {QUICK | FAST | MEDIUM | EXTENDED | CHANGED}-- 整理数据文件的碎片OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] .../* 杂项 */ ------------------1. 可用反引号（`）为标识符（库名、表名、字段名、索引、别名）包裹，以避免与关键字重名！中文也可以作为标识符！2. 每个库目录存在一个保存当前数据库的选项文件db.opt。3. 注释： 单行注释 # 注释内容 多行注释 /* 注释内容 */ 单行注释 -- 注释内容 (标准SQL注释风格，要求双破折号后加一空格符（空格、TAB、换行等）)4. 模式通配符： _ 任意单个字符 % 任意多个字符，甚至包括零字符 单引号需要进行转义 \\'5. CMD命令行内的语句结束符可以为 \";\", \"\\G\", \"\\g\"，仅影响显示结果。其他地方还是用分号结束。delimiter 可修改当前对话的语句结束符。6. SQL对大小写不敏感7. 清除已有语句：\\c","link":"/2019/04/18/一千行-MySQL-学习笔记-转载.html"},{"title":"安装、部分配置icarus主题中文版","text":"摘要发现icarus主题还不错，花了一两个小时研究了下安装、部分配置icarus主题中文版 安装icarus 直接下载主题模块放到blog项目 ,blog项目根目录执行 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus 此时已经下载到项目中。 顶级_config.yml中选择icarus主题 1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: icarus 此时主题已经安装好，清除、编译、部署可以看到效果了 配置icarus 完全参照官网配置，进行翻译解说 配置文章部分顶部图片添加icarus 主题中的配置_config.yml中开启图片开关 12article: thumbnail: true 文章.md文件头中添加图片绝对/相对地址 12345title: Getting Started with Icarusthumbnail: /gallery/thumbnails/desert.jpg// thumbnail:https://raw.githubusercontent.com/removeif/blog_image/master/20190620152744.png---Post content... 配置完成后部署显示效果如下(最新文章列表显示缩略图、文章开头显示一张设置图片) 左边文章导航栏开启icarus 主题中的配置_config.yml中开关 1234widgets: - type: toc position: left 同事文章顶部加入标签 1234title: Table of Contents Exampletoc: true---Post content... 配置效果 评论系统开启icarus 主题中的配置_config.yml中开启（部分评论系统需要翻墙才能使用，valine不用翻墙个人推荐，valine安装参考） 1234567comment: type: valine app_id: xxxxxxxx # (required) LeanCloud application id app_key: xxxxxxxx # (required) LeanCloud application key notify: false # (optional) receive email notification verify: false # (optional) show verification code placeholder: xxxxxxxx # (optional) comment box placeholder text 开启效果 捐赠收款开启icarus 主题中的配置_config.yml中开启 注意如果默认不配置，编译时有报错，可以# 把它注释掉，不启用功能 1234567891011donate: - # Donation entry name type: alipay # Qrcode image URL qrcode: 'https://wx2.sinaimg.cn/large/b5d1b710gy1g0lvxdcwm0j20p011i4bg.jpg' - # Donation entry name type: wechat # Qrcode image URL qrcode: 'https://wx2.sinaimg.cn/large/b5d1b710gy1g0lvwdcpb5j20u014qgy2.jpg' 开启配置效果如下 全局搜索开启icarus 主题中的配置_config.yml中开启,不同的搜索类型需要安装插件参考官网,type: insight此类型不需要安装，已经内置 12search: type: insight 效果如下 更多配置请参考官网配置目前配置基本已经够使用，还需要更多配置请参考连接 参考自","link":"/2019/02/28/安装、部分配置icarus主题中文版.html"},{"title":"java基础-static关键字","text":"static用法 static和final是两个我们必须掌握的关键字。不同于其他关键字，他们都有多种用法，而且在一定环境下使用，可以提高程序的运行性能，优化程序的结构。下面我们先来了解一下static关键字及其用法。 修饰成员变量在我们平时的使用当中，static最常用的功能就是修饰类的属性和方法，让他们成为类的成员属性和方法，我们通常将用static修饰的成员称为类成员或者静态成员。 1234567891011121314151617181920212223public class Person { String name; int age; public String toString() { return \"Name:\" + name + \", Age:\" + age; } public static void main(String[] args) { Person p1 = new Person(); p1.name = \"zhangsan\"; p1.age = 10; Person p2 = new Person(); p2.name = \"lisi\"; p2.age = 12; System.out.println(p1); System.out.println(p2); } /**Output * Name:zhangsan, Age:10 * Name:lisi, Age:12 *///~} 根据Person构造出的每一个对象都是独立存在的，保存有自己独立的成员变量，相互不会影响，他们在内存中的示意如下: 从上图中可以看出，p1和p2两个变量引用的对象分别存储在内存中堆区域的不同地址中，所以他们之间相互不会干扰。但其实，在这当中，我们省略了一些重要信息，相信大家也都会想到，对象的成员属性都在这了，由每个对象自己保存，那么他们的方法呢？实际上，不论一个类创建了几个对象，他们的方法都是一样的： 从上面的图中我们可以看到，两个Person对象的方法实际上只是指向了同一个方法定义。这个方法定义是位于内存中的一块不变区域（由jvm划分），我们暂称它为静态存储区。这一块存储区不仅存放了方法的定义，实际上从更大的角度而言，它存放的是各种类的定义，当我们通过new来生成对象时，会根据这里定义的类的定义去创建对象。多个对象仅会对应同一个方法，这里有一个让我们充分信服的理由，那就是不管多少的对象，他们的方法总是相同的，尽管最后的输出会有所不同，但是方法总是会按照我们预想的结果去操作，即不同的对象去调用同一个方法，结果会不尽相同。 static关键字可以修饰成员变量和方法，来让它们变成类的所属，而不是对象的所属，比如我们将Person的age属性用static进行修饰，结果会是什么样呢? 1234567891011public class Person { String name; static int age; /* 其余代码不变... */ /**Output * Name:zhangsan, Age:12 * Name:lisi, Age:12 *///~} 我们发现，结果发生了一点变化，在给p2的age属性赋值时，干扰了p1的age属性，这是为什么呢？我们还是来看他们在内存中的示意： 我们发现，给age属性加了static关键字之后，Person对象就不再拥有age属性了，age属性会统一交给Person类去管理，即多个Person对象只会对应一个age属性，一个对象如果对age属性做了改变，其他的对象都会受到影响。我们看到此时的age和toString()方法一样，都是交由类去管理。 虽然我们看到static可以让对象共享属性，但是实际中我们很少这么用，也不推荐这么使用。因为这样会让该属性变得难以控制，因为它在任何地方都有可能被改变。如果我们想共享属性，一般我们会采用其他的办法： 1234567891011121314151617181920212223242526272829public class Person { private static int count = 0; int id; String name; int age; public Person() { id = ++count; } public String toString() { return \"Id:\" + id + \", Name:\" + name + \", Age:\" + age; } public static void main(String[] args) { Person p1 = new Person(); p1.name = \"zhangsan\"; p1.age = 10; Person p2 = new Person(); p2.name = \"lisi\"; p2.age = 12; System.out.println(p1); System.out.println(p2); } /**Output * Id:1, Name:zhangsan, Age:10 * Id:2, Name:lisi, Age:12 *///~} 上面的代码起到了给Person的对象创建一个唯一id以及记录总数的作用，其中count由static修饰，是Person类的成员属性，每次创建一个Person对象，就会使该属性自加1然后赋给对象的id属性，这样，count属性记录了创建Person对象的总数，由于count使用了private修饰，所以从类外面无法随意改变。 修饰成员方法static的另一个作用，就是修饰成员方法。相比于修饰成员属性，修饰成员方法对于数据的存储上面并没有多大的变化，因为我们从上面可以看出，方法本来就是存放在类的定义当中的。static修饰成员方法最大的作用，就是可以使用”类名.方法名“的方式操作方法，避免了先要new出对象的繁琐和资源消耗，我们可能会经常在帮助类中看到它的使用： 12345678910public class PrintHelper { public static void print(Object o){ System.out.println(o); } public static void main(String[] args) { PrintHelper.print(\"Hello world\"); }} 上面便是一个例子（现在还不太实用），但是我们可以看到它的作用，使得static修饰的方法成为类的方法，使用时通过“类名.方法名”的方式就可以方便的使用了，相当于定义了一个全局的函数（只要导入该类所在的包即可）。不过它也有使用的局限，一个static修饰的类中，不能使用非static修饰的成员变量和方法，这很好理解，因为static修饰的方法是属于类的，如果去直接使用对象的成员变量，它会不知所措（不知该使用哪一个对象的属性）。 静态块在说明static关键字的第三个用法时，我们有必要重新梳理一下一个对象的初始化过程。以下面的代码为例： 1234567891011121314151617181920212223242526272829class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2 = new Book(\"static成员book2成员变量初始化\"); public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4 = new Book(\"static成员book4成员变量初始化\"); public static void main(String[] args) { Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 上面的例子中，Person类中组合了四个Book成员变量，两个是普通成员，两个是static修饰的类成员。我们可以看到，当我们new一个Person对象时，static修饰的成员变量首先被初始化，随后是普通成员，最后调用Person类的构造方法完成初始化。也就是说，在创建对象时，static修饰的成员会首先被初始化，而且我们还可以看到，如果有多个static修饰的成员，那么会按照他们的先后位置进行初始化。 实际上，static修饰的成员的初始化可以更早的进行，请看下面的例子： 12345678910111213141516171819202122232425262728293031323334353637class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2 = new Book(\"static成员book2成员变量初始化\"); public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4 = new Book(\"static成员book4成员变量初始化\"); public static void funStatic() { System.out.println(\"static修饰的funStatic方法\"); } public static void main(String[] args) { Person.funStatic(); System.out.println(\"****************\"); Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * static修饰的funStatic方法 * *************** * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 在上面的例子中我们可以发现两个有意思的地方，第一个是当我们没有创建对象，而是通过类去调用类方法时，尽管该方法没有使用到任何的类成员，类成员还是在方法调用之前就初始化了，这说明，当我们第一次去使用一个类时，就会触发该类的成员初始化。第二个是当我们使用了类方法，完成类的成员的初始化后，再new该类的对象时，static修饰的类成员没有再次初始化，这说明，static修饰的类成员，在程序运行过程中，只需要初始化一次即可，不会进行多次的初始化。 回顾了对象的初始化以后，我们再来看static的第三个作用就非常简单了，那就是当我们初始化static修饰的成员时，可以将他们统一放在一个以static开始，用花括号包裹起来的块状语句中： 123456789101112131415161718192021222324252627282930313233343536373839404142class Book{ public Book(String msg) { System.out.println(msg); }}public class Person { Book book1 = new Book(\"book1成员变量初始化\"); static Book book2; static { book2 = new Book(\"static成员book2成员变量初始化\"); book4 = new Book(\"static成员book4成员变量初始化\"); } public Person(String msg) { System.out.println(msg); } Book book3 = new Book(\"book3成员变量初始化\"); static Book book4; public static void funStatic() { System.out.println(\"static修饰的funStatic方法\"); } public static void main(String[] args) { Person.funStatic(); System.out.println(\"****************\"); Person p1 = new Person(\"p1初始化\"); } /**Output * static成员book2成员变量初始化 * static成员book4成员变量初始化 * static修饰的funStatic方法 * *************** * book1成员变量初始化 * book3成员变量初始化 * p1初始化 *///~} 我们将上一个例子稍微做了一下修改，可以看到，结果没有二致。 静态导包相比于上面的三种用途，第四种用途可能了解的人就比较少了，但是实际上它很简单，而且在调用类方法时会更方便。以上面的“PrintHelper”的例子为例，做一下稍微的变化，即可使用静态导包带给我们的方便： 123456789/* PrintHelper.java文件 */package com.dotgua.study;public class PrintHelper { public static void print(Object o){ System.out.println(o); }} 123456789101112import static com.dotgua.study.PrintHelper.*; // 导入上面的包public class App { public static void main( String[] args ) { print(\"Hello World!\"); } /**Output * Hello World! *///~} 上面的代码来自于两个java文件，其中的PrintHelper很简单，包含了一个用于打印的static方法。而在App.java文件中，我们首先将PrintHelper类导入，这里在导入时，我们使用了static关键字，而且在引入类的最后还加上了“.*”，它的作用就是将PrintHelper类中的所有类方法直接导入。不同于非static导入，采用static导入包后，在不与当前类的方法名冲突的情况下，无需使用“类名.方法名”的方法去调用类方法了，直接可以采用”方法名“去调用类方法，就好像是该类自己的方法一样使用即可。 总结static是java中非常重要的一个关键字，而且它的用法也很丰富，主要有四种用法： 用来修饰成员变量，将其变为类的成员，从而实现所有对象对于该成员的共享； 用来修饰成员方法，将其变为类方法，可以直接使用“类名.方法名”的方式调用，常用于工具类； 静态块用法，将多个类成员放在一起初始化，使得程序更加规整，其中理解对象的初始化过程非常关键； 静态导包用法，将类的方法直接导入到当前类中，从而直接使用“方法名”即可调用类方法，更加方便。 参考自","link":"/2019/01/07/java基础-static关键字.html"},{"title":"java基础-final关键字","text":"final 关键字 在java的关键字中，static和final是两个我们必须掌握的关键字。不同于其他关键字，他们都有多种用法，而且在一定环境下使用，可以提高程序的运行性能，优化程序的结构。下面我们来了解一下final关键字及其用法。 修饰数据在编写程序时，我们经常需要说明一个数据是不可变的，我们成为常量。在java中，用final关键字修饰的变量，只能进行一次赋值操作，并且在生存期内不可以改变它的值。更重要的是，final会告诉编译器，这个数据是不会修改的，那么编译器就可能会在编译时期就对该数据进行替换甚至执行计算，这样可以对我们的程序起到一点优化。不过在针对基本类型和引用类型时，final关键字的效果存在细微差别。我们来看下面的例子： 123456789101112131415161718192021222324 class Value { int v; public Value(int v) { this.v = v; }}public class FinalTest { final int f1 = 1; final int f2; public FinalTest() { f2 = 2; } public static void main(String[] args) { final int value1 = 1; // value1 = 4; final double value2; value2 = 2.0; final Value value3 = new Value(1); value3.v = 4; }} 上面的例子中，我们先来看一下main方法中的几个final修饰的数据，在给value1赋初始值之后，我们无法再对value1的值进行修改，final关键字起到了常量的作用。从value2我们可以看到，final修饰的变量可以不在声明时赋值，即可以先声明，后赋值。value3时一个引用变量，这里我们可以看到final修饰引用变量时，只是限定了引用变量的引用不可改变，即不能将value3再次引用另一个Value对象，但是引用的对象的值是可以改变的，从内存模型中我们看的更加清晰： 上图中，final修饰的值用粗线条的边框表示它的值是不可改变的，我们知道引用变量的值实际上是它所引用的对象的地址，也就是说该地址的值是不可改变的，从而说明了为什么引用变量不可以改变引用对象。而实际引用的对象实际上是不受final关键字的影响的，所以它的值是可以改变的。 另一方面，我们看到了用final修饰成员变量时的细微差别，因为final修饰的数据的值是不可改变的，所以我们必须确保在使用前就已经对成员变量赋值了。因此对于final修饰的成员变量，我们有且只有两个地方可以给它赋值，一个是声明该成员时赋值，另一个是在构造方法中赋值，在这两个地方我们必须给它们赋初始值。 最后我们需要注意的一点是，同时使用static和final修饰的成员在内存中只占据一段不能改变的存储空间。 修饰方法参数前面我们可以看到，如果变量是我们自己创建的，那么使用final修饰表示我们只会给它赋值一次且不会改变变量的值。那么如果变量是作为参数传入的，我们怎么保证它的值不会改变呢？这就用到了final的第二种用法，即在我们编写方法时，可以在参数前面添加final关键字，它表示在整个方法中，我们不会（实际上是不能）改变参数的值： 12345678910public class FinalTest { /* ... */ public void finalFunc(final int i, final Value value) { // i = 5; 不能改变i的值 // v = new Value(); 不能改变v的值 value.v = 5; // 可以改变引用对象的值 }} 修饰方法第三种方式，即用final关键字修饰方法，它表示该方法不能被覆盖。这种使用方式主要是从设计的角度考虑，即明确告诉其他可能会继承该类的程序员，不希望他们去覆盖这个方法。这种方式我们很容易理解，然而，关于private和final关键字还有一点联系，这就是类中所有的private方法都隐式地指定为是final的，由于无法在类外使用private方法，所以也就无法覆盖它。 修饰类了解了final关键字的其他用法，我们很容易可以想到使用final关键字修饰类的作用，那就是用final修饰的类是无法被继承的。 上面我们讲解了final的四种用法，然而，对于第三种和第四种用法，我们却甚少使用。这不是没有道理的，从final的设计来讲，这两种用法甚至可以说是鸡肋，因为对于开发人员来讲，如果我们写的类被继承的越多，就说明我们写的类越有价值，越成功。即使是从设计的角度来讲，也没有必要将一个类设计为不可继承的。Java标准库就是一个很好的反例，特别是Java 1.0/1.1中Vector类被如此广泛的运用，如果所有的方法均未被指定为final的话，它可能会更加有用。如此有用的类，我们很容易想到去继承和重写他们，然而，由于final的作用，导致我们对Vector类的扩展受到了一些阻碍，导致了Vector并没有完全发挥它应有的全部价值。 总结final关键字是我们经常使用的关键字之一，它的用法有很多，但是并不是每一种用法都值得我们去广泛使用。它的主要用法有以下四种： 用来修饰数据，包括成员变量和局部变量，该变量只能被赋值一次且它的值无法被改变。对于成员变量来讲，我们必须在声明时或者构造方法中对它赋值； 用来修饰方法参数，表示在变量的生存期中它的值不能被改变； 修饰方法，表示该方法无法被重写； 修饰类，表示该类无法被继承。 上面的四种方法中，第三种和第四种方法需要谨慎使用，因为在大多数情况下，如果是仅仅为了一点设计上的考虑，我们并不需要使用final来修饰方法和类。 参考自","link":"/2019/01/07/java基础-final关键字.html"},{"title":"Java设计模式之代理模式","text":"代理模式代理(Proxy)是一种设计模式,提供了对目标对象另外的访问方式;即通过代理对象访问目标对象.这样做的好处是:可以在目标对象实现的基础上,增强额外的功能操作,即扩展目标对象的功能.这里使用到编程中的一个思想:不要随意去修改别人已经写好的代码或者方法,如果需改修改,可以通过代理的方式来扩展该方法 举个例子来说明代理的作用:假设我们想邀请一位明星,那么并不是直接连接明星,而是联系明星的经纪人,来达到同样的目的.明星就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的代理人(经纪人)来解决.这就是代理思想在现实中的一个例子.图片表示如下： 代理模式的关键点是:代理对象与目标对象.代理对象是对目标对象的扩展,并会调用目标对象 静态代理静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类. eg:模拟保存动作,定义一个保存动作的接口:IUserDao.java,然后目标对象实现这个接口的方法UserDao.java,此时如果使用静态代理方式,就需要在代理对象(UserDaoProxy.java)中也实现IUserDao接口.调用的时候通过调用代理对象的方法来调用目标对象.需要注意的是,代理对象与目标对象要实现相同的接口,然后通过调用相同的方法来调用目标对象的方法 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * @desc 用户保存接口 */public interface IUserDao { // 保存方法 void save();}/** * @desc 用户保存 */public class UserDao implements IUserDao { @Override public void save() { System.out.println(\"OK，已保存数据!\"); }}/** * @desc 代理对象，静态代理 */public class UserDaoProxy implements IUserDao { // 目标对象 private IUserDao target; public UserDaoProxy(IUserDao user) { this.target = user; } @Override public void save() { System.out.println(\"开始事物.\"); target.save(); System.out.println(\"提交事物.\"); }}/** * @desc 静态代理测试方法 */public class MainTest { public static void main(String[] args) { // 目标对象 IUserDao userDao = new UserDao(); // 代理对象，把目标对象传给代理，建立代理关系 UserDaoProxy proxy = new UserDaoProxy(userDao); proxy.save(); }} 结果： 静态代理总结:1.可以做到在不修改目标对象的功能前提下,对目标功能扩展.2.缺点: 因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护. 如何解决静态代理中的缺点呢?答案是可以使用动态代理方式 动态代理动态代理有以下特点: 代理对象,不需要实现接口 .代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型) 动态代理也叫做:JDK代理,接口代理 JDK中生成代理对象的API代理类所在包:java.lang.reflect.ProxyJDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是: 1static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h ) 注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为: ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入 代码示例:接口类IUserDao.java以及接口实现类,目标对象UserDao是一样的,没有做修改.在这个基础上,增加一个代理工厂类(ProxyFactory.java),将代理类写在这个地方,然后在测试类(需要使用到代理的代码)中先建立目标对象和代理对象的联系,然后代用代理对象的中同名方法 示例代码代理工厂类:ProxyFactory.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * @desc 动态代理工厂 */public class ProxyFactory { private Object target; /** * 维护一个目标对象 * * @param target */ public ProxyFactory(Object target) { this.target = target; } public Object getProxyInstance() { return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"开始事物2.\"); // 执行目标方法 Object returnValue = method.invoke(target, args); System.out.println(\"提交事物2.\"); return returnValue; } }); }}/** * @desc 动态代理测试方法 */public class MainTest { public static void main(String[] args) { // 目标对象 IUserDao userDao = new UserDao(); // 原始类型 System.out.println(userDao.getClass()); // 给目标对象，创建代理对象 IUserDao proxy = (IUserDao) new ProxyFactory(userDao).getProxyInstance(); // 内存中动态生成的代理对象 System.out.println(proxy.getClass()); // 执行方法 proxy.save(); }} 结果： 总结代理对象不需要实现接口,但是目标对象一定要实现接口,否则不能用动态代理 Cglib代理上面的静态代理和动态代理模式都是要求目标对象是实现一个接口的目标对象,但是有时候目标对象只是一个单独的对象,并没有实现任何的接口,这个时候就可以使用以目标对象子类的方式类实现代理,这种方法就叫做:Cglib代理 一. Cglib代理,也叫作子类代理,它是在内存中构建一个子类对象从而实现对目标对象功能的扩展. JDK的动态代理有一个限制,就是使用动态代理的对象必须实现一个或多个接口,如果想代理没有实现接口的类,就可以使用Cglib实现. Cglib是一个强大的高性能的代码生成包,它可以在运行期扩展java类与实现java接口.它广泛的被许多AOP的框架使用,例如Spring AOP和synaop为他们提供方法的interception(拦截) Cglib包的底层是通过使用一个小而块的字节码处理框架ASM来转换字节码并生成新的类.不鼓励直接使用ASM,因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉. 二. Cglib子类代理实现方法: 需要引入cglib的jar文件,但是Spring的核心包中已经包括了Cglib功能,所以直接引入spring-core-3.2.5.jar即可. 引入功能包后,就可以在内存中动态构建子类 代理的类不能为final,否则报错 目标对象的方法如果为final/static,那么就不会被拦截,即不会执行目标对象额外的业务方法. 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 目标对象,没有实现任何接口 */public class UserDao { public void save() { System.out.println(\"----已经保存数据!----\"); }}/** * Cglib子类代理工厂 * 对UserDao在内存中动态构建一个子类对象 */public class ProxyFactory implements MethodInterceptor{ //维护目标对象 private Object target; public ProxyFactory(Object target) { this.target = target; } //给目标对象创建一个代理对象 public Object getProxyInstance(){ //1.工具类 Enhancer en = new Enhancer(); //2.设置父类 en.setSuperclass(target.getClass()); //3.设置回调函数 en.setCallback(this); //4.创建子类(代理对象) return en.create(); } @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.println(\"开始事务...\"); //执行目标对象的方法 Object returnValue = method.invoke(target, args); System.out.println(\"提交事务...\"); return returnValue; }}/** * 测试类 */public class App { @Test public void test(){ //目标对象 UserDao target = new UserDao(); //代理对象 UserDao proxy = (UserDao)new ProxyFactory(target).getProxyInstance(); //执行代理对象的方法 proxy.save(); }} 总结动态代理与静态代理相比较，最大的好处是接口中声明的所有方法都被转移到调用处理器一个集中的方法中处理。在接口方法数量比较多的时候，我们可以进行灵活处理，而不需要像静态代理那样对每一个方法或方法组合进行处理。Proxy 很美很强大，但是仅支持 interface 代理。Java 的单继承机制注定了这些动态代理类们无法实现对 class 的动态代理。好在有cglib为Proxy提供了弥补。class与interface的区别本来就模糊，在java8中更是增加了一些新特性，使得interface越来越接近class，当有一日，java突破了单继承的限制，动态代理将会更加强大。 参考：http://www.cnblogs.com/cenyu/p/6289209.html http://blog.csdn.net/goskalrie/article/details/52458773","link":"/2019/01/06/Java设计模式之代理模式.html"},{"title":"Java设计模式之命令模式","text":"目的 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化；对请求排队或记录日志，以及支持可撤销的操作。 将”发出请求的对象”和”接收与执行这些请求的对象”分隔开来。 效果 command模式将调用操作的对象和实现该操作的对象解耦 可以将多个命令装配成一个复合命令，复合命令是Composite模式的一个实例 增加新的command很容易，无需改变已有的类 适用性 抽象出待执行的动作以参数化某对象 在不同的时刻指定、排列和执行请求。如请求队列 支持取消操作 支持修改日志 用构建在原语操作上的高层操作构造一个系统。支持事物 参与者 Command声明执行操作的接口 ConcreteCommand将一个接收者对象绑定于一个动作 调用接收者相应的操作，以实现execute Client创建一个具体命令对象并设定它的接收者 Invoker要求该命令执行这个请求 Receiver知道如何实施与执行一个请求相关的操作。任何类都可能作为一个接收者 结构图 协作： 1)、client创建一个ConcreteCommand对象并指定它的Receiver对象 2)、某Invoker对象存储该ConcreteCommand对象 3)、该Invoker通过调用Command对象的execute操作来提交一个请求。若该命令是可撤销的，ConcreteCommand在执行execute操作前存储当前状态以用于取消该命令 4)、ConcreteCommand对象调用它的Receiver的操作以执行该请求 命令对象将动作和接受者包进对象中，这个对象只暴露出一个execute()方法，当此方法被调用的时候，接收者就会进行这些动作。从外面来看，其他对象不知道究竟哪个接收者进行了哪些动作，只知道如果调用execute()方法，请求的目的就能达到。 java 实现源码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * @desc 命令接口 */public interface Command { /** * 执行命令 */ void excute(); /** * 撤销命令 */ void undo();}/** * @desc 真正命令执行者，接收者 */public class Receiver { public void action() { System.out.println(\"正在执行命令...\"); } public void unAction() { System.out.println(\"正在撤销命令...\"); }}/** * @desc 创建命令（可实现多条命令以及多个命令执行人） */public class CreateCommand implements Command { private Receiver receiver; /** * 初始化命令接收人 * * @param receiver */ public CreateCommand(Receiver receiver) { this.receiver = receiver; } @Override public void excute() { receiver.action(); } @Override public void undo() { receiver.unAction(); }}/** * @desc 命令调用者 */public class Invoker { private Command command; /** * 命令调用者持有该命令 * * @param command */ public Invoker(Command command) { this.command = command; } /** * 执行命令 */ public void runCommand() { command.excute(); } /** * 撤销命令 */ public void unRunCommand() { command.undo(); }}/** * @desc 命令模式测试 */public class TestMain { public static void main(String[] args) { // new 一个命令执行人 Receiver receiver = new Receiver(); // new 一条命令 Command command = new CreateCommand(receiver); // 开始调用命令 Invoker invoker = new Invoker(command); invoker.runCommand(); invoker.unRunCommand(); }} 执行结果 常见应用： 1、工作队列，线程池，日程安排 2、日志请求(系统恢复)要点： 1、命令模式将发出请求的对象和执行请求的对象解耦 2、在被解耦的两者之间是通过命令对象进行沟通的。命令对象封装了接收者和一个或一组动作 3、调用者通过调用命令对象的execute()发出请求，这会使得接收者的动作被调用 4、调用者可以接受命令当作参数，甚至在运行时动态的进行 5、命令可以支持撤销，做法是实现一个undo()方法来回到execute()被执行前的状态 6、宏命令是命令的一种简单的延伸，允许调用多个命令。宏方法也可以支持撤销 7、实际操作时，很常见使用”聪明”命令对象，也就是直接实现了请求，而不是将工作委托给接受者(弊端？) 8、命令也可以用来实现日志和事物系统 参考：http://www.cnblogs.com/ikuman/archive/2013/08/06/3233092.html","link":"/2019/01/04/Java设计模式之命令模式.html"},{"title":"java 8部分读书笔记","text":"Lambda 表达式 Lambda 表达式引用的是值，不是变量。 Lambda 表达式中的变量只能是final类型，只能给变量赋值一次。 123String name = getUserName();name = formatUesrName();button.addActionListener(event -&gt; System.out.println(\"Hi\" + name)) 如上代码将不会编译通过，name被赋值多次。 函数接口：只有一个抽象方法的接口，用作Lambda表达式的类型。 Java中重要的几个函数接口 名称 解释 返回值 eg 参数 Predicate 断言 boolean 这张唱片已经发行了吗 T Consumer 消费 void 输出一个值 T Function&lt;T,R&gt; 运行 R 获得Artist对象的名字 T Supplier 供应 T 工厂方法 None UnaryOperator 一元运算 T 逻辑非(!) T BinaryOperator 二元运算 T 求两个数的乘积 (T,T) 所有的都有泛型没有的话值代码编译不过 123Predicate&lt;Integer&gt; atLeast5 = x -&gt; x &gt; 5;// 编译通过Predicate atLeast5 = x -&gt; x &gt; 5;// 编译不通过BinaryOperator&lt;Long&gt; addLongs = (x , y) -&gt; x + y;// 编译通过 流 Stream(针对于集合) 惰性求值 和及早求值 1allArtists.stream().filter(artist -&gt; artist.isFrom(\"London\")); 这行代码并没有做什么实质性工作,filter只是刻画出了Stream，没有产生新的集合。像filter这种只描述Stream，不产生新集合的方法叫做惰性求值方法,而像count这样最终会从Stream产生值的方法叫做及早求值方法。 123456789allArtists.stream().filter(artist - &gt;{ System.out.println(artist.getName()); return artist.isFrom(\"London\");});// 此段代码并不会输出 艺术家名字allArtists.stream().filter(artist - &gt;{ System.out.println(artist.getName()); return artist.isFrom(\"London\");}).count();// 此段代码并会输出 艺术家名字 判断一个操作是惰性求值还是及早求值，只需看它的返回值，返回值是Stream,那么就是惰性求值，返回值是另一个值或者是空，则是及早求值。最终达到的效果：通过这些方法形成一个惰性求值的链，最终调用一个及早求值方法得到我们需要的最终结果。 常用的流操作 collect(toList()) :由Stream里的值生成一个列表 Stream的of 方法使用一组初始值生成新的Stream 12List&lt;String&gt; collected = Stream.of(\"a\",\"b\",\"c\").collect(Collectors.toList());assertEquals(Arrays.asList(\"a\",\"b\",\"c\"),collected);//判断结果和预期值是否一样 map 将一种类型转换为另一种类型，将一个流中的值转换为一个新的流。mapToInt/mapToDouble/mapToLong 123List&lt;String&gt; collected = Stream.of(\"a\",\"b\",\"hello\") .map(string -&gt; string.toUpperCase()) .collect(Collectors.toList());//将小写转换为大写 filter filter模式，保留Stream中的一些元素，过滤掉其他的。返回true保留，返回false过滤。 123List&lt;String&gt; beginWithNumbers = Stream.of(\"a\",\"1adf\",\"abc1\") .filter(value -&gt; isDigit(value.chartAt(0))) .collect(toList());//返回数据开头的字符串 flatMap :可用Stream替换值，将多个Stream连接成一个Stream 123List&lt;Integer&gt; together = Stream.of(asList(1,2), asList(3,4)) .flatMap(numbers -&gt; numbers.stream()) .collect(toList()); 它会把原流中的每一个元素经过指定函数处理之后，返回一个Stream对象，并将之展开到原父流中。 max和min 1234List&lt;Track&gt; tracks = asList(new Track(\"Bakai\",524), new Track(\"Violets\",378), new Track(\"Time\",451));Track shortestTrack = tracks.stream().min(Commparator.comparing(track -&gt; track.getLength())).get();// 查找距离最短的 reduce 聚合归纳：操作中可以实现从一组值生成一个值 使用reduce求和 12int count = Stream.of(1,2,3) .reduce(0, (acc, element) -&gt; acc + element); 展开reduce操作 123456BinaryOperator&lt;Integer&gt; accumulator = (acc, element) -&gt; acc + element;int count = accumulator.apply( accumulator.apply( accumulator.apply(0, 1), 2), 3); 1collections.stream().map(Entity::getNum).reduce(0, Integer::sum); // collections求和num 1234//根据typeId分组 entities[{typeId:1,name:\"火锅\"},{typeId:1,name:\"烧烤\"}，{typeId:2,name:\"律师\"}]Map&lt;Integer, List&lt;Entity&gt;&gt; groups = entities.stream() .collect(Collectors.groupingBy(Entity::getTypeId));List&lt;Entity&gt; list = groups.get(typeId); //拿到对应的分组数据 找出长度大于一分钟的曲目 1234567public Set&lt;String&gt; findLongTracks(List&lt;Album&gt; albums){ return albums.stream() .flatMap(album -&gt; album.getTracks()) .filter(track -&gt; track.getLength() &gt; 60) .map(track -&gt; track.getName) .collect(toSet());}","link":"/2018/12/19/java-8部分读书笔记.html"},{"title":"Java设计模式之适配器模式","text":"定义 适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。 适配器模式的用途用电器做例子，笔记本电脑的插头一般都是三相的，即除了阳极、阴极外，还有一个地极。而有些地方的电源插座却只有两极，没有地极。电源插座与笔记本电脑的电源插头不匹配使得笔记本电脑无法使用。这时候一个三相到两相的转换器（适配器）就能解决此问题，而这正像是本模式所做的事情。 适配器模式的结构适配器模式有类的适配器模式和对象的适配器模式两种不同的形式。 类适配器模式类的适配器模式把适配的类的API转换成为目标类的API。 在上图中可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。为使客户端能够使用Adaptee类，提供一个中间环节，即类Adapter，把Adaptee的API与Target类的API衔接起来。Adapter与Adaptee是继承关系，这决定了这个适配器模式是类的： 模式所涉及的角色有： ● 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 ● 源(Adapee)角色：现在需要适配的接口。 ● 适配器(Adapter)角色：适配器类是本模式的核心。适配器把源接口转换成目标接口。显然，这一角色不可以是接口，而必须是具体类。 java源码123456789101112131415161718192021222324252627282930313233343536public interface Target { /** * 这是源类Adaptee也有的方法 */ public void sampleOperation1(); /** * 这是源类Adapteee没有的方法 */ public void sampleOperation2(); }/**上面给出的是目标角色的源代码，这个角色是以一个JAVA接口的形式实现的。可以看出，这个接口声明了两个方法：*sampleOperation1()和sampleOperation2()。而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。*/public class Adaptee { public void sampleOperation1(){}}/**适配器角色Adapter扩展了Adaptee,同时又实现了目标(Target)接口。由于Adaptee没有提供sampleOperation2()方法，而目标接口又要求这个方法，因此适配器角色Adapter实现了这个方法。*/public class Adapter extends Adaptee implements Target { /** * 由于源类Adaptee没有方法sampleOperation2() * 因此适配器补充上这个方法 */ @Override public void sampleOperation2() { //写相关的代码 }} 对象适配器模式与类的适配器模式一样，对象的适配器模式把被适配的类的API转换成为目标类的API，与类的适配器模式不同的是，对象的适配器模式不是使用继承关系连接到Adaptee类，而是使用委派关系连接到Adaptee类。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。为使客户端能够使用Adaptee类，需要提供一个包装(Wrapper)类Adapter。这个包装类包装了一个Adaptee的实例，从而此包装类能够把Adaptee的API与Target类的API衔接起来。Adapter与Adaptee是委派关系，这决定了适配器模式是对象的。 java 源码实现1234567891011121314151617181920212223242526272829303132333435363738public interface Target { /** * 这是源类Adaptee也有的方法 */ public void sampleOperation1(); /** * 这是源类Adapteee没有的方法 */ public void sampleOperation2(); }public class Adaptee { public void sampleOperation1(){} }public class Adapter { private Adaptee adaptee; public Adapter(Adaptee adaptee){ this.adaptee = adaptee; } /** * 源类Adaptee有方法sampleOperation1 * 因此适配器类直接委派即可 */ public void sampleOperation1(){ this.adaptee.sampleOperation1(); } /** * 源类Adaptee没有方法sampleOperation2 * 因此由适配器类需要补充此方法 */ public void sampleOperation2(){ //写相关的代码 }} 类适配器模式和对象适配器模式的权衡 类适配器，使用对象继承的方式，是静态的定义方式；对象适配器，使用对象组合的方式，是动态组合的方式。 对于类适配器，由于适配器直接继承了Adaptee，使得适配器不能和Adaptee的子类一起工作，因为继承是静态的关系 对于对象适配器，一个适配器可以把多种不同的源适配到同一个目标。换言之，同一个适配器可以把源类和它的子类都适配到目标接口。因为对象适配器采用的是对象组合的关系，只要对象类型正确，是不是子类都无所谓。 对于类适配器，适配器可以重定义Adaptee的部分行为，相当于子类覆盖父类的部分实现方法。 对于对象适配器，要重定义Adaptee的行为比较困难，这种情况下，需要定义Adaptee的子类来实现重定义，然后让适配器组合子类。虽然重定义Adaptee的行为比较困难，但是想要增加一些新的行为则方便的很，而且新增加的行为可同时适用于所有的源。 对于类适配器，仅仅引入了一个对象，并不需要额外的引用来间接得到Adaptee。 对于对象适配器，需要额外的引用来间接得到Adaptee。 建议尽量使用对象适配器的实现方式，多用合成/聚合、少用继承。当然，具体问题具体分析，根据需要来选用实现方式，最适合的才是最好的。 适配器模式的优点 更好的复用性 系统需要使用现有的类，而此类的接口不符合系统的需要。那么通过适配器模式就可以让这些功能得到更好的复用。 更好的扩展性 在实现适配器功能的时候，可以调用自己开发的功能，从而自然地扩展系统的功能。 适配器模式的缺点过多的使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部被适配成了B接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 缺省适配器模式缺省适配(Default Adapter)模式为一个接口提供缺省实现，这样子类型可以从这个缺省实现进行扩展，而不必从原有接口进行扩展。作为适配器模式的一个特例，缺省是适配模式在JAVA语言中有着特殊的应用。 实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/***鲁智深的故事* 和尚要做什么呢？吃斋、念经、打坐、撞钟、习武等。如果设计一个和尚*接口，*给出所有的和尚都需要实现的方法，那么这个接口应当如下：*/public interface 和尚 { public void 吃斋（）； public void 念经（）； public void 打坐（）； public void 撞钟（）； public void 习武（）； public String getName();}/**显然，所有的和尚类都应当实现接口所定义的全部方法，不然就根本通不过JAVA语言编辑器。像下面的鲁智深类就不行。*/public class 鲁智深 implements 和尚{ public void 习武(){ 拳打镇关西； 大闹五台山； 大闹桃花村； 火烧瓦官寺； 倒拔垂杨柳； } public String getName(){ return \"鲁智深\"; }}/*** 由于鲁智深只实现了getName()和习武()方法，而没有实现任何其他的方法。因此，它根本就通不过Java语言编译器。*鲁智深类只有实现和尚接口的所有的方法才可以通过Java语言编译器，但是这样一来鲁智深就不再是鲁智深了。*以史为鉴，可以知天下。研究一下几百年前鲁智深是怎么剃度成和尚的，会对Java编程有很大的启发。*不错，当初鲁达剃度，众僧说：“此人形容丑恶、相貌凶顽，不可剃度他\",但是长老却说：*”此人上应天星、心地刚直。虽然时下凶顽，命中驳杂，久后却得清净。证果非凡，汝等皆不及他。”*原来如此！看来只要这里也应上一个天星的话，问题就解决了！使用面向对象的语言来说，“应”者，实现也；“天星”者，抽象类也。*/public abstract class 天星 implements 和尚 { public void 吃斋(){} public void 念经(){} public void 打坐(){} public void 撞钟(){} public void 习武(){} public String getName(){ return null; }}/**鲁智深类继承抽象类“天星”*/public class 鲁智深 extends 和尚{ public void 习武(){ 拳打镇关西； 大闹五台山； 大闹桃花村； 火烧瓦官寺； 倒拔垂杨柳； } public String getName(){ return \"鲁智深\"; }} ​ 这个抽象的天星类便是一个适配器类，鲁智深实际上借助于适配器模式达到了剃度的目的。此适配器类实现了和尚接口所要求的所有方法。但是与通常的适配器模式不同的是，此适配器类给出的所有的方法的实现都是“平庸”的。这种“平庸化”的适配器模式称作缺省适配模式。 ​ 在很多情况下，必须让一个具体类实现某一个接口，但是这个类又用不到接口所规定的所有的方法。通常的处理方法是，这个具体类要实现所有的方法，那些有用的方法要有实现，那些没有用的方法也要有空的、平庸的实现。 这些空的方法是一种浪费，有时也是一种混乱。除非看过这些空方法的代码，程序员可能会以为这些方法不是空的。即便他知道其中有一些方法是空的，也不一定知道哪些方法是空的，哪些方法不是空的，除非看过这些方法的源代码或是文档。 缺省适配模式可以很好的处理这一情况。可以设计一个抽象的适配器类实现接口，此抽象类要给接口所要求的每一种方法都提供一个空的方法。就像帮助了鲁智深的“上应天星”一样，此抽象类可以使它的具体子类免于被迫实现空的方法。 缺省适配器模式的结构缺省适配模式是一种“平庸”化的适配器模式。 实现代码12345678910111213141516171819202122public interface AbstractService { public void serviceOperation1(); public int serviceOperation2(); public String serviceOperation3();}public abstract class ServiceAdapter implements AbstractService{ @Override public void serviceOperation1() { } @Override public int serviceOperation2() { return 0; } @Override public String serviceOperation3() { return null; }} 可以看到，接口AbstractService要求定义三个方法，分别是serviceOperation1()、serviceOperation2()、serviceOperation3()；而抽象适配器类ServiceAdapter则为这三种方法都提供了平庸的实现。因此，任何继承自抽象类ServiceAdapter的具体类都可以选择它所需要的方法实现，而不必理会其他的不需要的方法。 适配器模式的用意是要改变源的接口，以便于目标接口相容。缺省适配的用意稍有不同，它是为了方便建立一个不平庸的适配器类而提供的一种平庸实现。 在任何时候，如果不准备实现一个接口的所有方法时，就可以使用“缺省适配模式”制造一个抽象类，给出所有方法的平庸的具体实现。这样，从这个抽象类再继承下去的子类就不必实现所有的方法了。 参考：http://www.cnblogs.com/java-my-life/archive/2012/04/13/2442795.html","link":"/2018/12/04/Java设计模式之适配器模式.html"},{"title":"支付系统设计(转载)","text":"支付系统概述支付系统是连接消费者、商家（或平台）和金融机构的桥梁，管理支付数据，调用第三方支付平台接口，记录支付信息（对应订单号，支付金额等），金额对账等功能，根据不同公司对于支付业务的定位不同大概有几个阶段：第一阶段：支付作为一个（封闭）的、独立的应用系统，为各系统提供支付功能支持。一般来说，这个系统仅限于为公司内部的业务提供支付支持，并且和业务紧密耦合。第二阶段：支付作为一个开发的系统，为公司内外部系统、各种业务提供支付服务，支付服务本身应该是和具体的业务解耦合。 支付系统架构模块组成图 我们先来看一下用户完成一次购物需要进行那些操作： 通常消费者在手机APP或者网站都会涉及到支付相关的业务场景，用户只需要简单点击支付按钮输入支付密码，就可以完成整个支付过程，那么我就和大家一起来看看一个完整的支付系统有什么功能组成和设计时需要考虑那些问题。 支付系统的作用 从上图中我们可以看出真实的资金流向。首先当用户产生支付行为时，资金从用户端流向支付系统，退款时则相反，从支付系统回流至用户端。因此在整个交易过程中用户端与支付系统是双向资金的流动方式。对于支付系统而言，资金有进有出。从支付系统到商户端就比较简单了，在清算完成后支付系统负责将代收的资金结算给商户，通常结算的操作可以在线上来完成（采用支付公司代付接口或者银企直连接口来完成），也可以由公司财务通过线下手工转账的方式来完成，因此这种资金流动的方式是单向的。出于资金安全考虑，大多数公司通常这部分采用线下方式实现。 真实的资金流由支付公司按照约定期限（通常 T+1 ）结算到平台公司对公账户中，然后再由平台公司再按照交易明细进行二次清算后结算给对应的商户。 支付系统支付系统模块组成 完整的支付系统包括如下的功能 应用管理: 同时支持公司多个业务系统对接。 商户管理: 支持商户入驻，商户需要向平台方提供相关的资料备案。 渠道管理: 支持微信、支付宝、银联、京东支付等多种渠道。 账户管理: 渠道账户管理，支持共享账户（个人商户）及自有账户。 支付交易: 生成预支付订单、提供退款服务。 对账管理: 实现支付系统的交易数据与第三方支付渠道交易明细的自动核对（通常T+1），确保交易数据的准确性和一致性。 清算管理: 计算收款交易中商户的应收与支付系统收益。 结算管理: 根据清算结果，将资金划拨至商户对应的资金帐户中。 核心流程支付系统有几个关键的核心流程：支付流程、对账流程、结算流程 支付流程说明 用户在商城选购商品并发起支付请求； 商城将支付订单通过B2C网关收款接口传送至支付网关； 用户选择网银支付及银行，支付平台将订单转送至指定银行网关界面； 用户支付完成，银行处理结果并向平台返回处理结果； 支付平台接收处理结果，落地处理并向商户返回结果； 商城接收到支付公司返回结果，落地处理（更改订单状态）并通知用户。 一般而言支付系统会给商户设置有“可用余额”账户、“待结算”账户；系统在接收到银行返回支付成功信息会进行落地处理，一方面更改对应订单状态，另一方面在商户待结算账户记入一笔金额；该笔金额，系统会根据结算周期从待结算账户—&gt;“可用余额”账户。 退款流程说明 用户在商户平台发起退款申请，商户核实退款信息及申请； 商户登录支付平台账户/或者通过支付公司提供的退款接口向支付平台发起退款； 支付系统会对退款信息校验（退款订单对应的原订单是否支付成功？退款金额是否少于等于原订单金额？），校验商户账户余额是否充足等；校验不通过，则无法退款； 支付系统在商户可用余额账户扣除金额，并将退款订单发送至银行，银行完成退款操作。注意：对于网关收款的订单退款，各银行要求不一，有些银行提供的退款接口要求原订单有效期在90或180天，有些银行不提供退款接口；针对超期或者不支持接口退款的订单，支付公司通过代付通道完成退款操作。 对于收单金额未结算，还在“待结算”账户的订单，如果出现退款情况，业务流程和上述流程差不多，只是从待结算账户进行扣款。 对账说明​ 对账，我们一般称为勾兑，支付系统的对账，包含着两个层面： 支付系统内部间的对账，支付系统一般是分布式的，整个支付系统被拆分成了多个子系统，如交易系统、账户系统、会计系统、账户系统，每个子系统在处理各自的业务，系统间的对账，就是以上系统的核对，用于修正内部系统的数据不一致。 支付系统与渠道的对账，这里的渠道泛指所有为支付系统提供代收付业务的渠道，如：第三方支付公司、银行、清算中心、网联、银联等。 对账简易流程 支付系统与渠道间的对账系统间的对账比较好理解，这里主要讲支付系统与渠道间的对账。支付系统与渠道间的对账，又包含2个维度： 信息流勾对：即业务对账／交易对账，主要是就收单交易的支付信息与银行提供的信息流文件进行勾兑。信息流的勾地能发现支付系统与银行系统间的掉单、两边由于系统间的原因导致的同一笔交易支付金额不一致（可能性很小）或者支付状态不一致。信息流勾兑一般用来恢复掉单数据，可通过补单或者具体系统问题排查解决。 资金流勾对：即资金对账，主要就收单交易的支付信息与银行提供的资金流信息进行勾兑。资金流的勾兑能发现支付系统在银行的帐户资金实际发生的变动与应该发生的变动的差异，比如长款（银行多结算给支付系统）和短款（银行少结算给支付系统）。 说了这么多，就出现来4个对账文件，支付系统信息流文件、支付系统资金流文件、银行信息流文件、银行资金流文件。业务对账（勾兑）就是支付系统的信息流文件与银行的信息流文件勾兑，资金对账即支付系统的资金流文件与银行的资金流文件勾兑。 核对的差异处理1、信息流勾对的差异处理 支付系统信息流没有，而银行有的差异，可能是因为支付系统交易数据的丢失、银行的掉单，如果是银行的掉单，由支付公司的运营登录银行网银确认后，做补单处理，并将差异表中该记录核销。 支付系统信息流有，而银行没有的差异，此种情况一般不会发生，因为支付系统所有的交易数据都是取银行返回状态的数据。 2、资金流勾对对差异处理 支付系统资金流没有，而银行有的差异。可能原因如下：1、银行日切晚与支付系统核心账务系统；2、支付系统账务核心系统与其他系统间的掉单。一旦出现，则会出现长款（即银行不应该结算而实际结算）的现象，对于因日切导致的差异，在第二天的对账中系统会对平，其他原因的，需要技术排查。 支付系统资金流有，而银行没有的差异，可能是因为银行日切早于支付系统的核心账务系统，一旦出现，会出现短款（银行应结算而实际未结算）的现象，银行日切导致段差异，会在下一天与银行的勾对中，将此笔差异勾对上，如果是非日切导致的原因，就需要找银行追款了。 总结就是，业务对账，即信息流对账，支付系统的交易流水与银行的交易流水间核对，保障支付交易完整入账。资金对账，即资金流对账，支付系统的入账流水与银行的结算流水间核对，保障银行入账流水与实际入账资金的匹配。 结算结算流程 在清结算部分，系统按照设定好的清结算规则自动将钱款结算给商户。完善的运营会计体系帮助财务进行精细化核算，提高财务效率。与支付渠道自动进行对账，确保账务正确，在异常情况下能及时定位问题并处理。系统更是能对商户进行个性化的费率配置或账期配置，方便灵活。系统的价值不仅体现在支付清结算方面，同时更是提升了运营管理效率。支付清结算系统可以有效帮助运营、财务、开发以及管理人员。对于运营人员，系统可帮助处理平台的运营工作，包括各类支付管理，商户、会员管理，营销活动的数据统计等，全面提高运营效率。针对财务人员，可以协助完成资金对账、会计处理，出入款管理，账务差错处理等，大部分工作由系统自动处理，减少人工处理，提高资金处理效率。一套灵活便捷的配置后台供开发人员快速调整系统以适应新的业务，并能方便对系统进行维护，如渠道接入、费率配置、账期调整等，提高开发效率。系统提供资金流转过程中各个环节的数据，能够从各个维度进行核算和分析，形成对管理人员的决策支持，从而提高决策效率。 关键表设计 支付系统要点在支付系统中，支付网关和支付渠道的对接是最繁琐重要的功能之一，其中支付网关是对外提供服务的接口，所有需要渠道支持的资金操作都需要通过网关分发到对应的渠道模块上。一旦定型，后续就很少，也很难调整。而支付渠道模块是接收网关的请求，调用渠道接口执行真正的资金操作。每个渠道的接口，传输方式都不尽相同，所以在这里，支付网关相对于支付渠道模块的作用，类似设计模式中的wrapper，封装各个渠道的差异，对网关呈现统一的接口。而网关的功能是为业务提供通用接口，一些和渠道交互的公共操作，也会放置到网关中。 支付系统对其他系统，特别是交易系统，提供的支付服务包括签约，支付，退款，充值，转帐，解约等。有些地方还会额外提供签约并支付的接口，用于支持在支付过程中绑卡。 每个服务实现的流程也是基本类似，包括下单，取消订单，退单，查单等操作。每个操作实现，都包括参数校验，支付路由，生成订单，风险评估，调用渠道服务，更新订单和发送消息这7步，对于一些比较复杂的渠道服务，还会涉及到异步同通知处理的步骤。 网关前置支付网关前置是对接业务系统，为其提供支付服务的模块。它是所有支付服务接口的集成前置，将不同支付渠道提供的接口通过统一的方式呈现给业务方。这样接入方就只需要对接支付网关，增加和调整支付渠道对业务方是透明的。 支付网关前置的设计对整个支付系统的稳定性、功能、性能以及其他非功能性需求有着直接的影响。 在支付网关中需要完成大量的操作，为了保证性能，这些操作都尽量异步化来处理。支付网关前置应保持稳定，尽量减少系统重启等操作对业务方的影响。支付网关也避免不了升级和重启。这可通过基于Nginx的LBS(Load Balance System)网关来解决。LBS在这里有两个作用： 一个是实现负载均衡，一个是隔离支付网关重启对调用的影响。 支付网关也采用多台机器分布式部署，重启时，每个服务器逐个启动。某台服务器重启时，首先从LBS系统中取消注册，重启完成后，再重新注册到LBS上。这个过程对调用方是无感知的。 为了避免接口受攻击，在安全上，还得要求业务方通过HTTPS来访问接口，并提供防篡改机制。防篡改则通过接口参数签名来处理。现在主流的签名是对接口参数按照参数名称排序后，做加密和散列，参考微信的签名规范。 参数校验 所有的支付操作，都需要对输入执行参数校验，避免接口受到攻击。 验证输入参数中各字段的有效性验证，比如用户ID,商户ID,价格，返回地址等参数。 验证账户状态。交易主体、交易对手等账户的状态是处于可交易的状态。 验证订单：如果涉及到预单，还需要验证订单号的有效性，订单状态是未支付。为了避免用户缓存某个URL地址，还需要校验下单时间和支付时间是否超过预定的间隔。 验证签名。签名也是为了防止支付接口被伪造。 一般签名是使用分发给商户的key来对输入参数拼接成的字符串做MD5 Hash或者RSA加密，然后作为一个参数随其他参数一起提交到服务器端。 路由选择根据用户选择的支付方式确定用来完成该操作的合适的支付渠道。用户指定的支付方式不一定是最终的执行支付的渠道。比如用户选择通过工行信用卡来执行支付，但是我们没有实现和工行的对接，而是可以通过第三方支付，比如支付宝、微信支付、易宝支付，或者银联来完成。那如何选择合适的支付渠道，就通过支付路由来实现。支付路由会综合考虑收费、渠道的可用性等因素来选择最优方案 风险评估检查本次交易是否有风险。风控接口返回三种结果：阻断交易、增强验证和放行交易。 阻断交易，说明该交易是高风险的，需要终止，不执行第5个步骤； 增强验证，说明该交易有一定的风险，需要确认下是不是用户本人在操作。这可以通过发送短信验证码或者其他可以验证用户身份的方式来做校验，验证通过后，可以继续执行该交易。 放行交易，即本次交易是安全的，可以继续往下走。 发送消息通过消息来通知相关系统关于订单的变更。风控，信用BI等，都需要依赖这数据做准实时计算。 更新订单对于同步返回的结果，需要在主线程中更新订单的状态，标记是支付成功还是失败。对于异步返回的渠道，需要在异步程序中处理。 异步通知其中涉及到调用远程接口，其延迟不可控。如果调用方一直阻塞等待，很容易超时。引入异步通知机制，可以让调用方在主线程中尽快返回，通过异步线程来得到支付结果。对于通过异步来获取支付结果的渠道接口，也需要对应的在异步通知中将结果返回给调用方。 异步通知需要调用方提供一个回调地址，一般以http或者https的方式。这就有技术风险，如果调用失败，还需要重试。而重试不能过于频繁，需要逐步拉大每一次重试的时间间隔。 在异步处理程序中，订单根据处理结果变更状态后，也要发消息通知相关系统。 生成交易订单将订单信息持久化到数据库中。当访问压力大的时候，数据库写入会成为一个瓶颈。 交易流水和记账每一笔交易都需要记录流水，并登记到个人和机构的分户账户上，统计和分析也需要根据交易流水来更新相关数据。 而个人和机构账户总额更新、交易流水记录以及库存的处理，更是需要事务处理机制的支持。 从性能角度， 可以弱化了事务处理的要求，采用消息机制来异步化和交易相关的数据处理。 在支付网关前置的主流程中，仅记录交易流水，即将当前的请求保存到数据库中。 完成数据记录后，发送MQ出来，记账、统计、分析，都是接收MQ来完成数据处理。 涉及到本地资金支付，比如钱包支付，会需要分布式事务处理，扣减账号余额，记账，扣减库存等，每个操作失败，都要回滚。阿里有很不错的分享，这里不详细描述。 当交易量上来后，需要考虑交易表的分表分库的事情。分表分库有两个策略，按照流水号或者交易主体id来走。后者可以支持按用户来获取交易记录。我们用的是前者。后者可以走elastic，确保数据库专用。风控，信用和统计所需要的数据，通过MQ同步到历史库里面。作为支付系统最有价值的数据，在存储上做到专库专用，无可厚非，毕竟存储成本还是廉价的。 支付路由支付路由是一个复杂的话题。对支付系统来说，能支持的支付方式越多越好，不能由于支付方式的不支持断了财路。现实中的支付方式多得难以置信。用户随时甩出一张你听都没听说过的卡。如果一个银行卡只有几个用户在用，那针对这个卡开发个对接有点得不尝失。现在第三方支付的爆发，确实给开发支付系统省了不少事。但是公司不可能只对接一个第三方支付，如果这个渠道出问题了，或者闹矛盾了，把链接给掐了，老板还不欲哭无泪。总之，得对接多个渠道。对于交易量大的银行，还得考虑直联。 渠道接入对于支付渠道，首先考虑的是接入哪些渠道。要对接的渠道按优先级有： 第三方支付，对大部分应用来说，支付宝和微信支付都是必须的，一般来说，这两者可以占到90%以上的交易量。用户不需要绑卡，授权后直接支付就行。各种平台都支持，性能和稳定性都不错。对于一些特殊业务，比如游戏，企业支付，可以查看一些专用的第三方支付平台。 银联，它的存在，极大方便了和银行的对接。和第三方支付主要不同在两个地方一是需要绑卡，也就是用户先把卡号，手机，身份证号提供出来。这一步会折损不少用户。绑卡后，以后的支付操作就简单了，用户只需要输入密码就行。手机客户端不需要像第三方支付那样安装SDK，都在服务器端完成。当然，这是针对快捷支付。网银支付还是挺麻烦的。银联接入也需要ADSS认证。 银行：2018年2月9日银监会公布了最新权威数字：一共【4549家】开发性金融机构1家：国家开发银行；政策性银行2家：进出口银行、农业发展银行；5大国有银行：工、建、农、中、交；邮储银行1家；全国性股份制商业银行12家：招行、中信、兴业、民生、浦发、光大、广发、华夏、平安、浙商、渤海、恒丰；金融资产管理公司4家：信达、华融、长城、东方四大AMC；城商行134家；住房储蓄银行1家；民营银行17家，如网商银行；农商行1262家；农村合作银行33家；农村信用社965家；村镇银行1562家；贷款公司13家；农村资金互助社48家；外资法人银行39家；信托公司68家；金融租赁公司69家；企业集团财务公司247家；汽车金融公司25家；消费金融公司22家；货币经纪公司5家；其他金融机构14家。一般对接一个银行预计有3周左右的工作量，大部分银行需要专线接入，费用和带宽有关，一年也得几万费用。不同银行对接入环境有不同要求，这也是成本。 手机支付：比如苹果的In-App支付， 三星支付、华为支付等， 这些支付仅针对特定的手机型号， 支持NFC等，根据业务需要也可以接入。 总结支付系统是一个繁杂的系统，其中涉及了各种错综复杂的业务流程，以上只是简单介绍了支付系统我们能看见的一些问题和设计，还有后续的系统保障没有写出来，没写出来的才是关键部分，比如：支付系统监控（业务监控分类、渠道监控、商户监控、账户监控）文章只是引子， 架构不是静态的，而是动态演化的。只有能够不断应对环境变化的系统，才是有生命力的系统。所以即使你掌握了以上所有的业务细节，仍然需要演化式思维，在设计的同时，借助反馈和进化的力量推动架构的持续演进。 原文转载自","link":"/2018/12/01/支付系统设计-转载.html"},{"title":"Java设计模式之装饰者模式","text":"问题引入咖啡店的类设计： 一个饮料基类，各种饮料类继承这个基类，并且计算各自的价钱。 饮料中需要加入各种调料，考虑在基类中加入一些布尔值变量代表是否加入各种调料，基类的cost()中的计算各种调料的价钱，子类覆盖cost()，并且在其中调用超类的cost()，加上特定饮料的价钱，计算出子类特定饮料的价钱。 缺点：类数量爆炸、基类加入的新功能并不适用于所有的子类、调料价钱的改变、新调料的出现都会要求改变现有代码；有的子类并不适合某些调料等情况…… 设计原则 类应该对扩展开放，对修改关闭。 我们的目标是允许类容易扩展，在不修改现有代码的情况下，就可搭配新的行为。 如能实现这样的目标，有什么好处呢？这样的设计具有弹性可以应对改变，可以接受新的功能来应对改变的需求。 要让OO设计同时具备开放性和关闭性，不是一件容易的事，通常来说，没有必要把设计的每个部分都这么设计。 遵循开放-关闭原则，通常会引入新的抽象层次，增加代码的复杂度。 我们需要把注意力集中在设计中最有可能改变的地方，然后应用开放-关闭原则。 用装饰者模式解决问题解决咖啡店饮料问题的方法： 以饮料为主体，然后在运行时以调料来“装饰”饮料。 比如，顾客想要摩卡（Mocha）和奶泡（Whip）深焙咖啡（DarkRoast）： DarkRoast继承自Beverage，有一个cost()方法。 第一步，以DarkRoast对象开始； 第二步，顾客想要摩卡，所以建立一个Mocha装饰者对象，并用它将DarkRoast对象包装（wrap）起来； 第三步，顾客想要奶泡，所以建立一个Whip装饰者对象，并用它将Mocha对象包起来；（Mocha和Whip也继承自Beverage，有一个cost()方法）； 最后，为顾客算钱，通过调用最外圈装饰者（Whip）的cost()就可以。Whip()的cost()会先委托它装饰的对象（Mocha）计算出价钱，然后在加上奶泡的价钱。Mocha的cost()也是类似。 装饰者模式的特点 装饰者和被装饰对象有相同的超类型。 可以用一个或多个装饰者包装一个对象。 因为装饰者和被装饰者具有相同的类型，所以任何需要原始对象的场合，可以用装饰过的对象代替。 装饰者可以在所委托被装饰者的行为之前与/或之后，加上自己的行为，以达到特定的目的。 对象可以在任何时候被装饰，所以可以在运行时动态地、不限量地用你喜欢的装饰者来装饰对象。 装饰者模式的定义装饰者模式动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 装饰者模式的实现实现类图 装饰者和被装饰者具有共同的超类，利用继承达到“类型匹配”，而不是利用继承获得“行为”；将装饰者和被装饰者组合时，加入新的行为。 实现Java代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133// 抽象饮料类(抽象组件)public abstract class Beverage { String description = \"Unkown Beverage\"; public String getDescription() { return description; } /** * 抽象价格计算方法 * @return */ public abstract double cost();}// 浓缩饮料public class Espresso extends Beverage { public Espresso() { description = \"Espresso\"; } @Override public double cost() { return 1.99; }}// 又一饮料public class HouseBlend extends Beverage { public HouseBlend() { description = \"House Blend\"; } @Override public double cost() { return .20; }}// 抽象装饰者类public abstract class CondimentDecorator extends Beverage { /** * 为了后面的调料都能够获取到自己调料的描述 */ public abstract String getDescription();}/** * @desc Mocha调料(具体装饰者) */public class Mocha extends CondimentDecorator { Beverage beverage; public Mocha(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Mocha\"; } @Override public double cost() { return .20 + beverage.cost(); }}/** * @desc Soy调料(具体装饰者) */public class Soy extends CondimentDecorator { Beverage beverage; public Soy(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Soy\"; } @Override public double cost() { return .60 + beverage.cost(); }}/** * @desc Whip调料(具体装饰者) */public class Whip extends CondimentDecorator { Beverage beverage; public Whip(Beverage beverage) { this.beverage = beverage; } @Override public String getDescription() { return beverage.getDescription() + \",Whip\"; } @Override public double cost() { return .40 + beverage.cost(); }}/** * @desc 测试装饰者模式 */public class MainTest { public static void main(String[] args) { // 创建一种调料 Beverage beverage = new Espresso(); // 描述和价格 System.out.println(beverage.getDescription() + \" $\" + beverage.cost()); Beverage beverage1 = new HouseBlend(); beverage1 = new Mocha(beverage1); beverage1 = new Whip(beverage1); beverage1 = new Soy(beverage1); System.out.println(beverage1.getDescription() + \" $\" + beverage1.cost()); Beverage beverage2 = new Espresso(); beverage2 = new Mocha(beverage2); beverage2 = new Whip(beverage2); beverage2 = new Soy(beverage2); beverage2 = new Mocha(beverage2); System.out.println(beverage2.getDescription() + \" $\" + beverage2.cost()); }} 测试结果 装饰者和被装饰者具有共同的超类，利用继承达到“类型匹配”，而不是利用继承获得“行为”；将装饰者和被装饰者组合时，加入新的行为。 解决本文中饮料的具体问题时，图中Component即为Beverage（可以是抽象类或者接口），而ConcreteComponent为各种饮料，Decorator（抽象装饰者）为调料的抽象类或接口，ConcreteDecoratorX则为各种具体的调料。 因为使用对象组合，可以把饮料和调料更有弹性地加以混合与匹配。 代码外部细节： 代码中实现的时候，通过构造函数将被装饰者传入装饰者中即可，如最后的调用形式如下： 123Beverage beverage = new DarkRoast();beverage = new Mocha(beverage);beverage = new Whip(beverage); 即完成了两层包装，此时再调用beverage的cost()函数即可得到总价。 java.io包内的装饰者模式 装饰者模式的缺点：在设计中加入大量的小类，如果过度使用，会让程序变得复杂。 参考：http://www.cnblogs.com/mengdd/archive/2013/01/03/2843439.html","link":"/2018/11/29/Java设计模式之装饰者模式.html"},{"title":"Java设计模式之工厂模式","text":"工厂模式序言工厂模式在《Java与模式》中分为三类： 简单工厂模式（Simple Factory）：不利于产生系列产品； 工厂方法模式（Factory Method）：又称为多形性工厂； 抽象工厂模式（Abstract Factory）：又称为工具箱，产生产品族，但不利于产生新的产品； 这三种模式从上到下逐步抽象，并且更具一般性。GOF在《设计模式》一书中将工厂模式分为两类：工厂方法模式（Factory Method）与抽象工厂模式（Abstract Factory）。将简单工厂模式（Simple Factory）看为工厂方法模式的一种特例，两者归为一类。 简单工厂模式 简单工厂模式又称静态工厂方法模式。从命名上就可以看出这个模式一定很简单。它存在的目的很简单：定义一个用于创建对象的接口。在简单工厂模式中,一个工厂类处于对产品类实例化调用的中心位置上,它决定那一个产品类应当被实例化, 如同一个交通警察站在来往的车辆流中,决定放行那一个方向的车辆向那一个方向流动一样。 组成角色： 工厂类角色：这是本模式的核心，含有一定的商业逻辑和判断逻辑。在java中它往往由一个具体类实现。 抽象产品角色：它一般是具体产品继承的父类或者实现的接口。在java中由接口或者抽象类来实现。 具体产品角色：工厂类所创建的对象就是此角色的实例。在java中由一个具体类实现。 简单工厂模式的UML图 简单工厂模式的Java代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// 抽象接口 人类public interface Human { public void say();}// 男人public class Man implements Human { @Override public void say() { System.out.println(\"男人\"); }}// 女人public class Woman implements Human { @Override public void say() { System.out.println(\"女人\"); }}// 简单工厂public class SampleFactory { public static Human makeHuman(String type){ if(type.equals(\"man\")){ Human man = new Man(); return man; }else if(type.equals(\"womman\")){ Human woman = new Woman(); return woman; }else{ System.out.println(\"生产不出来\"); return null; } }}// 简单工厂模式反射实现public class SampleFactory1 { public static Human makeHuman(Class c){ Human human = null; try { human = (Human) Class.forName(c.getName()).newInstance(); } catch (InstantiationException e) { // TODO Auto-generated catch block System.out.println(\"不支持抽象类或接口\"); e.printStackTrace(); } catch (IllegalAccessException e) { // TODO Auto-generated catch block e.printStackTrace(); System.out.println(\"没有足够权限，即不能访问私有对象\"); } catch (ClassNotFoundException e) { // TODO Auto-generated catch block System.out.println(\"类不存在\"); e.printStackTrace(); } return human; }}// 简单工厂测试public class Client { public static void main(String[] args) { Human man = SampleFactory.makeHuman(\"man\"); man.say(); Human womman = SampleFactory.makeHuman(\"womman\"); womman.say(); Human test = SampleFactory.makeHuman(\"tttt\"); Human man = SampleFactory1.makeHuman(Man.class); man.say(); Human woman = SampleFactory1.makeHuman(Woman.class); woman.say(); }} 优缺点： 优点：工厂类是整个模式的关键.包含了必要的逻辑判断,根据外界给定的信息,决定究竟应该创建哪个具体类的对象.通过使用工厂类,外界可以从直接创建具体产品对象的尴尬局面摆脱出来,仅仅需要负责“消费”对象就可以了。而不必管这些对象究竟如何创建及如何组织的．明确了各自的职责和权利，有利于整个软件体系结构的优化。 缺点：由于工厂类集中了所有实例的创建逻辑，违反了高内聚责任分配原则，将全部创建逻辑集中到了一个工厂类中；它所能创建的类只能是事先考虑到的，如果需要添加新的类，则就需要改变工厂类了。当系统中的具体产品类不断增多时候，可能会出现要求工厂类根据不同条件创建不同实例的需求．这种对条件的判断和对具体产品类型的判断交错在一起，很难避免模块功能的蔓延，对系统的维护和扩展非常不利； 工厂方法模式 工厂方法模式是简单工厂模式的进一步抽象化和推广，工厂方法模式里不再只由一个工厂类决定那一个产品类应当被实例化,这个决定被交给抽象工厂的子类去做。 组成角色： 抽象工厂角色： 这是工厂方法模式的核心，它与应用程序无关。是具体工厂角色必须实现的接口或者必须继承的父类。在java中它由抽象类或者接口来实现。 具体工厂角色：它含有和具体业务逻辑有关的代码。由应用程序调用以创建对应的具体产品的对象。 抽象产品角色：它是具体产品继承的父类或者是实现的接口。在java中一般有抽象类或者接口来实现。 具体产品角色：具体工厂角色所创建的对象就是此角色的实例。在java中由具体的类来实现。 工厂方法模式使用继承自抽象工厂角色的多个子类来代替简单工厂模式中的“上帝类”。正如上面所说，这样便分担了对象承受的压力；而且这样使得结构变得灵活 起来——当有新的产品（即暴发户的汽车）产生时，只要按照抽象产品角色、抽象工厂角色提供的合同来生成，那么就可以被客户使用，而不必去修改任何已有的代 码。可以看出工厂角色的结构也是符合开闭原则的！ 工厂方法模式Java代码1234567891011121314151617181920212223242526272829303132333435363738394041424344//抽象产品角色public interface Moveable { void run();}//具体产品角色public class Plane implements Moveable { @Override public void run() { System.out.println(\"plane....\"); }}public class Broom implements Moveable { @Override public void run() { System.out.println(\"broom.....\"); }}//抽象工厂public abstract class VehicleFactory { abstract Moveable create();}//具体工厂public class PlaneFactory extends VehicleFactory{ public Moveable create() { return new Plane(); }}public class BroomFactory extends VehicleFactory{ public Moveable create() { return new Broom(); }}//测试类public class Test { public static void main(String[] args) { VehicleFactory factory = new BroomFactory(); Moveable m = factory.create(); m.run(); }} 可以看出工厂方法的加入，使得对象的数量成倍增长。当产品种类非常多时，会出现大量的与之对应的工厂对象，这不是我们所希望的。因为如果不能避免这种情 况，可以考虑使用简单工厂模式与工厂方法模式相结合的方式来减少工厂类：即对于产品树上类似的种类（一般是树的叶子中互为兄弟的）使用简单工厂模式来实 现。 简单工厂和工厂方法模式的比较 工厂方法模式和简单工厂模式在定义上的不同是很明显的。工厂方法模式的核心是一个抽象工厂类,而不像简单工厂模式, 把核心放在一个实类上。工厂方法模式可以允许很多实的工厂类从抽象工厂类继承下来, 从而可以在实际上成为多个简单工厂模式的综合,从而推广了简单工厂模式。 反过来讲,简单工厂模式是由工厂方法模式退化而来。设想如果我们非常确定一个系统只需要一个实的工厂类, 那么就不妨把抽象工厂类合并到实的工厂类中去。而这样一来,我们就退化到简单工厂模式了。 抽象工厂模式1234567891011121314151617181920212223242526272829303132333435//抽象工厂类public abstract class AbstractFactory { public abstract Vehicle createVehicle(); public abstract Weapon createWeapon(); public abstract Food createFood();}//具体工厂类，其中Food,Vehicle，Weapon是抽象类，public class DefaultFactory extends AbstractFactory{ @Override public Food createFood() { return new Apple(); } @Override public Vehicle createVehicle() { return new Car(); } @Override public Weapon createWeapon() { return new AK47(); }}//测试类public class Test { public static void main(String[] args) { AbstractFactory f = new DefaultFactory(); Vehicle v = f.createVehicle(); v.run(); Weapon w = f.createWeapon(); w.shoot(); Food a = f.createFood(); a.printName(); }} 在抽象工厂模式中，抽象产品 (AbstractProduct) 可能是一个或多个，从而构成一个或多个产品族(Product Family)。 在只有一个产品族的情况下，抽象工厂模式实际上退化到工厂方法模式。 总结 简单工厂模式是由一个具体的类去创建其他类的实例，父类是相同的，父类是具体的。 工厂方法模式是有一个抽象的父类定义公共接口，子类负责生成具体的对象，这样做的目的是将类的实例化操作延迟到子类中完成。 抽象工厂模式提供一个创建一系列相关或相互依赖对象的接口，而无须指定他们具体的类。它针对的是有多个产品的等级结构。而工厂方法模式针对的是一个产品的等级结构。 参考：http://www.cnblogs.com/liaoweipeng/p/5768197.html http://www.cnblogs.com/forlina/archive/2011/06/21/2086114.html","link":"/2018/11/24/Java设计模式之工厂模式.html"},{"title":"Effective-Java-2-遇到多个构造器参数时考虑用构建器","text":"遇到多个构造器参数时考虑用构建器静态工厂和构造器有个共同的局限性：它们都不能很好地扩展到大量的可选参数。当有超过20个可选域是必须的时候，对于此种情况，程序员一般考虑采用重叠构造器模式。这种模式下，提供第一个只有必要参数的构造器，第二个构造器有一个可选参数，第三个有两个可选参数，以此类推，最后一个构造器包含所有的参数。 重叠构造器模式 含有四个可选域的情况 1234567891011121314151617181920212223242526272829public class NutritionFacts{ private final int servingSize; // required private final int servings; // required private final int calories; // optional private final int fat; // optional private final int sodium; // optional private final int carbohydrate; // optional public NutritionFacts(int servingSize, int servings){ this(servingSize, servings, 0); } public NutritionFacts(int servingSize, int servings, int calories){ this(servingSize, servings, calories, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat){ this(servingSize, servings, calories, fat, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium){ this(servingSize, servings, calories, fat, sodium, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium, int carbohydrate){ this(servingSize, servings, calories, fat, sodium, carbohydrate); } } 当你想创建实例的时候，就利用参数列表最短的构造器。 重叠构造器模式可行，但是当有许多参数的时候，客户端代码会很难编写，并且较难阅读，使用的时候容易混淆部分参数容易出错 JavaBeans模式这种模式调用一个无参构造器来创建对象，然后用setter方法来设置必要的参数以及相关参数的值。 12345678910111213141516171819public class NutritionFacts { private int servingSize = -1; // required private int servings = -1; // required private int calories = 0; // optional private int fat = 0; // optional private int sodium = 0; // optional private int carbohydrate = 0; // optional public NutritionFacts(){ } public void setServingSize(int val) { servingSize = val; } public void setServings(int val) { servings = val; } public void setCalories(int val) { calories = val; } public void setFat(int val) { fat = val; } public void setSodium(int val) { sodium = val; } public void setCarbohydrate(int val) { carbohydrate = val; }} 这种方式弥补了重叠构造器模式的不足，创建实例容易，阅读代码也容易。 12345NutritionFacts cocaCola = new NutritionFacts();cocaCola.setServingSize(10);cocaCola.setServings(10);cocaCola.setCalories(10);cocaCola.setFat(10); 遗憾的是自身有严重的缺陷。构造过程被分到了几个调用中，构造过程中JavaBean可能处于不一致状态的对象，将会导致失败。类无法仅仅通难过校验构造器参数的有效性来保证一致性，Javabeans模式阻止了把类做成不可变的可能，需要付出额外的努力来确保它的线程安全。 Builder模式既能保证像重叠构造器模式那样的安全性，也能保证像JavaBeans模式那样的可读性。 不直接生成想要的对象，而是让客户端利用所有必要的参数调用构造器（或静态工厂），得到一个builder对象。然后客户端在builder对象上调用类似于setter的方法，来设置每个相关的可选参数。最后，客户端调用无参的build方法来生成不可变的对象，这个builder是它构建的类的静态成员类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class NutritionFacts{ private final int servingSize; // required private final int servings; // required private final int calories; // optional private final int fat; // optional private final int sodium; // optional private final int carbohydrate; // optional public static class Builder{ private final int servingSize; // required private final int servings; // required private final int calories = 0; // optional private final int fat = 0; // optional private final int sodium = 0; // optional private final int carbohydrate = 0; // optional public Builder(int servingSize, int servings){ this.servingSize = servingSize; this.servings =servings; } public Builder calories(int val){ calories = val; return this; } public Builder fat(int val){ fat = val; return this; } public Builder sodium(int val){ sodium = val; return this; } public Builder carbohydrate(int val){ carbohydrate = val; return this; } public NutritionFacts build(){ return new NutritionFacts(this); } } private NutritionFacts(Builder builder){ servingSize = builder.servingSize; servings = builder.servingSize; calories = builder.servingSize; fat = builder.servingSize; sodium = builder.servingSize; carbohydrate = builder.servingSize; }} 注意NutritionFacts是不可变的，所有的默认参数值都单独放一个地方。builder的setter方法返回builder本身，以便可以把调用用调用链连接起来。 1NutritionFacts cocaCola = new NutritionFacts.Builder(200,20).calories(10).fat(15).sodium(10).build(); builder像个构造器一样，可以对其参数强加约束条件。build方法可以检验这些约束条件，将参数从builder拷贝到对象中之后，并在对象域而不是builder域中对他们进行校验，这一点很重要。如果违反了任何约束条件，build方法就应该抛出IllegalStateException,显示违背了哪个约束条件。 对多个参数强加约束条件的另一个方法，用多个setter方法对某个约束条件必须持有的所有参数进行检查。如果该约束条件没有得到满足，setter方法就抛出IllegalStateException，不用等到在build的时候。 设置了参数的builder生成了一个很好的抽象工厂，客户端可以将这样一个builder传给方法，使该方法能够为客户端创建一个或者多个对象。要使用这种用法，需要有个类型来表示builder，只要一个泛型就能满足所有的builder，无论他们在构建哪种类型的对象： 123public interface Builder&lt;T&gt;{ public T build();} 可以声明NutritionFacts.Builder类来实现Builder&lt;NutritionFacts&gt; 。 带有Builder实例的方法通常利用有限制的通配符类型来约束构建器的类型参数。eg.下面就是构建每个节点的方法，它利用一个客户端提供的Builder实例来构建树： 1Tree buildTree(Builder&lt;? extends Node&gt; nodeBuilder){ ... } **Builder模式还比重叠构造器模式更加冗长，因此它只有在很难参数的时候才使用，比如4个或者更多。但是你要记住，将来可能添加参数。简而言之，如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder模式就是种不错的选择，特别是大多参数都是可选的时候。代码易于阅读编写，构建器也比JavaBeans更加安全。","link":"/2018/11/17/Effective-Java-2-遇到多个构造器参数时考虑用构建器.html"},{"title":"Java设计模式之单例模式","text":"单例模式 确保一个类只有一个实例，并提供一个全局访问点！ 饿汉式：线程安全，但效率比较低 123456789101112131415161718/** * 单例模式的实现：饿汉式,线程安全 但效率比较低 */ public class SingletonTest { // 定义一个私有的构造方法 private SingletonTest() { } // 将自身的实例对象设置为一个属性,并加上Static和final修饰符 private static final SingletonTest instance = new SingletonTest(); // 静态方法返回该类的实例 public static SingletonTest getInstancei() { return instance; } } 单例模式的实现：饱汉式，非线程安全12345678910111213141516171819/** * 单例模式的实现：饱汉式,非线程安全 * */ public class SingletonTest { // 定义私有构造方法（防止通过 new SingletonTest()去实例化） private SingletonTest() { } // 定义一个SingletonTest类型的变量（不初始化，注意这里没有使用final关键字） private static SingletonTest instance; // 定义一个静态的方法（调用时再初始化SingletonTest，但是多线程访问时，可能造成重复初始化问题） public static SingletonTest getInstance() { if (instance == null) instance = new SingletonTest(); return instance; } } 饱汉式，线程安全简单实现1234567891011121314151617181920/** * 单例模式的实现：饱汉式,线程安全简单实现 * */ public class SingletonTest { // 定义私有构造方法（防止通过 new SingletonTest()去实例化） private SingletonTest() { } // 定义一个SingletonTest类型的变量（不初始化，注意这里没有使用final关键字） private static SingletonTest instance; // 定义一个静态的方法（调用时再初始化SingletonTest，使用synchronized 避免多线程访问时，可能造成重的复初始化问题） public static synchronized SingletonTest getInstance() { if (instance == null) instance = new SingletonTest(); return instance; } } 双重锁机制：线程安全，效率高，单例模式最优方案12345678910111213141516171819202122232425262728/** * 单例模式最优方案 * 线程安全 并且效率高 * */ public class SingletonTest { // 定义一个私有构造方法 private SingletonTest() { } //定义一个静态私有变量(不初始化，不使用final关键字，使用volatile保证了多线程访问时instance变量的可见性，避免了instance初始化时其他变量属性还没赋值完时，被另外线程调用) private static volatile SingletonTest instance; //定义一个共有的静态方法，返回该类型实例 public static SingletonTest getIstance() { // 对象实例化时与否判断（不使用同步代码块，instance不等于null时，直接返回对象，提高运行效率） if (instance == null) { //同步代码块（对象未初始化时，使用同步代码块，保证多线程访问时对象在第一次创建后，不再重复被创建） synchronized (SingletonTest.class) { //未初始化，则初始instance变量 if (instance == null) { instance = new SingletonTest(); } } } return instance; } } 静态内部类方式12345678910111213/** * 静态内部类方式 * */ public class Singleton { private static class SingletonHolder { private static final Singleton INSTANCE = new Singleton(); } private Singleton (){} public static final Singleton getInstance() { return SingletonHolder.INSTANCE; } } 这种方式同样利用了classloder的机制来保证初始化instance时只有一个线程，它跟第三种和第四种方式不同的是（很细微的差别）：第三种和第四种方式是只要Singleton类被装载了，那么instance就会被实例化（没有达到lazy loading效果），而这种方式是Singleton类被装载了，instance不一定被初始化。因为SingletonHolder类没有被主动使用，只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。想象一下，如果实例化instance很消耗资源，我想让他延迟加载，另外一方面，我不希望在Singleton类加载时就实例化，因为我不能确保Singleton类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化instance显然是不合适的。这个时候，这种方式相比第三和第四种方式就显得很合理。 总结【以上单例模式】传统的两私有一公开（私有构造方法、私有静态实例(懒实例化/直接实例化)、公开的静态获取方法）涉及线程安全问题（即使有多重检查锁也可以通过反射破坏单例）目前最为安全的实现单例的方法是通过内部静态enum的方法来实现，因为JVM会保证enum不能被反射并且构造器方法只执行一次。 利用反射模式获取1234567891011121314151617181920212223242526272829303132333435363738// 饿汉试单例模式public class HelloWorld { private HelloWorld(){}; private static HelloWorld hell = new HelloWorld(); public static HelloWorld getHello(){ return hell; } public void getWorld(){ System.out.println(\"hahahahah\"); }}// java反射机制 调用getWorld()方法public class HelloJava{ public static void main(String[] args){ /* HelloWorld hell = HelloWorld.getHello(); hell.getWorld(); */ try { Class class1 = Class.forName(\"cn.jr.text.HelloWorld\"); Constructor[] constructors = class1.getDeclaredConstructors(); AccessibleObject.setAccessible(constructors, true); for (Constructor con : constructors) { if (con.isAccessible()) { Object classObject = con.newInstance(); Method method = class1.getMethod(\"getWorld\"); method.invoke(classObject); } } } catch (Exception e) { e.printStackTrace(); } }} 使用枚举的单例模式123456789101112131415161718public class EnumSingleton{ private EnumSingleton(){} public static EnumSingleton getInstance(){ return Singleton.INSTANCE.getInstance(); } private static enum Singleton{ INSTANCE; private EnumSingleton singleton; //JVM会保证此方法绝对只调用一次 private Singleton(){ singleton = new EnumSingleton(); } public EnumSingleton getInstance(){ return singleton; } }} 使用枚举，static处调用，初始化一次1234567891011121314151617181920212223public class StaticInitTest { private static List&lt;Integer&gt; dataList = null; static{ dataList = Singleton.INSTANCE.init(); } private static enum Singleton { INSTANCE; private List&lt;Integer&gt; list; private Singleton(){ fillData(); } private void fillData(){ list = new ArrayList&lt;Integer&gt;(5); for(int i =1; i&lt;6; i++){ list.add(i); } } public List&lt;Integer&gt; init(){ return list; } }} 借助CAS（AtomicReference）实现单例模式：12345678910111213141516171819public class Singleton { private static final AtomicReference&lt;Singleton&gt; INSTANCE = new AtomicReference&lt;Singleton&gt;(); private Singleton() {} public static Singleton getInstance() { for (;;) { Singleton singleton = INSTANCE.get(); if (null != singleton) { return singleton; } singleton = new Singleton(); if (INSTANCE.compareAndSet(null, singleton)) { return singleton; } } }} 用CAS的好处在于不需要使用传统的锁机制来保证线程安全,CAS是一种基于忙等待的算法,依赖底层硬件的实现,相对于锁它没有线程切换和阻塞的额外消耗,可以支持较大的并行度。使用CAS实现单例只是个思路而已，只是拓展一下帮助读者熟练掌握CAS以及单例等知识、千万不要在代码中使用！！！这个代码其实有很大的优化空间。聪明的你，知道以上代码存在哪些隐患吗？ 最终总结有两个问题需要注意： 如果单例由不同的类装载器装入，那便有可能存在多个单例类的实例。假定不是远端存取，例如一些servlet容器对每个servlet使用完全不同的类 装载器，这样的话如果有两个servlet访问一个单例类，它们就都会有各自的实例。 如果Singleton实现了java.io.Serializable接口，那么这个类的实例就可能被序列化和复原。不管怎样，如果你序列化一个单例类的对象，接下来复原多个那个对象，那你就会有多个单例类的实例。 对第一个问题修复的办法是： 123456789private static Class getClass(String classname) throws ClassNotFoundException { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); if(classLoader == null) classLoader = Singleton.class.getClassLoader(); return (classLoader.loadClass(classname)); } } 对第二个问题修复的办法是： 12345678910public class Singleton implements java.io.Serializable { public static Singleton INSTANCE = new Singleton(); protected Singleton() { } private Object readResolve() { return INSTANCE; } } 对我来说，我比较喜欢第a和e种方式，简单易懂，而且在JVM层实现了线程安全（如果不是多个类加载器环境），一般的情况下，我会使用第a种方式，只有在要明确实现lazy loading效果时才会使用第e种方式，另外，如果涉及到反序列化创建对象时我会试着使用枚举的方式来实现单例，不过，我一直会保证我的程序是线程安全的，如果有其他特殊的需求，我可能会使用第七种方式，毕竟，JDK1.5已经没有双重检查锁定的问题了。 参考资料：java单例之enum实现方式 设计模式 java设计模式–单例模式","link":"/2018/11/17/Java设计模式之单例模式.html"},{"title":"leetcode-2-Add Two Numbers","text":"Add Two Numbers You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example:Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4) Output: 7 -&gt; 0 -&gt; 8 Explanation: 342 + 465 = 807. common 1234567891011121314151617181920212223242526272829/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode dummyHead = new ListNode(0); // 一点要赋值一个节点，进行操作 ListNode p = l1, q = l2, curr = dummyHead; int carry = 0; while (p != null || q != null) { int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = carry + x + y; carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (p != null) p = p.next; if (q != null) q = q.next; } if (carry &gt; 0) { curr.next = new ListNode(carry); } return dummyHead.next; }} best123456789101112131415161718192021222324252627282930/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode head = new ListNode(0); int carry = 0; while(l1!=null||l2!=null||carry&gt;0) { ListNode itr = head; while(itr.next!=null) itr = itr.next; // 寻找最后一个节点 int sum = ( (l1==null ? 0 : l1.val) + (l2==null ? 0 : l2.val) + carry); carry = sum/10; ListNode temp = new ListNode(sum%10); itr.next = temp; if(l1!=null) l1 = l1.next; if(l2!=null) l2 = l2.next; } return head.next; }}","link":"/2018/11/16/leetcode-2-Add-Two-Numbers.html"},{"title":"Java设计模式之观察者模式","text":"定义 在阎宏博士的《JAVA与模式》一书中开头是这样描述观察者（Observer）模式的：观察者模式是对象的行为模式，又叫发布-订阅(Publish/Subscribe)模式、模型-视图(Model/View)模式、源-监听器(Source/Listener)模式或从属者(Dependents)模式。观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 推结构模式推模式相关结构说明一个软件系统里面包含了各种对象，就像一片欣欣向荣的森林充满了各种生物一样。在一片森林中，各种生物彼此依赖和约束，形成一个个生物链。一种生物的状态变化会造成其他一些生物的相应行动，每一个生物都处于别的生物的互动之中。 同样，一个软件系统常常要求在某一个对象的状态发生变化的时候，某些其他的对象做出相应的改变。做到这一点的设计方案有很多，但是为了使系统能够易于复用，应该选择低耦合度的设计方案。减少对象之间的耦合有利于系统的复用，但是同时设计师需要使这些低耦合度的对象之间能够维持行动的协调一致，保证高度的协作。观察者模式是满足这一要求的各种设计方案中最重要的一种。 下面以一个简单的示意性实现为例，讨论观察者模式的结构。 观察者模式所涉及的角色有： ● 抽象主题(Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList对象）里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象，抽象主题角色又叫做抽象被观察者(Observable)角色。 ● 具体主题(ConcreteSubject)角色：将有关状态存入具体观察者对象；在具体主题的内部状态改变时，给所有登记过的观察者发出通知。具体主题角色又叫做具体被观察者(Concrete Observable)角色。 ● 抽象观察者(Observer)角色：为所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 ● 具体观察者(ConcreteObserver)角色：存储与主题的状态自恰的状态。具体观察者角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态 像协调。如果需要，具体观察者角色可以保持一个指向具体主题对象的引用。 主题对象向观察者推送主题的详细信息，不管观察者是否需要，推送的信息通常是主题对象的全部或部分数据。 抽象观察者角色1234public interface Observer { void update(String state); String getName();} 具体观察者1234567891011121314151617181920212223242526public class ConcreteObserver implements Observer { private String name; private String state; public ConcreteObserver(String name) { this.name = name; } public String getState() { return state; } public void setState(String state) { this.state = state; } @Override public void update(String state) { // 更新观察 着状态 this.state = state; System.out.println(getName() + \"观察者状态更新为：\" + state); } @Override public String getName() { return name; }} 抽象主题角色1234567891011121314151617181920212223242526272829303132public abstract class Subject { /** * 保存观察者的容器 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者 */ public void register(Observer o) { list.add(o); System.out.println(\"增加了一个观察者:\" + o.getName()); } /** * 移除观察者 * * @param o */ public void remove(Observer o) { System.out.println(\"移除了一个观察者:\" + o.getName()); list.remove(o); } /** * 通知观察者 * * @param newState */ public void nodifyObservers(String newState) { for (Observer observer : list) { observer.update(newState); } }} 具体主题角色12345678910111213141516public class ConcreteSubject extends Subject { /** * 状态 */ private String state; public String getState() { return state; } public void change(String newState) { state = newState; System.out.println(\"状态变为：\" + newState); System.out.println(\"开始通知观察者...\"); this.nodifyObservers(state); }} 测试类12345678910111213public class MainTest { public static void main(String[] args) { Observer o1 = new ConcreteObserver(\"o1\"); Observer o2 = new ConcreteObserver(\"o2\"); Observer o3 = new ConcreteObserver(\"o3\"); ConcreteSubject csj = new ConcreteSubject(); csj.register(o1); csj.register(o2); csj.register(o3); csj.remove(o2); csj.change(\"new State！\"); }} 输出结果 在运行时，这个客户端首先创建了具体主题类的实例，以及一个观察者对象。然后，它调用主题对象的register()方法，将这个观察者对象向主题对象登记，也就是将它加入到主题对象的聚集中去。 这时，客户端调用主题的change()方法，改变了主题对象的内部状态。主题对象在状态发生变化时，调用超类的notifyObservers()方法，通知所有登记过的观察者对象 拉模式结构说明 主题对象在通知观察者的时候，只传递少量信息。如果观察者需要更具体的信息，由观察者主动到主题对象中获取，相当于是观察者从主题对象中拉数据。一般这种模型的实现中，会把主题对象自身通过update()方法传递给观察者，这样在观察者需要获取数据的时候，就可以通过这个引用来获取了。 抽象观察者角色12345678public interface Observer { /** * 传入主题，获取中的对象 * @param subject */ void update(Subject subject); String getName();} 具体观察者123456789101112131415161718192021222324252627public class ConcreteObserver implements Observer { private String name; private String state; public ConcreteObserver(String name) { this.name = name; } public String getState() { return state; } public void setState(String state) { this.state = state; } @Override public String getName() { return name; } @Override public void update(Subject subject) { // 主动去主题里拿数据 state = ((ConcreteSubject) subject).getState(); System.out.println(getName() + \"观察者状态更新为：\" + state); }} 抽象主题角色1234567891011121314151617181920212223242526272829303132333435public abstract class Subject { /** * 保存观察者的容器 */ private List&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;(); /** * 注册观察者 */ public void register(Observer o) { list.add(o); System.out.println(\"增加了一个观察者:\" + o.getName()); } /** * 移除观察者 * * @param o */ public void remove(Observer o) { System.out.println(\"移除了一个观察者:\" + o.getName()); list.remove(o); } /** * 通知观察者 * * @param newState */ public void nodifyObservers() { for (Observer observer : list) { observer.update(this); } }} 具体主题角色123456789101112131415161718public class ConcreteSubject extends Subject { /** * 状态 */ private String state; public String getState() { return state; } public void change(String newState) { state = newState; System.out.println(\"状态变为：\" + newState); System.out.println(\"开始通知观察者...\"); this.nodifyObservers(); }} 测试12345678910111213public class MainTest { public static void main(String[] args) { Observer o1 = new ConcreteObserver(\"o1\"); Observer o2 = new ConcreteObserver(\"o2\"); Observer o3 = new ConcreteObserver(\"o3\"); ConcreteSubject csj = new ConcreteSubject(); csj.register(o1); csj.register(o2); csj.register(o3); csj.remove(o2); csj.change(\"new State！\"); }} 测试结果 两种模式的比较 推模型是假定主题对象知道观察者需要的数据；而拉模型是主题对象不知道观察者具体需要什么数据，没有办法的情况下，干脆把自身传递给观察者，让观察者自己去按需要取值。 推模型可能会使得观察者对象难以复用，因为观察者的update()方法是按需要定义的参数，可能无法兼顾没有考虑到的使用情况。这就意味着出现新情况的时候，就可能提供新的update()方法，或者是干脆重新实现观察者；而拉模型就不会造成这样的情况，因为拉模型下，update()方法的参数是主题对象本身，这基本上是主题对象能传递的最大数据集合了，基本上可以适应各种情况的需要。 参考链接","link":"/2018/11/15/Java设计模式之观察者模式.html"},{"title":"Immutable Object(不可变对象)模式","text":"多线程下，一个对象会被多个线程共享，存在多线程并发地修改对象的属性，需要做些同步访问控制，如显示锁，CAS操作，会带来额外的开销和问题，如上下文切换、等待时间、ABA问题。Immutable Object模式意图通过使用对外可见的状态不可变的对象，使得天生具有线程安全性。 车辆管理系统状态可变的位置信息模型123456789101112131415161718192021public class Location { private double x; private double y; public Location(double x, double y) { this.x = x; this.y = y; } public double getX() { return x; } public double getY() { return y; } public void setXY(double x, double y) { this.x = x; this.y = y; }} 管理系统中会调用Location的setXY方法来更新位置，因为是非线程安全，并非原子操作，导致调用时会出现数据不一致的情况 改进：状态不可变的位置信息模型123456789public final class Location{ public final double x; public final double y; public Location(double x,double y){ this.x = x; this.y = y; }} 使用状态不可变的对象时，更新信息模型时，如果车辆的位置发生变动，更新的是整个位置信息的对象 更新不可变对象的位置信息123456public class VehicleTracker{ private Map&lt;String,Location&gt; locMap = new ConcurrentHashMap&lt;String, Location&gt;(); public void updateLocation(String vehicleId,Location newLocation){ locMap.put(vehicleId,newLocation); } } 一个严格意义上的不可变对象应该满足以下所有条件 类本身用final修饰 所有字段都是用final修饰，这个语意在多线程环境下由JVM保证了被修饰字段所引用对象的初始化安全，即final修饰的字段在其他线程是可见的，必定是初始化完成的。 在对象的创建过程中，this关键字没有泄露给其他类，防止其他类在对象创建过程中修改其状态 任何字段如果引用其他状态可变的对象，如集合数组，这些字段必须是private修饰的，不能暴露给外部，所有相关方法要返回这些字段值，应该防止防御性复制 实例： 某彩信网关系统 在处理由增值业务提供商VASP下发给手机终端用户的彩信信息时，需要根据彩信接收方号码的前缀选择对应的彩信中心MMSC，然后转发消息给选中的彩信中心。由其他系统将彩信信息下发给手机终端用户。选择彩信中心的过程称为 路由 ，手机前缀和彩信中心对应的关系叫路由表，在系统中多线程共享，很少改变此数据，不希望访问这些数据时进行加锁并发访问控制，避免产生不必要的开销，所以选择immutable object模型。 彩信中心路由规则管理器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/***彩信中心路由规则管理器**/public final class MMSCRouter{ // 保证多线程环境下该变量的可见性 private static volatile MMSCRouter instance = new MMSCRouter(); // 维护手机号码前缀到彩信中心之间的映射关系 private final Map&lt;String,MMSCInfo&gt; routerMap; public MMSCRouter(){ // 将数据库表中的数据加载到内存，存为Map this.routerMap = MMSCRouter.retrieveRouterMapFromDB(); } private static Map&lt;String,MMSCInfo&gt; retrieveRouterMapFromDB(){ Map&lt;String,MMSCInfo&gt; map = new HashMap&lt;&gt;(); // 省略其余代码 return map; } public static MMSCRouter getInstance(){ return instance; } /** *根据手机号前缀获取彩信中心信息 **/ public MMSCInfo getMMSC(String msisdPrefix){ return routerMap.get(msisdPrefix); } /** *更新为指定的新实例 **/ public static void setInstance(MMSCRouter newInstance){ instance = newInstance; } /** *防御性复制 **/ private static Map&lt;String,MMSCInfo&gt; deepCopy(Map&lt;String,MMSCInfo&gt; m){ Map&lt;String,MMSCInfo&gt; result = new HashMap&lt;String,MMSCInfo&gt;(); for(String key : m.keySet()){ result.put(key, new MMSCInfo(m.get(key))); } return result; } // 防止外部代码修改可变数据routerMap的值 public Map&lt;String,MMSCInfo&gt; getRouterMap(){ return Collections.unmodifiableMap(deepCopy(routerMap)); }} 彩信中心信息123456789101112131415161718192021222324252627282930public final class MMSCInfo{ private final String deviceId; private final String url; private final int maxAttachmentSizeInBytes; public MMSCInfo(String deviceId, String url, int maxAttachmentSizeInBytes){ this.deviceId = deviceId; this.url = url; this.maxAttachmentSizeInBytes = maxAttachmentSizeInBytes; } public MMSCInfo(MMSCInfo protoType){ this.deviceId = protoType.deviceId; this.url = protoType.url; this.maxAttachmentSizeInBytes = protoType.maxAttachmentSizeInBytes; } public String getDeviceId(){ return deviceId; } public String getUrl(){ return url; } public int getMaxAttachmentSizeInBytes(){ return maxAttachmentSizeInBytes; } } 彩信中心信息变更的频率也同样不高。因此，当彩信网关系统通过网络被通知到这种彩信中心信息本身或者路由变更时，网关系统会重新生成新的MMSInfo和MMSRouter来反应变更。 彩信中心、路由表的变更123456789101112131415161718public class OMCAgent extends Thread{ @Override public void run(){ boolean isTableModificationMsg = false; String updatedTableName = null; while(true){ // 省略代码 从与OMC 连接中读取信息进行解析 // 解析到数据表更新信息后，重置MMSCRouter实例 if(isTableModificationMsg){ if(\"MMSCInfo\".equals(updatedTableName)){ // new MMSCRouter() 从数据库中加载变更的信息存入 MMSCRouter.setInstance(new MMSCRouter()); } } // 省略其他代码 } }} 本列中MMSCInfo 是一个严格意义上的不可变对象，虽然MMSCRouter对象对外提供了setInstance方法用于改变静态字段instance的值，但它仍然可被视作一个等效的不可变对象。因为setInstance仅仅改变instance变量指向的对象，而instance变量采用volatile修饰保证了其余线程的可见性，所以无需加锁其他线程也能获取到最新的instance 总结Immutable Object 模型使用场景 被建模对象的状态变化不频繁 同时对一组相关的数据进行写操作，因此需要保证原子性 使用某个对象作为安全的HashMap的可以key。由于final不可变对象不变所有hashcode不变，所以适合作为HashMap 的key。 参考文献java多线程编程实战指南（设计模式篇）黄文海/著","link":"/2018/11/13/Immutable-Object-不可变对象-模式.html"},{"title":"elasticsearch6 query 全文查询与词项查询","text":"query全文查询 QueryBuilders.matchQuery(“filed”,”value”).operator(Operator.AND); // 对查询的语句进行分词，分词后的词任意一个匹配doc都能查出来 term query 查询的是词项&lt;分词后的&gt; （eg：Java编程思想） Java编程 term query 不能查到 分词后变成（Java 编程 思想） matchQuery能查到 QueryBuilders.matchPhraseQuery(“field”,”value”);对value进行分词，可以自定义分词器,满足两个条件才能被搜到： 分词后的所有词项都要匹配原字段 顺序还需要一致 QueryBuilders.matchPhrasePrefixQuery(“field”,”value”);与matchPhraseQuery类似,最后一个term支持前缀匹配eg.matchPhraseQuery 查 “hello word” matchPhrasePrefixQuery只需要查 “hello w”即可 QueryBuilders.multiMatchQuery(“value”,”field1”,”field2”); 多字段支持查询，字段可以使用通配符eg,{&quot;中国&quot;,&quot;tit*&quot;,&quot;wor?&quot;} QueryBuilders.commonTermsQuery(“哇”,”hehe”);通用查询，会自动分词为低频和高频项，先查低频，可以控制低频、高频出现概率 eg.the word the就是高频 ，可以先查 word QueryBuilders.queryStringQuery(“”);支持lucene查询语法 QueryBuilders.simpleQueryStringQuery(“”);支持lucene查询语法，具有非常完善的语法查询，解析过程中出现异常不会抛错 QueryBuilders.matchAllQuery();查所有和不写同样效果 词项查询 term query 词项检索 terms query 词项检索，可以多个词项，查到一个都能匹配结果 range query 查询范围内的 gt 大于 gte 大于等于 lt 小于 lte 小于等于 exist query 查询会返回字段中至少有一个非空空字符串也返回的doc prefix query 查询字段中给定前缀的文档 eg.{&quot;title&quot;:&quot;hel&quot;} wildcard query 查询字段通配符eg.&quot;{&quot;title&quot;:&quot;hell?/ *ell*&quot;} regexp query 正则匹配查询eg.{&quot;title&quot;:&quot;W[0-9].+&quot;} fuzzy query 模糊查询，最接近的查询，单词拼错一个字母的时候，消耗资源多 type query 指定类型的文档 ids query 查询具有指定id的文档","link":"/2018/11/13/elasticsearch6-query-全文查询与词项查询.html"},{"title":"leetcode-1-Two Sum","text":"description Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example: Given nums = [2, 7, 11, 15], target = 9, Because nums[0] + nums[1] = 2 + 7 = 9, return [0, 1]. common method 1234567891011121314class Solution { public int[] twoSum(int[] nums, int target) { int[] ret = new int[2]; for(int i =0; i&lt;nums.length-1 ;i++){ for (int j = i+1 ;j &lt; nums.length ;j++ ){ if (nums[i] + nums[j] == target){ ret = new int[]{i, j}; return ret; } } } return ret ; }} best method1234567891011121314151617class Solution { public int[] twoSum(int[] nums, int target) { int len=nums.length; HashMap&lt;Integer, Integer&gt; map=new HashMap&lt;&gt;(); map.put(nums[0], 0); for(int i=1;i&lt;len;i++){ if(map.containsKey(target-nums[i])){ int[] returnArray={map.get(target-nums[i]),i}; return returnArray; } else{ map.put(nums[i], i); } } int[] returnArray={0,0}; return returnArray; }}","link":"/2018/11/11/leetcode-1-Two-Sum.html"},{"title":"Hello blog","text":"this is a first blog.It's a very exciting time make a plan execute have a harvest come on 12345public void start(){ while(true){ System.out.println(\"struggle！\"); }}","link":"/2018/11/11/Hello-blog.html"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \" My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2018/11/11/hello-world.html"}],"tags":[{"name":"Effective-Java","slug":"Effective-Java","link":"/tags/Effective-Java/"},{"name":"读书笔记","slug":"读书笔记","link":"/tags/读书笔记/"},{"name":"think","slug":"think","link":"/tags/think/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"elasticsearch6","slug":"elasticsearch6","link":"/tags/elasticsearch6/"},{"name":"query","slug":"query","link":"/tags/query/"},{"name":"arithmetic","slug":"arithmetic","link":"/tags/arithmetic/"},{"name":"leetcode","slug":"leetcode","link":"/tags/leetcode/"},{"name":"工具教程","slug":"工具教程","link":"/tags/工具教程/"},{"name":"icarus主题配置","slug":"icarus主题配置","link":"/tags/icarus主题配置/"},{"name":"hexo主题","slug":"hexo主题","link":"/tags/hexo主题/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"索引","slug":"索引","link":"/tags/索引/"},{"name":"经验成长","slug":"经验成长","link":"/tags/经验成长/"},{"name":"正则表达式","slug":"正则表达式","link":"/tags/正则表达式/"},{"name":"索引分词","slug":"索引分词","link":"/tags/索引分词/"},{"name":"幂等性,restful-api","slug":"幂等性-restful-api","link":"/tags/幂等性-restful-api/"},{"name":"支付系统","slug":"支付系统","link":"/tags/支付系统/"},{"name":"支付架构","slug":"支付架构","link":"/tags/支付架构/"}],"categories":[{"name":"读书笔记","slug":"读书笔记","link":"/categories/读书笔记/"},{"name":"遐想","slug":"遐想","link":"/categories/遐想/"},{"name":"java设计模式","slug":"java设计模式","link":"/categories/java设计模式/"},{"name":"elasticsearch6","slug":"elasticsearch6","link":"/categories/elasticsearch6/"},{"name":"java基础","slug":"java基础","link":"/categories/java基础/"},{"name":"leetcode","slug":"leetcode","link":"/categories/leetcode/"},{"name":"常用工具教程","slug":"常用工具教程","link":"/categories/常用工具教程/"},{"name":"hexo主题","slug":"hexo主题","link":"/categories/hexo主题/"},{"name":"数据库","slug":"数据库","link":"/categories/数据库/"},{"name":"经验成长","slug":"经验成长","link":"/categories/经验成长/"},{"name":"基础工具类","slug":"基础工具类","link":"/categories/基础工具类/"},{"name":"架构、设计","slug":"架构、设计","link":"/categories/架构、设计/"}]}